[01;32mxgg@decs[00m:[01;34m~/pros/MLM_transfer[00m$ bash scrii[Kpts/frequency_ratio/r[Kfine_tune_yelp_frequency_ratio.sh 
+ PROJECTPATH=/home/xgg/pros/MLM_transfer
+ cp configs/bert_yelp_frequency_ratio.config run.config
+ PYTHONPATH=/home/xgg/pros/MLM_transfer
+ /home/xgg/.conda/envs/py36/bin//python fine_tune_bert.py
03/12/2019 08:12:20 - INFO - dataloader -   device cuda n_gpu 1 distributed training False
03/12/2019 08:12:21 - INFO - dataloader -   *** Example ***
03/12/2019 08:12:21 - INFO - dataloader -   guid: train-1
03/12/2019 08:12:21 - INFO - dataloader -   tokens: [CLS] always a great place to stop by in the mall . [SEP]
03/12/2019 08:12:21 - INFO - dataloader -   init_ids: 101 2467 1037 2307 2173 2000 2644 2011 1999 1996 6670 1012 102
03/12/2019 08:12:21 - INFO - dataloader -   input_ids: 101 103 103 103 103 103 103 2011 1999 1996 6670 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 08:12:21 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 08:12:21 - INFO - dataloader -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 08:12:21 - INFO - dataloader -   masked_lm_labels: -1 2467 1037 2307 2173 2000 2644 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 08:12:21 - INFO - dataloader -   *** Example ***
03/12/2019 08:12:21 - INFO - dataloader -   guid: train-2
03/12/2019 08:12:21 - INFO - dataloader -   tokens: [CLS] the food is good for inexpensive chinese food . [SEP]
03/12/2019 08:12:21 - INFO - dataloader -   init_ids: 101 1996 2833 2003 2204 2005 23766 2822 2833 1012 102
03/12/2019 08:12:21 - INFO - dataloader -   input_ids: 101 103 103 103 103 2005 23766 2822 2833 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 08:12:21 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 08:12:21 - INFO - dataloader -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 08:12:21 - INFO - dataloader -   masked_lm_labels: -1 1996 2833 2003 2204 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 08:12:21 - INFO - dataloader -   *** Example ***
03/12/2019 08:12:21 - INFO - dataloader -   guid: train-3
03/12/2019 08:12:21 - INFO - dataloader -   tokens: [CLS] i would highly recommend taking your car here . [SEP]
03/12/2019 08:12:21 - INFO - dataloader -   init_ids: 101 1045 2052 3811 16755 2635 2115 2482 2182 1012 102
03/12/2019 08:12:21 - INFO - dataloader -   input_ids: 101 103 103 103 103 2635 2115 2482 2182 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 08:12:21 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 08:12:21 - INFO - dataloader -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 08:12:21 - INFO - dataloader -   masked_lm_labels: -1 1045 2052 3811 16755 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 08:12:21 - INFO - dataloader -   *** Example ***
03/12/2019 08:12:21 - INFO - dataloader -   guid: train-4
03/12/2019 08:12:21 - INFO - dataloader -   tokens: [CLS] my husband had the chile re ##llen ##o and thought it was amazing . [SEP]
03/12/2019 08:12:21 - INFO - dataloader -   init_ids: 101 2026 3129 2018 1996 7029 2128 12179 2080 1998 2245 2009 2001 6429 1012 102
03/12/2019 08:12:21 - INFO - dataloader -   input_ids: 101 2026 3129 2018 1996 7029 2128 12179 2080 103 103 103 103 6429 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 08:12:21 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 08:12:21 - INFO - dataloader -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 08:12:21 - INFO - dataloader -   masked_lm_labels: -1 -1 -1 -1 -1 -1 -1 -1 -1 1998 2245 2009 2001 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 08:12:21 - INFO - dataloader -   *** Example ***
03/12/2019 08:12:21 - INFO - dataloader -   guid: train-5
03/12/2019 08:12:21 - INFO - dataloader -   tokens: [CLS] my second bad experience at a t ##gi fridays . [SEP]
03/12/2019 08:12:21 - INFO - dataloader -   init_ids: 101 2026 2117 2919 3325 2012 1037 1056 5856 26587 1012 102
03/12/2019 08:12:21 - INFO - dataloader -   input_ids: 101 2026 2117 103 103 103 1037 1056 5856 26587 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 08:12:21 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 08:12:21 - INFO - dataloader -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 08:12:21 - INFO - dataloader -   masked_lm_labels: -1 -1 -1 2919 3325 2012 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 08:12:47 - INFO - dataloader -   ***** Running training *****
03/12/2019 08:12:47 - INFO - dataloader -     Num examples = 172670
03/12/2019 08:12:47 - INFO - dataloader -     Batch size = 32
03/12/2019 08:12:47 - INFO - dataloader -     Num steps = 53959
**********************************************************
Namespace(bert_model='/home/xgg/.pytorch_pretrained_bert/bert-base-uncased.tar.gz', data_dir='./processed_data_frequency_ratio/yelp/', do_lower_case=True, do_train=True, eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, loss_scale=128, max_seq_length=32, no_cuda=False, num_train_epochs=10.0, optimize_on_cpu=False, output_dir='/tmp/yelp_output/', seed=42, task_name=None, train_batch_size=32, warmup_proportion=0.1)
03/12/2019 08:12:48 - INFO - pytorch_pretrained_bert.modeling -   loading archive file /home/xgg/.pytorch_pretrained_bert/bert-base-uncased.tar.gz
03/12/2019 08:12:48 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/xgg/.pytorch_pretrained_bert/bert-base-uncased.tar.gz to temp dir /tmp/tmpp5kutnu1
03/12/2019 08:12:50 - INFO - pytorch_pretrained_bert.modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

03/12/2019 08:12:52 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
Epoch:   0%|                                                                                                                                                                         | 0/10 [00:00<?, ?it/s]avg_loss: 5.942069072723388
avg_loss: 5.439849977493286
avg_loss: 5.206103448867798
avg_loss: 4.8073280143737795
avg_loss: 4.642253370285034
avg_loss: 4.4583961343765255
avg_loss: 4.386351447105408
avg_loss: 4.329717154502869
avg_loss: 4.235608415603638
avg_loss: 4.1466193199157715
avg_loss: 4.050462317466736
avg_loss: 3.9452441453933718
avg_loss: 4.030308766365051
avg_loss: 3.8563805484771727
avg_loss: 3.9009999322891233
avg_loss: 3.749362282752991
avg_loss: 3.8316307163238523
avg_loss: 3.8307798051834108
avg_loss: 3.7735184097290038
avg_loss: 3.8355519914627076
avg_loss: 3.7127173233032225
avg_loss: 3.7041432809829713
avg_loss: 3.6003974628448487
avg_loss: 3.5852662229537966
avg_loss: 3.542758889198303
avg_loss: 3.6064729261398316
avg_loss: 3.556658482551575
avg_loss: 3.5761438179016114
avg_loss: 3.512668318748474
avg_loss: 3.494314193725586
avg_loss: 3.4578014278411864
avg_loss: 3.4346785497665406
avg_loss: 3.437664370536804
avg_loss: 3.496030230522156
avg_loss: 3.485897307395935
avg_loss: 3.375803289413452
avg_loss: 3.3844054174423217
avg_loss: 3.343039216995239
avg_loss: 3.375419874191284
avg_loss: 3.4337411022186277
avg_loss: 3.3650643968582155
avg_loss: 3.268964991569519
avg_loss: 3.285443215370178
avg_loss: 3.272540764808655
avg_loss: 3.2455172634124754
avg_loss: 3.2541962242126465
avg_loss: 3.252710461616516
avg_loss: 3.1825624990463255
avg_loss: 3.2238400554656983
avg_loss: 3.1652405357360838
avg_loss: 3.218099875450134
avg_loss: 3.219844627380371
avg_loss: 3.1965397644042968
avg_loss: 3.162138361930847
avg_loss: 3.1348257780075075
avg_loss: 3.2318810653686523
avg_loss: 3.1510387325286864
avg_loss: 3.054499635696411
avg_loss: 3.156438183784485
avg_loss: 3.1664538097381594
avg_loss: 2.9524479055404664
avg_loss: 3.082366733551025
avg_loss: 3.0889225959777833
avg_loss: 3.0514892625808714
avg_loss: 3.0478049421310427
avg_loss: 3.021507906913757
avg_loss: 3.0932656049728395
avg_loss: 3.0629471206665038
avg_loss: 3.060016436576843
avg_loss: 2.9445455121994017
avg_loss: 2.9208991861343385
avg_loss: 3.027679443359375
avg_loss: 2.962056450843811
avg_loss: 2.9683097791671753
avg_loss: 2.97976056098938
avg_loss: 3.03768527507782
avg_loss: 2.988661985397339
avg_loss: 2.970157513618469
avg_loss: 2.970995454788208
avg_loss: 2.9851488399505617
avg_loss: 2.932849111557007
avg_loss: 2.977933259010315
avg_loss: 2.905828285217285
avg_loss: 2.9518124055862427
avg_loss: 2.9473440265655517
avg_loss: 2.9583658742904664
avg_loss: 2.884553380012512
avg_loss: 2.8799335765838623
avg_loss: 2.916104598045349
avg_loss: 2.92417893409729
avg_loss: 2.9330222988128662
avg_loss: 2.8830652236938477
avg_loss: 2.906296796798706
avg_loss: 2.8617921686172485
avg_loss: 2.8582450342178345
avg_loss: 2.9102102518081665
avg_loss: 2.881930513381958
avg_loss: 2.8022844123840334
avg_loss: 2.862827429771423
avg_loss: 2.8139019584655762
avg_loss: 2.808954162597656
avg_loss: 2.8575480604171752
avg_loss: 2.801641719341278
avg_loss: 2.828406181335449
avg_loss: 2.7589698743820192
avg_loss: 2.83592668056488
avg_loss: 2.793264136314392
Epoch:  10%|███████████████▊                                                                                                                                              | 1/10 [14:03<2:06:27, 843.11s/it]avg_loss: 2.6710274600982666
avg_loss: 2.6368083429336546
avg_loss: 2.649335308074951
avg_loss: 2.6160398888587952
avg_loss: 2.54795955657959
avg_loss: 2.618294885158539
avg_loss: 2.550096478462219
avg_loss: 2.595237774848938
avg_loss: 2.651995053291321
avg_loss: 2.6432491660118105
avg_loss: 2.609543652534485
avg_loss: 2.593451623916626
avg_loss: 2.6031064319610597
avg_loss: 2.605169348716736
avg_loss: 2.582293062210083
avg_loss: 2.558660299777985
avg_loss: 2.638194224834442
avg_loss: 2.522702307701111
avg_loss: 2.649796071052551
avg_loss: 2.5596319150924685
avg_loss: 2.5569607973098756
avg_loss: 2.540914332866669
avg_loss: 2.597786774635315
avg_loss: 2.6425985217094423
avg_loss: 2.5677845597267153
avg_loss: 2.608580493927002
avg_loss: 2.544202082157135
avg_loss: 2.591354908943176
avg_loss: 2.54342652797699
avg_loss: 2.503196349143982
avg_loss: 2.642191767692566
avg_loss: 2.5914999890327453
avg_loss: 2.4874636697769166
avg_loss: 2.565241024494171
avg_loss: 2.6063750553131104
avg_loss: 2.587744300365448
avg_loss: 2.645814211368561
avg_loss: 2.467153685092926
avg_loss: 2.571071271896362
avg_loss: 2.47033203125
avg_loss: 2.508790340423584
avg_loss: 2.475434651374817
avg_loss: 2.6172541189193725
avg_loss: 2.530138084888458
avg_loss: 2.4940482330322267
avg_loss: 2.5388632798194886
avg_loss: 2.4774625396728513
avg_loss: 2.4417980766296385
avg_loss: 2.537146167755127
avg_loss: 2.5140828919410705
avg_loss: 2.4679890179634096
avg_loss: 2.515427625179291
avg_loss: 2.4792971062660216
avg_loss: 2.4756451225280762
avg_loss: 2.521860809326172
avg_loss: 2.5298143291473387
avg_loss: 2.423847880363464
avg_loss: 2.5021021294593813
avg_loss: 2.4943296265602113
avg_loss: 2.551872801780701
avg_loss: 2.579153218269348
avg_loss: 2.519945080280304
avg_loss: 2.489410572052002
avg_loss: 2.481794195175171
avg_loss: 2.5652548122406005
avg_loss: 2.4638373756408694
avg_loss: 2.493748700618744
avg_loss: 2.427305729389191
avg_loss: 2.4713439631462095
avg_loss: 2.4954387950897217
avg_loss: 2.4315063118934632
avg_loss: 2.492765645980835
avg_loss: 2.472536723613739
avg_loss: 2.5540130519866944
avg_loss: 2.5174503445625307
avg_loss: 2.4372545051574708
avg_loss: 2.4957275009155273
avg_loss: 2.460167500972748
avg_loss: 2.5024073553085326
avg_loss: 2.429007103443146
avg_loss: 2.4983816647529604
avg_loss: 2.43117546081543
avg_loss: 2.383198821544647
avg_loss: 2.42526859998703
avg_loss: 2.440423519611359
avg_loss: 2.491709156036377
avg_loss: 2.4091958737373353
avg_loss: 2.500023682117462
avg_loss: 2.47921320438385
avg_loss: 2.4249877190589904
avg_loss: 2.4870900869369508
avg_loss: 2.5300311708450316
avg_loss: 2.33694078207016
avg_loss: 2.4659847950935365
avg_loss: 2.479240965843201
avg_loss: 2.437732138633728
avg_loss: 2.378957209587097
avg_loss: 2.3560299921035766
avg_loss: 2.434509711265564
avg_loss: 2.3879101395606996
avg_loss: 2.405849416255951
avg_loss: 2.451564152240753
avg_loss: 2.49749694108963
avg_loss: 2.4398408246040346
avg_loss: 2.4799637603759765
avg_loss: 2.476174614429474
avg_loss: 2.4963308072090147
Epoch:  20%|███████████████████████████████▌                                                                                                                              | 2/10 [28:06<1:52:26, 843.27s/it]avg_loss: 2.153592166900635
avg_loss: 2.102695586681366
avg_loss: 2.197426254749298
avg_loss: 2.1524328088760374
avg_loss: 2.107721004486084
avg_loss: 2.1814212656021117
avg_loss: 2.167246603965759
avg_loss: 2.1248173832893373
avg_loss: 2.2179056334495546
avg_loss: 2.0321670174598694
avg_loss: 2.1659806871414187
avg_loss: 2.198441150188446
avg_loss: 2.129447205066681
avg_loss: 2.1154617929458617
avg_loss: 2.1693228101730346
avg_loss: 2.1820274639129638
avg_loss: 2.093259074687958
avg_loss: 2.213114175796509
avg_loss: 2.1969753241539003
avg_loss: 2.2086030626296997
avg_loss: 2.1671902894973756
avg_loss: 2.170112359523773
avg_loss: 2.192524480819702
avg_loss: 2.1634928083419798
avg_loss: 2.1670254850387574
avg_loss: 2.1347525405883787
avg_loss: 2.1769629096984864
avg_loss: 2.2070284938812255
avg_loss: 2.166520457267761
avg_loss: 2.131484341621399
avg_loss: 2.139578971862793
avg_loss: 2.1054291939735412
avg_loss: 2.2055116510391235
avg_loss: 2.2543872690200804
avg_loss: 2.132118275165558
avg_loss: 2.1898378896713258
avg_loss: 2.143769884109497
avg_loss: 2.1821862649917603
avg_loss: 2.181256926059723
avg_loss: 2.178401005268097
avg_loss: 2.190954954624176
avg_loss: 2.1181269907951354
avg_loss: 2.1649230885505677
avg_loss: 2.2251274967193604
avg_loss: 2.145896735191345
avg_loss: 2.180730068683624
avg_loss: 2.1457342648506166
avg_loss: 2.152544379234314
avg_loss: 2.130881357192993
avg_loss: 2.145728120803833
avg_loss: 2.1011402726173403
avg_loss: 2.1693724822998046
avg_loss: 2.1911279511451722
avg_loss: 2.0842901968955996
avg_loss: 2.0848038482666014
avg_loss: 2.1473004245758056
avg_loss: 2.137646200656891
avg_loss: 2.142262725830078
avg_loss: 2.1863731360435485
avg_loss: 2.123117847442627
avg_loss: 2.1510661172866823
avg_loss: 2.157527520656586
avg_loss: 2.19696058511734
avg_loss: 2.083627872467041
avg_loss: 2.1700977993011477
avg_loss: 2.143013973236084
avg_loss: 2.160790717601776
avg_loss: 2.153630676269531
avg_loss: 2.117158200740814
avg_loss: 2.164554979801178
avg_loss: 2.1529701590538024
avg_loss: 2.125212218761444
avg_loss: 2.1320912051200867
avg_loss: 2.146090807914734
avg_loss: 2.1625652623176577
avg_loss: 2.1060033440589905
avg_loss: 2.1648571634292604
avg_loss: 2.1788612389564515
avg_loss: 2.0796688079833983
avg_loss: 2.2008842825889587
avg_loss: 2.1952203488349915
avg_loss: 2.1518083691596983
avg_loss: 2.1372245383262634
avg_loss: 2.1863510990142823
avg_loss: 2.1518687129020693
avg_loss: 2.180747950077057
avg_loss: 2.0969854974746704
avg_loss: 2.1376764130592347
avg_loss: 2.0694008755683897
avg_loss: 2.1432985663414
avg_loss: 2.1167401123046874
avg_loss: 2.089122402667999
avg_loss: 2.106959867477417
avg_loss: 2.216859850883484
avg_loss: 2.1222535729408265
avg_loss: 2.1665196132659914
avg_loss: 2.13119677066803
avg_loss: 2.141806139945984
avg_loss: 2.151262059211731
avg_loss: 2.1229260921478272
avg_loss: 2.1276950335502622
avg_loss: 2.1135926938056944
avg_loss: 2.1534887313842774
avg_loss: 2.113704888820648
avg_loss: 2.068978807926178
avg_loss: 2.097679121494293
avg_loss: 2.0730845880508424
Epoch:  30%|███████████████████████████████████████████████▍                                                                                                              | 3/10 [42:10<1:38:24, 843.46s/it]avg_loss: 1.8875628209114075
avg_loss: 1.9148814225196837
avg_loss: 1.8808762049674987
avg_loss: 1.9006775951385497
avg_loss: 1.8294494724273682
avg_loss: 1.945129120349884
avg_loss: 1.8788452935218811
avg_loss: 1.848012945652008
avg_loss: 1.8404999494552612
avg_loss: 1.920814335346222
avg_loss: 1.914840259552002
avg_loss: 1.8304824781417848
avg_loss: 1.884611141681671
avg_loss: 1.9144880867004395
avg_loss: 1.9254589200019836
avg_loss: 1.958266258239746
avg_loss: 1.8634809041023255
avg_loss: 1.900023729801178
avg_loss: 1.9297049474716186
avg_loss: 1.9248822212219239
avg_loss: 1.9417768597602845
avg_loss: 1.8946220874786377
avg_loss: 1.952357258796692
avg_loss: 1.8646313118934632
avg_loss: 1.8140887069702147
avg_loss: 1.857870910167694
avg_loss: 1.9640918254852295
avg_loss: 1.930943329334259
avg_loss: 1.9044081306457519
avg_loss: 1.7943592739105225
avg_loss: 1.9588994431495665
avg_loss: 1.8968272709846496
avg_loss: 1.8778819632530213
avg_loss: 1.9084642028808594
avg_loss: 1.8694879031181335
avg_loss: 1.8603034281730653
avg_loss: 1.8799134063720704
avg_loss: 1.8692317628860473
avg_loss: 1.887271752357483
avg_loss: 1.8896900987625123
avg_loss: 1.9281190681457518
avg_loss: 1.9122720241546631
avg_loss: 1.9205836820602418
avg_loss: 1.8975573110580444
avg_loss: 1.9507113218307495
avg_loss: 1.9458084750175475
avg_loss: 1.8549183988571167
avg_loss: 1.8201295232772827
avg_loss: 1.8273962259292602
avg_loss: 1.863868145942688
avg_loss: 1.8609810543060303
avg_loss: 1.9219927191734314
avg_loss: 1.8596118903160095
avg_loss: 1.8699351978302001
avg_loss: 1.8814671635627747
avg_loss: 1.8769798111915588
avg_loss: 1.9045055103302002
avg_loss: 1.8978557538986207
avg_loss: 1.8698539710044861
avg_loss: 1.874280195236206
avg_loss: 1.8326210498809814
avg_loss: 1.9183465790748597
avg_loss: 1.8288620948791503
avg_loss: 1.9066817665100098
avg_loss: 1.8326509404182434
avg_loss: 1.9050490188598632
avg_loss: 1.8778418874740601
avg_loss: 1.9079425430297852
avg_loss: 1.871779775619507
avg_loss: 1.8691499304771424
avg_loss: 1.9196544146537782
avg_loss: 1.8926213741302491
avg_loss: 1.913913242816925
avg_loss: 1.9138888835906982
avg_loss: 1.823529794216156
avg_loss: 1.9859576988220216
avg_loss: 1.8641971349716187
avg_loss: 1.848042848110199
avg_loss: 1.888458993434906
avg_loss: 1.9674003076553346
avg_loss: 1.9218485474586486
avg_loss: 1.9106071448326112
avg_loss: 1.8567289757728576
avg_loss: 1.8865490341186524
avg_loss: 1.9709215211868285
avg_loss: 1.8489358925819397
avg_loss: 1.8726037764549255
avg_loss: 1.9271862959861756
avg_loss: 1.911224706172943
avg_loss: 1.8892407536506652
avg_loss: 1.8938597083091735
avg_loss: 1.8145059967041015
avg_loss: 1.952776188850403
avg_loss: 1.9353221464157104
avg_loss: 1.9109630298614502
avg_loss: 1.8822946381568908
avg_loss: 1.8956212282180787
avg_loss: 1.8702974820137024
avg_loss: 1.882348735332489
avg_loss: 1.867785918712616
avg_loss: 1.8638933801651
avg_loss: 1.9200022339820861
avg_loss: 1.8987366628646851
avg_loss: 1.9285084462165833
avg_loss: 1.9285256886482238
avg_loss: 1.8700971984863282
avg_loss: 1.8956780552864074
Epoch:  40%|███████████████████████████████████████████████████████████████▏                                                                                              | 4/10 [56:14<1:24:22, 843.72s/it]avg_loss: 1.6321519112586975
avg_loss: 1.6984921216964721
avg_loss: 1.7149331760406494
avg_loss: 1.6271579623222352
avg_loss: 1.6406494164466858
avg_loss: 1.6177792739868164
avg_loss: 1.6640667700767517
avg_loss: 1.7357259750366212
avg_loss: 1.664741714000702
avg_loss: 1.6208300924301147
avg_loss: 1.7226241397857667
avg_loss: 1.695607259273529
avg_loss: 1.6796531558036805
avg_loss: 1.6664830374717712
avg_loss: 1.6840641522407531
avg_loss: 1.6559718561172485
avg_loss: 1.6972031497955322
avg_loss: 1.6875363945961
avg_loss: 1.7080249333381652
avg_loss: 1.668954095840454
avg_loss: 1.6898908531665802
avg_loss: 1.6921125030517579
avg_loss: 1.7102447938919068
avg_loss: 1.639109845161438
avg_loss: 1.7065990686416626
avg_loss: 1.6409685564041139
avg_loss: 1.6561388492584228
avg_loss: 1.68890207529068
avg_loss: 1.6389183139801025
avg_loss: 1.6568198657035829
avg_loss: 1.7672364521026611
avg_loss: 1.6759662854671478
avg_loss: 1.6940166521072388
avg_loss: 1.6628309893608093
avg_loss: 1.610360360145569
avg_loss: 1.7273448038101196
avg_loss: 1.7001207876205444
avg_loss: 1.6305553102493286
avg_loss: 1.719333689212799
avg_loss: 1.7151182293891907
avg_loss: 1.6475325441360473
avg_loss: 1.65642333984375
avg_loss: 1.6785770511627198
avg_loss: 1.6442721676826477
avg_loss: 1.6962710070610045
avg_loss: 1.6733045649528504
avg_loss: 1.674735279083252
avg_loss: 1.6951963031291961
avg_loss: 1.7005292558670044
avg_loss: 1.700241312980652
avg_loss: 1.6862202763557435
avg_loss: 1.7049901247024537
avg_loss: 1.733124452829361
avg_loss: 1.7048456501960754
avg_loss: 1.6863616907596588
avg_loss: 1.705273597240448
avg_loss: 1.6775977468490602
avg_loss: 1.7503504061698913
avg_loss: 1.6695884847640992
avg_loss: 1.7006050181388854
avg_loss: 1.6827026104927063
avg_loss: 1.722597794532776
avg_loss: 1.7046919465065002
avg_loss: 1.7119863152503967
avg_loss: 1.6622442865371705
avg_loss: 1.7168517470359803
avg_loss: 1.732379493713379
avg_loss: 1.7036663484573364
avg_loss: 1.705731246471405
avg_loss: 1.6421790277957917
avg_loss: 1.6795801520347595
avg_loss: 1.6907561922073364
avg_loss: 1.7346844577789307
avg_loss: 1.705243489742279
avg_loss: 1.7108748626708985
avg_loss: 1.753303391933441
avg_loss: 1.7324073815345764
avg_loss: 1.786229691505432
avg_loss: 1.767656888961792
avg_loss: 1.686978051662445
avg_loss: 1.6391424822807312
avg_loss: 1.7105930352210998
avg_loss: 1.66863872051239
avg_loss: 1.7556795501708984
avg_loss: 1.7244772839546203
avg_loss: 1.6331209874153136
avg_loss: 1.6855173110961914
avg_loss: 1.7277503991127015
avg_loss: 1.6696156811714173
avg_loss: 1.6984768080711365
avg_loss: 1.6887176096439362
avg_loss: 1.71994300365448
avg_loss: 1.6834554553031922
avg_loss: 1.7271454381942748
avg_loss: 1.663809027671814
avg_loss: 1.741897749900818
avg_loss: 1.6991085886955262
avg_loss: 1.7093485963344575
avg_loss: 1.6832803010940551
avg_loss: 1.6485815453529358
avg_loss: 1.737251753807068
avg_loss: 1.666055405139923
avg_loss: 1.638977848291397
avg_loss: 1.6747184491157532
avg_loss: 1.7075856351852416
avg_loss: 1.666275315284729
avg_loss: 1.7244057154655457
Epoch:  50%|██████████████████████████████████████████████████████████████████████████████                                                                              | 5/10 [1:10:19<1:10:20, 844.06s/it]avg_loss: 1.4330149126052856
avg_loss: 1.4433308637142181
avg_loss: 1.4859240674972534
avg_loss: 1.5450835943222045
avg_loss: 1.551006360054016
avg_loss: 1.560625865459442
avg_loss: 1.5251809096336364
avg_loss: 1.5211251997947692
avg_loss: 1.447110857963562
avg_loss: 1.5369710743427276
avg_loss: 1.529712996482849
avg_loss: 1.436980309486389
avg_loss: 1.5105238914489747
avg_loss: 1.5109251737594604
avg_loss: 1.4709153270721436
avg_loss: 1.5161069178581237
avg_loss: 1.5149594748020172
avg_loss: 1.5059725987911223
avg_loss: 1.4979977869987489
avg_loss: 1.5486882376670836
avg_loss: 1.5486174178123475
avg_loss: 1.5456236839294433
avg_loss: 1.5177695655822754
avg_loss: 1.4900233018398286
avg_loss: 1.510498185157776
avg_loss: 1.5686000728607177
avg_loss: 1.5506349420547485
avg_loss: 1.5399094998836518
avg_loss: 1.505509979724884
avg_loss: 1.477680561542511
avg_loss: 1.5312074518203735
avg_loss: 1.5536428117752075
avg_loss: 1.5136905717849731
avg_loss: 1.443058533668518
avg_loss: 1.5284932041168213
avg_loss: 1.5419859087467194
avg_loss: 1.5236335813999176
avg_loss: 1.5870606446266173
avg_loss: 1.4903877544403077
avg_loss: 1.532644898891449
avg_loss: 1.5298844134807588
avg_loss: 1.4715331137180327
avg_loss: 1.511378860473633
avg_loss: 1.5028632998466491
avg_loss: 1.5151530265808106
avg_loss: 1.490623219013214
avg_loss: 1.4709383714199067
avg_loss: 1.5539977622032166
avg_loss: 1.5142747020721437
avg_loss: 1.5025054478645326
avg_loss: 1.57482684135437
avg_loss: 1.5010681796073913
avg_loss: 1.5032570266723633
avg_loss: 1.564088957309723
avg_loss: 1.5204889953136445
avg_loss: 1.4858112239837646
avg_loss: 1.5402961707115173
avg_loss: 1.5238712739944458
avg_loss: 1.558057405948639
avg_loss: 1.5068260300159455
avg_loss: 1.5675867772102356
avg_loss: 1.4985298025608063
avg_loss: 1.5001576364040374
avg_loss: 1.5611744654178619
avg_loss: 1.5761977934837341
avg_loss: 1.5818771386146546
avg_loss: 1.471142930984497
avg_loss: 1.5735844945907593
avg_loss: 1.5284386706352233
avg_loss: 1.5272638916969299
avg_loss: 1.5559423565864563
avg_loss: 1.5082272136211394
avg_loss: 1.4996974778175354
avg_loss: 1.4893572926521301
avg_loss: 1.493921765089035
avg_loss: 1.5370759439468384
avg_loss: 1.5296660995483398
avg_loss: 1.5456355476379395
avg_loss: 1.5030724143981933
avg_loss: 1.5162913012504577
avg_loss: 1.5546520948410034
avg_loss: 1.499287714958191
avg_loss: 1.5970573782920838
avg_loss: 1.5170468056201936
avg_loss: 1.58055757522583
avg_loss: 1.577608699798584
avg_loss: 1.541619873046875
avg_loss: 1.5785824537277222
avg_loss: 1.5235043716430665
avg_loss: 1.5038056707382201
avg_loss: 1.501287888288498
avg_loss: 1.5091180288791657
avg_loss: 1.533475580215454
avg_loss: 1.530771379470825
avg_loss: 1.53434725522995
avg_loss: 1.5752169275283814
avg_loss: 1.5533417654037476
avg_loss: 1.5330705845355987
avg_loss: 1.5371689105033874
avg_loss: 1.494180850982666
avg_loss: 1.5515882611274718
avg_loss: 1.5224234986305236
avg_loss: 1.5489439642429352
avg_loss: 1.5634741008281707
avg_loss: 1.5044561433792114
avg_loss: 1.5323582458496094
avg_loss: 1.6028103137016296
Epoch:  60%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 6/10 [1:24:24<56:17, 844.29s/it]avg_loss: 1.3712639439105987
avg_loss: 1.3742937242984772
avg_loss: 1.3823916733264923
avg_loss: 1.3804767966270446
avg_loss: 1.3372558796405791
avg_loss: 1.3843435561656952
avg_loss: 1.3217269849777222
avg_loss: 1.3703488183021546
avg_loss: 1.3252530181407929
avg_loss: 1.3773285055160522
avg_loss: 1.3445060896873473
avg_loss: 1.3774971055984497
avg_loss: 1.3469397079944612
avg_loss: 1.3619579207897186
avg_loss: 1.3424577486515046
avg_loss: 1.359127503633499
avg_loss: 1.3623199474811554
avg_loss: 1.3756705725193024
avg_loss: 1.3763924825191498
avg_loss: 1.4357422554492951
avg_loss: 1.4039372634887695
avg_loss: 1.3813018548488616
avg_loss: 1.3389087867736817
avg_loss: 1.3946793758869171
avg_loss: 1.3684520745277404
avg_loss: 1.4084746909141541
avg_loss: 1.3619762432575226
avg_loss: 1.3148625850677491
avg_loss: 1.3774937760829926
avg_loss: 1.41031245470047
avg_loss: 1.3633362877368926
avg_loss: 1.3665485739707948
avg_loss: 1.4320124530792235
avg_loss: 1.402587115764618
avg_loss: 1.4523824858665466
avg_loss: 1.354430935382843
avg_loss: 1.3632370865345
avg_loss: 1.4033828604221343
avg_loss: 1.3864448630809785
avg_loss: 1.37650381565094
avg_loss: 1.393173177242279
avg_loss: 1.4050286400318146
avg_loss: 1.3750979268550874
avg_loss: 1.3863300609588622
avg_loss: 1.4006282138824462
avg_loss: 1.4021966671943664
avg_loss: 1.4362850737571717
avg_loss: 1.427356072664261
avg_loss: 1.4682532405853272
avg_loss: 1.3700143575668335
avg_loss: 1.4202853965759277
avg_loss: 1.4007685744762421
avg_loss: 1.4442464292049408
avg_loss: 1.4259323787689209
avg_loss: 1.3937388956546783
avg_loss: 1.3486551594734193
avg_loss: 1.3957668244838715
avg_loss: 1.4152979934215546
avg_loss: 1.351563822031021
avg_loss: 1.347491192817688
avg_loss: 1.3706379640102386
avg_loss: 1.3719404578208922
avg_loss: 1.3672741377353668
avg_loss: 1.3946598553657532
avg_loss: 1.4050680553913117
avg_loss: 1.4040753996372224
avg_loss: 1.3429596531391144
avg_loss: 1.4389079737663268
avg_loss: 1.396279240846634
avg_loss: 1.395140368938446
avg_loss: 1.3702751517295837
avg_loss: 1.3989907538890838
avg_loss: 1.4200619518756867
avg_loss: 1.4816932845115662
avg_loss: 1.4290244364738465
avg_loss: 1.40257141828537
avg_loss: 1.3827748465538026
avg_loss: 1.381195192337036
avg_loss: 1.3918410301208497
avg_loss: 1.4322239184379577
avg_loss: 1.410800851583481
avg_loss: 1.4696121573448182
avg_loss: 1.359720208644867
avg_loss: 1.4253660583496093
avg_loss: 1.3550406980514527
avg_loss: 1.4204110896587372
avg_loss: 1.3621052062511445
avg_loss: 1.4295233845710755
avg_loss: 1.4011865544319153
avg_loss: 1.433917897939682
avg_loss: 1.4475213050842286
avg_loss: 1.374666566848755
avg_loss: 1.3958250212669372
avg_loss: 1.4218487274646758
avg_loss: 1.4453112721443175
avg_loss: 1.4089072692394256
avg_loss: 1.39081813454628
avg_loss: 1.3641072916984558
avg_loss: 1.4334241843223572
avg_loss: 1.3945653212070466
avg_loss: 1.404194679260254
avg_loss: 1.4118475556373595
avg_loss: 1.4040342819690705
avg_loss: 1.376320561170578
avg_loss: 1.3422515499591827
avg_loss: 1.3572395861148834
avg_loss: 1.4430572545528413
Epoch:  70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                               | 7/10 [1:38:29<42:13, 844.44s/it]avg_loss: 1.3179389452934265
avg_loss: 1.3314635586738586
avg_loss: 1.2523874306678773
avg_loss: 1.2305283629894257
avg_loss: 1.2998422598838806
avg_loss: 1.266947466135025
avg_loss: 1.215912560224533
avg_loss: 1.2845437514781952
avg_loss: 1.2760093700885773
avg_loss: 1.2726976370811462
avg_loss: 1.2885942041873932
avg_loss: 1.2849929571151733
avg_loss: 1.2767139446735383
avg_loss: 1.2509971821308137
avg_loss: 1.2217996501922608
avg_loss: 1.277212780714035
avg_loss: 1.2934987020492554
avg_loss: 1.2801956582069396
avg_loss: 1.3088868355751038
avg_loss: 1.226000429391861
avg_loss: 1.2610162258148194
avg_loss: 1.2287061369419099
avg_loss: 1.2873983573913574
avg_loss: 1.243032146692276
avg_loss: 1.2480470657348632
avg_loss: 1.3290415060520173
avg_loss: 1.2556763112545013
avg_loss: 1.305300669670105
avg_loss: 1.3108559274673461
avg_loss: 1.2511790096759796
avg_loss: 1.2884237813949584
avg_loss: 1.315130624771118
avg_loss: 1.3137142598628997
avg_loss: 1.3034841978549958
avg_loss: 1.2587250065803528
avg_loss: 1.277455073595047
avg_loss: 1.3162955391407012
avg_loss: 1.2515884625911713
avg_loss: 1.267404386997223
avg_loss: 1.2435476386547089
avg_loss: 1.2671222400665283
avg_loss: 1.2960806536674498
avg_loss: 1.2477894389629365
avg_loss: 1.3250322902202607
avg_loss: 1.3451679956912994
avg_loss: 1.247190135717392
avg_loss: 1.256546550989151
avg_loss: 1.268299813270569
avg_loss: 1.3071889865398407
avg_loss: 1.285234055519104
avg_loss: 1.3140977573394776
avg_loss: 1.2465060150623322
avg_loss: 1.3134099793434144
avg_loss: 1.3157250952720643
avg_loss: 1.2692396748065948
avg_loss: 1.2758205902576447
avg_loss: 1.2510778653621673
avg_loss: 1.2244594931602477
avg_loss: 1.2443332040309907
avg_loss: 1.3450251865386962
avg_loss: 1.2859394967556
avg_loss: 1.2461160111427307
avg_loss: 1.3027223920822144
avg_loss: 1.2827155780792237
avg_loss: 1.324868162870407
avg_loss: 1.3458274948596953
avg_loss: 1.2986361396312713
avg_loss: 1.318783015012741
avg_loss: 1.279264236688614
avg_loss: 1.3094737255573272
avg_loss: 1.332682249546051
avg_loss: 1.2215857160091401
avg_loss: 1.2926111149787902
avg_loss: 1.2875589883327485
avg_loss: 1.3516710591316223
avg_loss: 1.3356144738197326
avg_loss: 1.3178827464580536
avg_loss: 1.2393194043636322
avg_loss: 1.2549569940567016
avg_loss: 1.2842738437652588
avg_loss: 1.289265285730362
avg_loss: 1.3023268508911132
avg_loss: 1.312970039844513
avg_loss: 1.2646581602096558
avg_loss: 1.278259619474411
avg_loss: 1.2542167174816132
avg_loss: 1.3099190425872802
avg_loss: 1.2968647289276123
avg_loss: 1.2641382253170013
avg_loss: 1.3280651938915253
avg_loss: 1.3677956366539001
avg_loss: 1.3036191809177398
avg_loss: 1.252737134695053
avg_loss: 1.3352922844886779
avg_loss: 1.2893420886993407
avg_loss: 1.2908100521564483
avg_loss: 1.3246993565559386
avg_loss: 1.312573754787445
avg_loss: 1.2248156726360322
avg_loss: 1.2851676201820375
avg_loss: 1.271763949394226
avg_loss: 1.2446116590499878
avg_loss: 1.1929997456073762
avg_loss: 1.298093546628952
avg_loss: 1.2715035951137543
avg_loss: 1.2703974735736847
avg_loss: 1.3065692222118377
Epoch:  80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 8/10 [1:52:34<28:09, 844.56s/it]avg_loss: 1.192806247472763
avg_loss: 1.2050861954689025
avg_loss: 1.1772649657726288
avg_loss: 1.1853130650520325
avg_loss: 1.1642768585681915
avg_loss: 1.1604124903678894
avg_loss: 1.2078894937038422
avg_loss: 1.2035357201099395
avg_loss: 1.204070806503296
avg_loss: 1.2255315637588502
avg_loss: 1.225632004737854
avg_loss: 1.1911879944801331
avg_loss: 1.1848962223529815
avg_loss: 1.2089019644260406
avg_loss: 1.2015071773529054
avg_loss: 1.159086058139801
avg_loss: 1.1869573605060577
avg_loss: 1.1592441403865814
avg_loss: 1.2040578174591063
avg_loss: 1.2233034026622773
avg_loss: 1.2123628211021424
avg_loss: 1.1931106877326965
avg_loss: 1.193770877122879
avg_loss: 1.1500978338718415
avg_loss: 1.176126980781555
avg_loss: 1.2103097224235535
avg_loss: 1.2153344011306764
avg_loss: 1.2241113996505737
avg_loss: 1.1879694747924805
avg_loss: 1.221387802362442
avg_loss: 1.241278076171875
avg_loss: 1.213636463880539
avg_loss: 1.2327020597457885
avg_loss: 1.2553959059715272
avg_loss: 1.1655156242847442
avg_loss: 1.1964993917942046
avg_loss: 1.1597209990024566
avg_loss: 1.2050847470760346
avg_loss: 1.209940572977066
avg_loss: 1.1677991127967835
avg_loss: 1.2266806268692017
avg_loss: 1.1591210126876832
avg_loss: 1.1826876986026764
avg_loss: 1.2463512468338012
avg_loss: 1.2165569126605988
avg_loss: 1.2215753149986268
avg_loss: 1.2569315016269684
avg_loss: 1.2409075284004212
avg_loss: 1.2132974886894226
avg_loss: 1.1941895353794099
avg_loss: 1.167080878019333
avg_loss: 1.1924919593334198
avg_loss: 1.2424094438552857
avg_loss: 1.213822491168976
avg_loss: 1.2517047035694122
avg_loss: 1.1972009432315827
avg_loss: 1.1517318522930144
avg_loss: 1.2005407953262328
avg_loss: 1.1897283685207367
avg_loss: 1.2143037045001983
avg_loss: 1.237667111158371
avg_loss: 1.2072761845588684
avg_loss: 1.1837461125850677
avg_loss: 1.2078718161582946
avg_loss: 1.211834192276001
avg_loss: 1.2560774874687195
avg_loss: 1.1994770741462708
avg_loss: 1.1749102079868317
avg_loss: 1.2015095710754395
avg_loss: 1.1979784882068634
avg_loss: 1.2255945646762847
avg_loss: 1.2018857538700103
avg_loss: 1.1720086002349854
avg_loss: 1.1993337404727935
avg_loss: 1.2139186024665833
avg_loss: 1.2191705584526062
avg_loss: 1.270774281024933
avg_loss: 1.2040966439247132
avg_loss: 1.1917868399620055
avg_loss: 1.2004510176181793
avg_loss: 1.222284927368164
avg_loss: 1.20026154756546
avg_loss: 1.178854364156723
avg_loss: 1.168357458114624
avg_loss: 1.1975276136398316
avg_loss: 1.1631305730342865
avg_loss: 1.1553230583667755
avg_loss: 1.237288295030594
avg_loss: 1.254905915260315
avg_loss: 1.1929451632499695
avg_loss: 1.1889717972278595
avg_loss: 1.1553056836128235
avg_loss: 1.2448401904106141
avg_loss: 1.230114551782608
avg_loss: 1.199092868566513
avg_loss: 1.2280176961421967
avg_loss: 1.2451897644996643
avg_loss: 1.1642326354980468
avg_loss: 1.196746518611908
avg_loss: 1.2301778304576874
avg_loss: 1.191635591983795
avg_loss: 1.2036441946029663
avg_loss: 1.189077136516571
avg_loss: 1.2243488240242004
avg_loss: 1.2365746927261352
avg_loss: 1.2107290375232695
avg_loss: 1.1914084005355834
Epoch:  90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏               | 9/10 [2:06:39<14:04, 844.69s/it]avg_loss: 1.1751441287994384
avg_loss: 1.1282044649124146
avg_loss: 1.1322796845436096
avg_loss: 1.1443519365787507
avg_loss: 1.129559783935547
avg_loss: 1.1394839763641358
avg_loss: 1.1587158560752868
avg_loss: 1.0851823937892915
avg_loss: 1.1543235969543457
avg_loss: 1.1296517753601074
avg_loss: 1.1664098501205444
avg_loss: 1.1816562461853026
avg_loss: 1.1248104119300841
avg_loss: 1.1364001297950745
avg_loss: 1.1571932411193848
avg_loss: 1.1313187670707703
avg_loss: 1.1977287709712983
avg_loss: 1.1640642666816712
avg_loss: 1.048944524526596
avg_loss: 1.1001444900035857
avg_loss: 1.1598639166355134
avg_loss: 1.143757050037384
avg_loss: 1.1850861120223999
avg_loss: 1.1180915927886963
avg_loss: 1.193952844142914
avg_loss: 1.1577315378189086
avg_loss: 1.2035231733322143
avg_loss: 1.1121322453022002
avg_loss: 1.1237851572036743
avg_loss: 1.1263022243976593
avg_loss: 1.1703015458583832
avg_loss: 1.1417074847221373
avg_loss: 1.171048458814621
avg_loss: 1.1294993233680726
avg_loss: 1.1696241068840028
avg_loss: 1.185738477706909
avg_loss: 1.159839768409729
avg_loss: 1.1729260277748108
avg_loss: 1.1544759726524354
avg_loss: 1.1680163371562957
avg_loss: 1.1054820120334625
avg_loss: 1.1261641430854796
avg_loss: 1.1594323050975799
avg_loss: 1.1575757658481598
avg_loss: 1.2075272870063782
avg_loss: 1.1773422157764435
avg_loss: 1.1771570122241974
avg_loss: 1.2046323490142823
avg_loss: 1.1557639467716216
avg_loss: 1.1686221933364869
avg_loss: 1.2034909701347352
avg_loss: 1.1148844861984253
avg_loss: 1.1186560082435608
avg_loss: 1.1305131256580352
avg_loss: 1.1375909185409545
avg_loss: 1.1051083290576935
avg_loss: 1.1220712959766388
avg_loss: 1.155916782617569
avg_loss: 1.1657269525527953
avg_loss: 1.1585490262508393
avg_loss: 1.1519484150409698
avg_loss: 1.2047385156154633
avg_loss: 1.1838184654712678
avg_loss: 1.145540702342987
avg_loss: 1.1356872344017028
avg_loss: 1.170107469558716
avg_loss: 1.1511944222450257
avg_loss: 1.1404871249198913
avg_loss: 1.1626533412933349
avg_loss: 1.1135318279266357
avg_loss: 1.0981354713439941
avg_loss: 1.1905599486827851
avg_loss: 1.1710078525543213
avg_loss: 1.1251744318008423
avg_loss: 1.1433561420440674
avg_loss: 1.180693258047104
avg_loss: 1.166366493701935
avg_loss: 1.1479810738563538
avg_loss: 1.1442459297180176
avg_loss: 1.1676170170307159
avg_loss: 1.1219681799411774
avg_loss: 1.1833745086193084
avg_loss: 1.1604254019260407
avg_loss: 1.1155758571624756
avg_loss: 1.1494826030731202
avg_loss: 1.1603770244121552
avg_loss: 1.1532366120815276
avg_loss: 1.1450560784339905
avg_loss: 1.144437974691391
avg_loss: 1.1892649006843568
avg_loss: 1.132666413784027
avg_loss: 1.1871425223350525
avg_loss: 1.2034645068645478
avg_loss: 1.0821263897418976
avg_loss: 1.130252673625946
avg_loss: 1.1691204166412354
avg_loss: 1.152399867773056
avg_loss: 1.0778839921951293
avg_loss: 1.1401412653923035
avg_loss: 1.165023148059845
avg_loss: 1.1734449315071105
avg_loss: 1.1636713564395904
avg_loss: 1.1294608867168427
avg_loss: 1.1465853893756865
avg_loss: 1.1134616994857789
avg_loss: 1.1293534207344056
avg_loss: 1.1881341803073884
Epoch: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [2:20:44<00:00, 844.98s/it]
+ cp configs/cbert_yelp_frequency_ratio.config run.config
+ PYTHONPATH=/home/xgg/pros/MLM_transfer
+ /home/xgg/.conda/envs/py36/bin//python fine_tune_cbert.py
03/12/2019 10:33:42 - WARNING - theano.configdefaults -   install mkl with `conda install mkl-service`: No module named 'mkl'
03/12/2019 10:33:42 - WARNING - theano.tensor.blas -   Using NumPy C-API based implementation for BLAS functions.
Traceback (most recent call last):
  File "fine_tune_cbert.py", line 18, in <module>
    from test_tools.yang_test_tool.cnntext_wd import tokenizer
  File "/home/xgg/pros/MLM_transfer/test_tools/yang_test_tool/cnntext_wd.py", line 28, in <module>
    model = load_model(cbert_name)
  File "/home/xgg/pros/MLM_transfer/test_tools/yang_test_tool/cnntext_wd.py", line 23, in load_model
    model = torch.load(weights_path)
  File "/home/xgg/.conda/envs/py36/lib/python3.6/site-packages/torch/serialization.py", line 366, in load
    f = open(f, 'rb')
FileNotFoundError: [Errno 2] No such file or directory: '/home/xgg/.pytorch_pretrained_bert/yelp/CBertForMaskedLM_yelp_epoch_10_frequency_ratio'
+ PYTHONPATH=/home/xgg/pros/MLM_transfer
+ /home/xgg/.conda/envs/py36/bin//python fine_tune_cbert_w_cls.py
03/12/2019 10:33:43 - WARNING - theano.configdefaults -   install mkl with `conda install mkl-service`: No module named 'mkl'
03/12/2019 10:33:43 - WARNING - theano.tensor.blas -   Using NumPy C-API based implementation for BLAS functions.
Traceback (most recent call last):
  File "fine_tune_cbert_w_cls.py", line 20, in <module>
    from test_tools.yang_test_tool.cnntext_wd import bert_embeddings, tokenizer
  File "/home/xgg/pros/MLM_transfer/test_tools/yang_test_tool/cnntext_wd.py", line 28, in <module>
    model = load_model(cbert_name)
  File "/home/xgg/pros/MLM_transfer/test_tools/yang_test_tool/cnntext_wd.py", line 23, in load_model
    model = torch.load(weights_path)
  File "/home/xgg/.conda/envs/py36/lib/python3.6/site-packages/torch/serialization.py", line 366, in load
    f = open(f, 'rb')
FileNotFoundError: [Errno 2] No such file or directory: '/home/xgg/.pytorch_pretrained_bert/yelp/CBertForMaskedLM_yelp_epoch_10_frequency_ratio'
[01;32mxgg@decs[00m:[01;34m~/pros/MLM_transfer[00m$ bash scripts/frequency_ratio/fine_tune_yelp_frequency_ratio.sh [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython train_ae.py [K-W ignoresudo apt-get install trickle[6Ppc ping www.google.com[6Pwww.baidu.com[Kvim aug_dataset.py ls[Kcd cbert_aug/ls[Kcd pros/la[Kpython aug_dataset.py [3Pvim[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[3@python[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[4Pcat global.config[C[1@vim aug_dataset.py[C[1Pcat global.config[C[4@python aug_dataset.py[C[5@finetune[C[C[C[C[C[C[C[C[C[C[C[C[5@train_text_classifier[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1Pvim args_of[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1@python train[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1Pvim args_of[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1@python train[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[5Pfinetune_dataset[C[C[C[C[5Paug[C[C[C[C[C[C[C[C[C[C[C[C[4Pcat global.config[C[1@vim aug_dataset.py[C[1Pcat global.config[C[4@python aug_dataset.py[C[3Pvim[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[3@python[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cla[Kcd pros/ls[Kcd cbert_aug/ls[Kvim aug_dataset.py pc[K www.baidu.comping www.google.comsudo apt-get install tricklepython train_ae.py -W ignore[K[44@bash scripts/frequency_ratio/fine_tune_yelp_frequency_ratio.sh[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Kbash scripts/frequency_ratio/fine_tune_yelp_frequency_ratio.sh [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython train_ae.py [K[44@bash scripts/frequency_ratio/fine_tune_yelp_frequency_ratio.sh[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Kbash scripts/frequency_ratio/fine_tune_yelp_frequency_ratio.sh 
+ PROJECTPATH=/home/xgg/pros/MLM_transfer
+ cp configs/cbert_yelp_frequency_ratio.config run.config
+ PYTHONPATH=/home/xgg/pros/MLM_transfer
+ /home/xgg/.conda/envs/py36/bin//python fine_tune_cbert.py
03/12/2019 16:49:40 - WARNING - theano.configdefaults -   install mkl with `conda install mkl-service`: No module named 'mkl'
03/12/2019 16:49:40 - WARNING - theano.tensor.blas -   Using NumPy C-API based implementation for BLAS functions.
03/12/2019 16:49:40 - INFO - dataloader -   device cuda n_gpu 1 distributed training False
03/12/2019 16:49:41 - INFO - dataloader -   *** Example ***
03/12/2019 16:49:41 - INFO - dataloader -   guid: train-1
03/12/2019 16:49:41 - INFO - dataloader -   tokens: [CLS] always a great place to stop by in the mall . [SEP]
03/12/2019 16:49:41 - INFO - dataloader -   init_ids: 101 2467 1037 2307 2173 2000 2644 2011 1999 1996 6670 1012 102
03/12/2019 16:49:41 - INFO - dataloader -   input_ids: 101 103 103 103 103 103 103 2011 1999 1996 6670 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 16:49:41 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 16:49:41 - INFO - dataloader -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 16:49:41 - INFO - dataloader -   masked_lm_labels: -1 2467 1037 2307 2173 2000 2644 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 16:49:41 - INFO - dataloader -   *** Example ***
03/12/2019 16:49:41 - INFO - dataloader -   guid: train-2
03/12/2019 16:49:41 - INFO - dataloader -   tokens: [CLS] the food is good for inexpensive chinese food . [SEP]
03/12/2019 16:49:41 - INFO - dataloader -   init_ids: 101 1996 2833 2003 2204 2005 23766 2822 2833 1012 102
03/12/2019 16:49:41 - INFO - dataloader -   input_ids: 101 103 103 103 103 2005 23766 2822 2833 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 16:49:41 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 16:49:41 - INFO - dataloader -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 16:49:41 - INFO - dataloader -   masked_lm_labels: -1 1996 2833 2003 2204 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 16:49:41 - INFO - dataloader -   *** Example ***
03/12/2019 16:49:41 - INFO - dataloader -   guid: train-3
03/12/2019 16:49:41 - INFO - dataloader -   tokens: [CLS] i would highly recommend taking your car here . [SEP]
03/12/2019 16:49:41 - INFO - dataloader -   init_ids: 101 1045 2052 3811 16755 2635 2115 2482 2182 1012 102
03/12/2019 16:49:41 - INFO - dataloader -   input_ids: 101 103 103 103 103 2635 2115 2482 2182 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 16:49:41 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 16:49:41 - INFO - dataloader -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 16:49:41 - INFO - dataloader -   masked_lm_labels: -1 1045 2052 3811 16755 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 16:49:41 - INFO - dataloader -   *** Example ***
03/12/2019 16:49:41 - INFO - dataloader -   guid: train-4
03/12/2019 16:49:41 - INFO - dataloader -   tokens: [CLS] my husband had the chile re ##llen ##o and thought it was amazing . [SEP]
03/12/2019 16:49:41 - INFO - dataloader -   init_ids: 101 2026 3129 2018 1996 7029 2128 12179 2080 1998 2245 2009 2001 6429 1012 102
03/12/2019 16:49:41 - INFO - dataloader -   input_ids: 101 2026 3129 2018 1996 7029 2128 12179 2080 103 103 103 103 6429 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 16:49:41 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 16:49:41 - INFO - dataloader -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 16:49:41 - INFO - dataloader -   masked_lm_labels: -1 -1 -1 -1 -1 -1 -1 -1 -1 1998 2245 2009 2001 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 16:49:41 - INFO - dataloader -   *** Example ***
03/12/2019 16:49:41 - INFO - dataloader -   guid: train-5
03/12/2019 16:49:41 - INFO - dataloader -   tokens: [CLS] my second bad experience at a t ##gi fridays . [SEP]
03/12/2019 16:49:41 - INFO - dataloader -   init_ids: 101 2026 2117 2919 3325 2012 1037 1056 5856 26587 1012 102
03/12/2019 16:49:41 - INFO - dataloader -   input_ids: 101 2026 2117 103 103 103 1037 1056 5856 26587 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 16:49:41 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 16:49:41 - INFO - dataloader -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 16:49:41 - INFO - dataloader -   masked_lm_labels: -1 -1 -1 2919 3325 2012 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 16:50:08 - INFO - dataloader -   ***** Running training *****
03/12/2019 16:50:08 - INFO - dataloader -     Num examples = 172670
03/12/2019 16:50:08 - INFO - dataloader -     Batch size = 32
03/12/2019 16:50:08 - INFO - dataloader -     Num steps = 53959
**********************************************************
Namespace(bert_model='/home/xgg/.pytorch_pretrained_bert/bert-base-uncased.tar.gz', data_dir='./processed_data_frequency_ratio/yelp/', do_lower_case=True, do_train=True, eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, loss_scale=128, max_seq_length=32, no_cuda=False, num_train_epochs=10.0, optimize_on_cpu=False, output_dir='/tmp/yelp_output/', seed=42, task_name=None, train_batch_size=32, warmup_proportion=0.1)
Epoch:   0%|                                                                                                                                                                         | 0/10 [00:00<?, ?it/s]avg_loss: 1.1708188438415528
avg_loss: 1.1876452684402465
avg_loss: 1.164333803653717
avg_loss: 1.0992263233661652
avg_loss: 1.111788558959961
avg_loss: 1.1576966774463653
avg_loss: 1.1325612413883208
avg_loss: 1.109874699115753
avg_loss: 1.1249351012706756
avg_loss: 1.1264882755279542
avg_loss: 1.139634507894516
avg_loss: 1.1721872234344481
avg_loss: 1.1191127800941467
avg_loss: 1.1178264701366425
avg_loss: 1.1283357489109038
avg_loss: 1.100308097600937
avg_loss: 1.1661762273311616
avg_loss: 1.1438226330280303
avg_loss: 1.1367768478393554
avg_loss: 1.1234539079666137
avg_loss: 1.1161723232269287
avg_loss: 1.1269633322954178
avg_loss: 1.1312318444252014
avg_loss: 1.1587088537216186
avg_loss: 1.2056647527217865
avg_loss: 1.1403339171409608
avg_loss: 1.1691889774799347
avg_loss: 1.1548499166965485
avg_loss: 1.1538767957687377
avg_loss: 1.1421810007095337
avg_loss: 1.1252161478996277
avg_loss: 1.1950197052955627
avg_loss: 1.174440346956253
avg_loss: 1.1486162543296814
avg_loss: 1.1127178728580476
avg_loss: 1.1262533473968506
avg_loss: 1.1585819256305694
avg_loss: 1.1787037253379822
avg_loss: 1.206648508310318
avg_loss: 1.1590558254718781
avg_loss: 1.1955988609790802
avg_loss: 1.1949387514591217
avg_loss: 1.1573194003105163
avg_loss: 1.1857199704647063
avg_loss: 1.2358782577514649
avg_loss: 1.1944692301750184
avg_loss: 1.1333047544956207
avg_loss: 1.1482027184963226
avg_loss: 1.1185941255092622
avg_loss: 1.1953093457221984
avg_loss: 1.2520196735858917
avg_loss: 1.1515305972099303
avg_loss: 1.1598482930660248
avg_loss: 1.2155776035785675
avg_loss: 1.183452445268631
avg_loss: 1.166556168794632
avg_loss: 1.2141256201267243
avg_loss: 1.2000837981700898
avg_loss: 1.2215234792232514
avg_loss: 1.2284460949897766
avg_loss: 1.1895672464370728
avg_loss: 1.1811022877693176
avg_loss: 1.2021211981773376
avg_loss: 1.1989059031009675
avg_loss: 1.1730009615421295
avg_loss: 1.1596795225143433
avg_loss: 1.1753459906578063
avg_loss: 1.2235981488227845
avg_loss: 1.1917838501930236
avg_loss: 1.1849622297286988
avg_loss: 1.198795976638794
avg_loss: 1.225543885231018
avg_loss: 1.2467286002635956
avg_loss: 1.2120329606533051
avg_loss: 1.2275571131706238
avg_loss: 1.2568227028846741
avg_loss: 1.191378561258316
avg_loss: 1.2367530572414398
avg_loss: 1.1604331207275391
avg_loss: 1.189871973991394
avg_loss: 1.2646233439445496
avg_loss: 1.1556057238578796
avg_loss: 1.2453863835334777
avg_loss: 1.30159015417099
avg_loss: 1.2535599064826966
avg_loss: 1.2327035319805146
avg_loss: 1.2289893269538879
avg_loss: 1.2168700003623962
avg_loss: 1.2823884999752044
avg_loss: 1.2594207477569581
avg_loss: 1.269613174200058
avg_loss: 1.252039865255356
avg_loss: 1.23742351770401
avg_loss: 1.2297188127040863
avg_loss: 1.2827550017833709
avg_loss: 1.265834822654724
avg_loss: 1.31695925116539
avg_loss: 1.2478806591033935
avg_loss: 1.23376091837883
avg_loss: 1.2627351403236389
avg_loss: 1.270243158340454
avg_loss: 1.2740100300312043
avg_loss: 1.3214961409568786
avg_loss: 1.31805961728096
avg_loss: 1.2993903398513793
avg_loss: 1.2602406108379365
avg_loss: 1.2494363236427306
{"dev acc"：0.35244622766809647}
Traceback (most recent call last):
  File "fine_tune_cbert.py", line 160, in <module>
    main()
  File "fine_tune_cbert.py", line 129, in main
    bleu_0 = eval_bleu(generate_file=generate_file_0, orgin_file=orgin_file_0)
  File "/home/xgg/pros/MLM_transfer/test_tools/li_test_tool/BLEU/my_bleu_evaluate.py", line 109, in eval_bleu
    f=open(orgin_file,'r') #orgin_file
FileNotFoundError: [Errno 2] No such file or directory: 'evaluation/outputs/yelp/sentiment.test.0.human'
Exception ignored in: <bound method tqdm.__del__ of Epoch:   0%|                                                                                                                                                                         | 0/10 [14:56<?, ?it/s]>
Traceback (most recent call last):
  File "/home/xgg/.conda/envs/py36/lib/python3.6/site-packages/tqdm/_tqdm.py", line 931, in __del__
    self.close()
  File "/home/xgg/.conda/envs/py36/lib/python3.6/site-packages/tqdm/_tqdm.py", line 1133, in close
    self._decr_instances(self)
  File "/home/xgg/.conda/envs/py36/lib/python3.6/site-packages/tqdm/_tqdm.py", line 496, in _decr_instances
    cls.monitor.exit()
  File "/home/xgg/.conda/envs/py36/lib/python3.6/site-packages/tqdm/_monitor.py", line 52, in exit
    self.join()
  File "/home/xgg/.conda/envs/py36/lib/python3.6/threading.py", line 1053, in join
    raise RuntimeError("cannot join current thread")
RuntimeError: cannot join current thread
+ PYTHONPATH=/home/xgg/pros/MLM_transfer
+ /home/xgg/.conda/envs/py36/bin//python fine_tune_cbert_w_cls.py
03/12/2019 17:05:09 - WARNING - theano.configdefaults -   install mkl with `conda install mkl-service`: No module named 'mkl'
03/12/2019 17:05:09 - WARNING - theano.tensor.blas -   Using NumPy C-API based implementation for BLAS functions.
Traceback (most recent call last):
  File "fine_tune_cbert_w_cls.py", line 20, in <module>
    from test_tools.yang_test_tool.cnntext_wd import bert_embeddings, tokenizer
  File "/home/xgg/pros/MLM_transfer/test_tools/yang_test_tool/cnntext_wd.py", line 28, in <module>
    model = load_model(cbert_name)
  File "/home/xgg/pros/MLM_transfer/test_tools/yang_test_tool/cnntext_wd.py", line 23, in load_model
    model = torch.load(weights_path)
  File "/home/xgg/.conda/envs/py36/lib/python3.6/site-packages/torch/serialization.py", line 366, in load
    f = open(f, 'rb')
FileNotFoundError: [Errno 2] No such file or directory: '/home/xgg/.pytorch_pretrained_bert/yelp/CBertForMaskedLM_yelp_epoch_10_frequency_ratio'
[01;32mxgg@decs[00m:[01;34m~/pros/MLM_transfer[00m$ bash scripts/frequency_ratio/fine_tune_yelp_frequency_ratio.sh 
+ PROJECTPATH=/home/xgg/pros/MLM_transfer
+ cp configs/cbert_yelp_frequency_ratio.config run.config
+ PYTHONPATH=/home/xgg/pros/MLM_transfer
+ /home/xgg/.conda/envs/py36/bin//python fine_tune_cbert.py
03/12/2019 17:11:12 - WARNING - theano.configdefaults -   install mkl with `conda install mkl-service`: No module named 'mkl'
03/12/2019 17:11:12 - WARNING - theano.tensor.blas -   Using NumPy C-API based implementation for BLAS functions.
03/12/2019 17:11:12 - INFO - dataloader -   device cuda n_gpu 1 distributed training False
03/12/2019 17:11:13 - INFO - dataloader -   *** Example ***
03/12/2019 17:11:13 - INFO - dataloader -   guid: train-1
03/12/2019 17:11:13 - INFO - dataloader -   tokens: [CLS] always a great place to stop by in the mall . [SEP]
03/12/2019 17:11:13 - INFO - dataloader -   init_ids: 101 2467 1037 2307 2173 2000 2644 2011 1999 1996 6670 1012 102
03/12/2019 17:11:13 - INFO - dataloader -   input_ids: 101 103 103 103 103 103 103 2011 1999 1996 6670 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 17:11:13 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 17:11:13 - INFO - dataloader -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 17:11:13 - INFO - dataloader -   masked_lm_labels: -1 2467 1037 2307 2173 2000 2644 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 17:11:13 - INFO - dataloader -   *** Example ***
03/12/2019 17:11:13 - INFO - dataloader -   guid: train-2
03/12/2019 17:11:13 - INFO - dataloader -   tokens: [CLS] the food is good for inexpensive chinese food . [SEP]
03/12/2019 17:11:13 - INFO - dataloader -   init_ids: 101 1996 2833 2003 2204 2005 23766 2822 2833 1012 102
03/12/2019 17:11:13 - INFO - dataloader -   input_ids: 101 103 103 103 103 2005 23766 2822 2833 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 17:11:13 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 17:11:13 - INFO - dataloader -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 17:11:13 - INFO - dataloader -   masked_lm_labels: -1 1996 2833 2003 2204 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 17:11:13 - INFO - dataloader -   *** Example ***
03/12/2019 17:11:13 - INFO - dataloader -   guid: train-3
03/12/2019 17:11:13 - INFO - dataloader -   tokens: [CLS] i would highly recommend taking your car here . [SEP]
03/12/2019 17:11:13 - INFO - dataloader -   init_ids: 101 1045 2052 3811 16755 2635 2115 2482 2182 1012 102
03/12/2019 17:11:13 - INFO - dataloader -   input_ids: 101 103 103 103 103 2635 2115 2482 2182 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 17:11:13 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 17:11:13 - INFO - dataloader -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 17:11:13 - INFO - dataloader -   masked_lm_labels: -1 1045 2052 3811 16755 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 17:11:13 - INFO - dataloader -   *** Example ***
03/12/2019 17:11:13 - INFO - dataloader -   guid: train-4
03/12/2019 17:11:13 - INFO - dataloader -   tokens: [CLS] my husband had the chile re ##llen ##o and thought it was amazing . [SEP]
03/12/2019 17:11:13 - INFO - dataloader -   init_ids: 101 2026 3129 2018 1996 7029 2128 12179 2080 1998 2245 2009 2001 6429 1012 102
03/12/2019 17:11:13 - INFO - dataloader -   input_ids: 101 2026 3129 2018 1996 7029 2128 12179 2080 103 103 103 103 6429 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 17:11:13 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 17:11:13 - INFO - dataloader -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 17:11:13 - INFO - dataloader -   masked_lm_labels: -1 -1 -1 -1 -1 -1 -1 -1 -1 1998 2245 2009 2001 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 17:11:13 - INFO - dataloader -   *** Example ***
03/12/2019 17:11:13 - INFO - dataloader -   guid: train-5
03/12/2019 17:11:13 - INFO - dataloader -   tokens: [CLS] my second bad experience at a t ##gi fridays . [SEP]
03/12/2019 17:11:13 - INFO - dataloader -   init_ids: 101 2026 2117 2919 3325 2012 1037 1056 5856 26587 1012 102
03/12/2019 17:11:13 - INFO - dataloader -   input_ids: 101 2026 2117 103 103 103 1037 1056 5856 26587 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 17:11:13 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 17:11:13 - INFO - dataloader -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 17:11:13 - INFO - dataloader -   masked_lm_labels: -1 -1 -1 2919 3325 2012 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 17:11:40 - INFO - dataloader -   ***** Running training *****
03/12/2019 17:11:40 - INFO - dataloader -     Num examples = 172670
03/12/2019 17:11:40 - INFO - dataloader -     Batch size = 32
03/12/2019 17:11:40 - INFO - dataloader -     Num steps = 53959
**********************************************************
Namespace(bert_model='/home/xgg/.pytorch_pretrained_bert/bert-base-uncased.tar.gz', data_dir='./processed_data_frequency_ratio/yelp/', do_lower_case=True, do_train=True, eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, loss_scale=128, max_seq_length=32, no_cuda=False, num_train_epochs=10.0, optimize_on_cpu=False, output_dir='/tmp/yelp_output/', seed=42, task_name=None, train_batch_size=32, warmup_proportion=0.1)
Epoch:   0%|                                                                                                                                                                         | 0/10 [00:00<?, ?it/s]avg_loss: 1.1708188438415528
avg_loss: 1.1876452684402465
avg_loss: 1.164333803653717
avg_loss: 1.0992263233661652
avg_loss: 1.111788558959961
avg_loss: 1.1576966774463653
avg_loss: 1.1325612413883208
avg_loss: 1.109874699115753
avg_loss: 1.1249351012706756
avg_loss: 1.1264882755279542
avg_loss: 1.139634507894516
avg_loss: 1.1721872234344481
avg_loss: 1.1191127800941467
avg_loss: 1.1178264701366425
avg_loss: 1.1283357489109038
avg_loss: 1.100308097600937
avg_loss: 1.1661762273311616
avg_loss: 1.1438226330280303
avg_loss: 1.1367768478393554
avg_loss: 1.1234539079666137
avg_loss: 1.1161723232269287
avg_loss: 1.1269633322954178
avg_loss: 1.1312318444252014
avg_loss: 1.1587088537216186
avg_loss: 1.2056647527217865
avg_loss: 1.1403339171409608
avg_loss: 1.1691889774799347
avg_loss: 1.1548499166965485
avg_loss: 1.1538767957687377
avg_loss: 1.1421810007095337
avg_loss: 1.1252161478996277
avg_loss: 1.1950197052955627
avg_loss: 1.174440346956253
avg_loss: 1.1486162543296814
avg_loss: 1.1127178728580476
avg_loss: 1.1262533473968506
avg_loss: 1.1585819256305694
avg_loss: 1.1787037253379822
avg_loss: 1.206648508310318
avg_loss: 1.1590558254718781
avg_loss: 1.1955988609790802
avg_loss: 1.1949387514591217
avg_loss: 1.1573194003105163
avg_loss: 1.1857199704647063
avg_loss: 1.2358782577514649
avg_loss: 1.1944692301750184
avg_loss: 1.1333047544956207
avg_loss: 1.1482027184963226
avg_loss: 1.1185941255092622
avg_loss: 1.1953093457221984
avg_loss: 1.2520196735858917
avg_loss: 1.1515305972099303
avg_loss: 1.1598482930660248
avg_loss: 1.2155776035785675
avg_loss: 1.183452445268631
avg_loss: 1.166556168794632
avg_loss: 1.2141256201267243
avg_loss: 1.2000837981700898
avg_loss: 1.2215234792232514
avg_loss: 1.2284460949897766
avg_loss: 1.1895672464370728
avg_loss: 1.1811022877693176
avg_loss: 1.2021211981773376
avg_loss: 1.1989059031009675
avg_loss: 1.1730009615421295
avg_loss: 1.1596795225143433
avg_loss: 1.1753459906578063
avg_loss: 1.2235981488227845
avg_loss: 1.1917838501930236
avg_loss: 1.1849622297286988
avg_loss: 1.198795976638794
avg_loss: 1.225543885231018
avg_loss: 1.2467286002635956
avg_loss: 1.2120329606533051
avg_loss: 1.2275571131706238
avg_loss: 1.2568227028846741
avg_loss: 1.191378561258316
avg_loss: 1.2367530572414398
avg_loss: 1.1604331207275391
avg_loss: 1.189871973991394
avg_loss: 1.2646233439445496
avg_loss: 1.1556057238578796
avg_loss: 1.2453863835334777
avg_loss: 1.30159015417099
avg_loss: 1.2535599064826966
avg_loss: 1.2327035319805146
avg_loss: 1.2289893269538879
avg_loss: 1.2168700003623962
avg_loss: 1.2823884999752044
avg_loss: 1.2594207477569581
avg_loss: 1.269613174200058
avg_loss: 1.252039865255356
avg_loss: 1.23742351770401
avg_loss: 1.2297188127040863
avg_loss: 1.2827550017833709
avg_loss: 1.265834822654724
avg_loss: 1.31695925116539
avg_loss: 1.2478806591033935
avg_loss: 1.23376091837883
avg_loss: 1.2627351403236389
avg_loss: 1.270243158340454
avg_loss: 1.2740100300312043
avg_loss: 1.3214961409568786
avg_loss: 1.31805961728096
avg_loss: 1.2993903398513793
avg_loss: 1.2602406108379365
avg_loss: 1.2494363236427306
{"dev acc"：0.35244622766809647}
{"bleu_0": 0.13507187678133475, "bleu_1": 0.12783998341252387, "bleu_avg": 0.1314559300969293}
{"acc_0": 0.45399999999999996, "acc_1": 0.33199999999999996, "acc_avg": 0.39299999999999996}
Epoch:  10%|███████████████▊                                                                                                                                              | 1/10 [15:04<2:15:38, 904.24s/it]avg_loss: 1.1355621361732482
avg_loss: 1.127882878780365
avg_loss: 1.1258419132232667
avg_loss: 1.1295847916603088
avg_loss: 1.1038359236717223
avg_loss: 1.0875862264633178
avg_loss: 1.120912253856659
avg_loss: 1.1299883282184602
avg_loss: 1.0654504358768464
avg_loss: 1.1917484557628633
avg_loss: 1.1227378857135772
avg_loss: 1.1302353644371033
avg_loss: 1.1584456479549408
avg_loss: 1.1103366255760192
avg_loss: 1.1359989619255066
avg_loss: 1.1255616438388825
avg_loss: 1.140540384054184
avg_loss: 1.1099952840805054
avg_loss: 1.1947846591472626
avg_loss: 1.1751642274856566
avg_loss: 1.0994279515743255
avg_loss: 1.1054242646694183
avg_loss: 1.155484617948532
avg_loss: 1.1623719477653502
avg_loss: 1.2091731476783751
avg_loss: 1.1183639311790465
avg_loss: 1.173128032684326
avg_loss: 1.1778864240646363
avg_loss: 1.1579478973150252
avg_loss: 1.159047122001648
avg_loss: 1.1375025343894958
avg_loss: 1.148701730966568
avg_loss: 1.1509441089630128
avg_loss: 1.1401722621917725
avg_loss: 1.1991730260848998
avg_loss: 1.1859536910057067
avg_loss: 1.1104558777809144
avg_loss: 1.1984533452987671
avg_loss: 1.14526832818985
avg_loss: 1.1431999480724335
avg_loss: 1.192276451587677
avg_loss: 1.2178669905662536
avg_loss: 1.181480165719986
avg_loss: 1.1856090724468231
avg_loss: 1.16778746008873
avg_loss: 1.1461370027065276
avg_loss: 1.1957466208934784
avg_loss: 1.1302809953689574
avg_loss: 1.197459533214569
avg_loss: 1.1311760413646699
avg_loss: 1.1378727126121522
avg_loss: 1.1772111392021178
avg_loss: 1.2107537686824799
avg_loss: 1.2371743595600129
avg_loss: 1.2007903850078583
avg_loss: 1.1988227105140685
avg_loss: 1.149528466463089
avg_loss: 1.1790016746520997
avg_loss: 1.1972644221782685
avg_loss: 1.1929804694652557
avg_loss: 1.1776205480098725
avg_loss: 1.170427680015564
avg_loss: 1.190037282705307
avg_loss: 1.1661893463134765
avg_loss: 1.1510708832740784
avg_loss: 1.1631528663635253
avg_loss: 1.184904854297638
avg_loss: 1.2711834228038787
avg_loss: 1.1995338630676269
avg_loss: 1.1793227803707123
avg_loss: 1.1447007501125335
avg_loss: 1.1993340694904326
avg_loss: 1.2219370377063752
avg_loss: 1.2210209798812866
avg_loss: 1.1719670045375823
avg_loss: 1.2072247409820556
avg_loss: 1.157828040122986
avg_loss: 1.185531543493271
avg_loss: 1.139180176258087
avg_loss: 1.2056567347049714
avg_loss: 1.246183569431305
avg_loss: 1.255158132314682
avg_loss: 1.1917831528186797
avg_loss: 1.19998575091362
avg_loss: 1.1955476629734039
avg_loss: 1.1955446326732635
avg_loss: 1.2190487849712373
avg_loss: 1.2188436472415924
avg_loss: 1.2067917108535766
avg_loss: 1.2391445112228394
avg_loss: 1.1808347368240357
avg_loss: 1.179211313724518
avg_loss: 1.1554267454147338
avg_loss: 1.2221736657619475
avg_loss: 1.1946322154998779
avg_loss: 1.2153894698619843
avg_loss: 1.1681328809261322
avg_loss: 1.2359326803684234
avg_loss: 1.2022489273548127
avg_loss: 1.2586003518104554
avg_loss: 1.1947127997875213
avg_loss: 1.2056096589565277
avg_loss: 1.1674174082279205
avg_loss: 1.2141178286075591
avg_loss: 1.205524355173111
avg_loss: 1.2237133586406708
avg_loss: 1.2014890861511232
{"dev acc"：0.4211792249441973}
{"bleu_0": 0.13418774681611884, "bleu_1": 0.1296694218284088, "bleu_avg": 0.13192858432226381}
{"acc_0": 0.526, "acc_1": 0.46399999999999997, "acc_avg": 0.495}
Epoch:  20%|███████████████████████████████▌                                                                                                                              | 2/10 [30:07<2:00:31, 903.95s/it]avg_loss: 0.9939444875717163
avg_loss: 0.9546691769361496
avg_loss: 0.976248220205307
avg_loss: 0.9748606383800507
avg_loss: 0.9772903680801391
avg_loss: 0.9759260696172715
avg_loss: 1.0043445599079133
avg_loss: 0.9609867656230926
avg_loss: 1.0207861256599426
avg_loss: 0.9896726906299591
avg_loss: 1.0010794174671174
avg_loss: 0.9488181734085083
avg_loss: 1.0663797092437743
avg_loss: 0.9977843832969665
avg_loss: 0.9954727125167847
avg_loss: 1.0321712565422059
avg_loss: 0.9970489871501923
avg_loss: 1.0069494557380676
avg_loss: 0.9672051310539246
avg_loss: 0.9953720760345459
avg_loss: 0.9724613118171692
avg_loss: 1.027427761554718
avg_loss: 0.9682586824893952
avg_loss: 0.9821849846839905
avg_loss: 0.9679946458339691
avg_loss: 0.9861012434959412
avg_loss: 0.9836314129829407
avg_loss: 0.967526832818985
avg_loss: 0.97044154047966
avg_loss: 1.0083928847312926
avg_loss: 1.0414008677005768
avg_loss: 0.9650044226646424
avg_loss: 0.9921579980850219
avg_loss: 0.9830120003223419
avg_loss: 1.0484885847568512
avg_loss: 0.9882602691650391
avg_loss: 0.9909085488319397
avg_loss: 0.9781576240062714
avg_loss: 0.990369484424591
avg_loss: 1.0147313868999481
avg_loss: 1.0141774713993073
avg_loss: 1.0189339053630828
avg_loss: 0.9931893229484559
avg_loss: 1.0133753263950347
avg_loss: 1.026067773103714
avg_loss: 0.971542477607727
avg_loss: 1.0140633749961854
avg_loss: 1.0033260357379914
avg_loss: 1.0040165483951569
avg_loss: 1.009780877828598
avg_loss: 1.0553581929206848
avg_loss: 1.0356941628456116
avg_loss: 1.0069729137420653
avg_loss: 1.024059933423996
avg_loss: 1.0330877208709717
avg_loss: 1.0100024437904358
avg_loss: 0.9673677122592926
avg_loss: 0.9873426949977875
avg_loss: 1.0055651772022247
avg_loss: 1.0225033640861512
avg_loss: 1.0021831142902373
avg_loss: 0.9815471756458283
avg_loss: 0.9823284363746643
avg_loss: 0.9538649106025696
avg_loss: 0.9701322543621064
avg_loss: 0.9948824381828308
avg_loss: 1.0105712461471557
avg_loss: 1.028085161447525
avg_loss: 1.0252272081375122
avg_loss: 1.0413247346878052
avg_loss: 1.0172604548931121
avg_loss: 1.076631124019623
avg_loss: 1.007556858062744
avg_loss: 1.015411561727524
avg_loss: 0.9998318195343018
avg_loss: 1.0062498235702515
avg_loss: 1.0120145714282989
avg_loss: 1.0847616255283357
avg_loss: 1.0054246473312378
avg_loss: 1.0105289113521576
avg_loss: 1.0493970203399658
avg_loss: 1.019068305492401
avg_loss: 1.0588347816467285
avg_loss: 1.0137867963314056
avg_loss: 1.023431557416916
avg_loss: 1.0789418971538545
avg_loss: 1.0319564759731292
avg_loss: 1.0422271418571472
avg_loss: 1.024483208656311
avg_loss: 1.0166391932964325
avg_loss: 1.0371357190608979
avg_loss: 0.9766954779624939
avg_loss: 1.0383619618415834
avg_loss: 1.0502933764457703
avg_loss: 1.0484521090984344
avg_loss: 1.0417093706130982
avg_loss: 1.0634552943706512
avg_loss: 1.0493955528736114
avg_loss: 1.0424390387535096
avg_loss: 1.0430272448062896
avg_loss: 1.0827634680271148
avg_loss: 1.0750850820541382
avg_loss: 1.0117146348953248
avg_loss: 1.0599207949638367
avg_loss: 1.0374203824996948
avg_loss: 1.0395683121681214
avg_loss: 1.042340214252472
{"dev acc"：0.45298373452979407}
{"bleu_0": 0.1348127145280005, "bleu_1": 0.1278488724743694, "bleu_avg": 0.13133079350118496}
{"acc_0": 0.494, "acc_1": 0.494, "acc_avg": 0.494}
Epoch:  30%|███████████████████████████████████████████████▍                                                                                                              | 3/10 [45:10<1:45:25, 903.65s/it]avg_loss: 0.8637199580669404
avg_loss: 0.8369121724367141
avg_loss: 0.8372970229387283
avg_loss: 0.8398100864887238
avg_loss: 0.8234244221448899
avg_loss: 0.8375026720762253
avg_loss: 0.8631099200248719
avg_loss: 0.8625756841897965
avg_loss: 0.873234897851944
avg_loss: 0.8321881425380707
avg_loss: 0.8622723376750946
avg_loss: 0.8543748426437378
avg_loss: 0.8057077485322952
avg_loss: 0.8231903517246246
avg_loss: 0.8167247706651688
avg_loss: 0.8014182895421982
avg_loss: 0.8445453321933747
avg_loss: 0.8756194198131562
avg_loss: 0.8365119302272797
avg_loss: 0.8487912964820862
avg_loss: 0.8358769327402115
avg_loss: 0.8732200503349304
avg_loss: 0.8680807387828827
avg_loss: 0.8771576488018036
avg_loss: 0.8524623525142669
avg_loss: 0.8448654079437256
avg_loss: 0.8099035561084748
avg_loss: 0.8314102292060852
avg_loss: 0.8493324476480484
avg_loss: 0.8069395041465759
avg_loss: 0.8351058351993561
avg_loss: 0.8715234446525574
avg_loss: 0.9064471542835235
avg_loss: 0.8650456809997559
avg_loss: 0.887548623085022
avg_loss: 0.8364180034399032
avg_loss: 0.88126624584198
avg_loss: 0.8278812646865845
avg_loss: 0.8509494233131408
avg_loss: 0.8704034852981567
avg_loss: 0.9051437211036683
avg_loss: 0.8833013868331909
avg_loss: 0.8535208940505982
avg_loss: 0.8375784480571746
avg_loss: 0.849972299337387
avg_loss: 0.892440973520279
avg_loss: 0.9112979650497437
avg_loss: 0.9194026637077332
avg_loss: 0.8543004816770554
avg_loss: 0.8718997716903687
avg_loss: 0.9151169669628143
avg_loss: 0.8985117661952973
avg_loss: 0.888414546251297
avg_loss: 0.8517888158559799
avg_loss: 0.8799375921487809
avg_loss: 0.8931301879882813
avg_loss: 0.8815434348583221
avg_loss: 0.813602482676506
avg_loss: 0.8633716225624084
avg_loss: 0.8893487691879273
avg_loss: 0.9076094317436219
avg_loss: 0.8989129966497421
avg_loss: 0.8676204204559326
avg_loss: 0.9043886911869049
avg_loss: 0.9083921456336975
avg_loss: 0.904176687002182
avg_loss: 0.9122910642623902
avg_loss: 0.8680336499214172
avg_loss: 0.8764707589149475
avg_loss: 0.8867651760578156
avg_loss: 0.84564583837986
avg_loss: 0.8778059822320938
avg_loss: 0.9105809390544891
avg_loss: 0.8880769866704941
avg_loss: 0.9116753172874451
avg_loss: 0.8366934251785278
avg_loss: 0.9349766349792481
avg_loss: 0.9309911322593689
avg_loss: 0.9209943079948425
avg_loss: 0.8623457092046738
avg_loss: 0.8520064747333527
avg_loss: 0.8762335991859436
avg_loss: 0.9099852871894837
avg_loss: 0.930641485452652
avg_loss: 0.8830056154727935
avg_loss: 0.8926020306348801
avg_loss: 0.8987567019462586
avg_loss: 0.944049084186554
avg_loss: 0.8875882756710053
avg_loss: 0.860566475391388
avg_loss: 0.8885325694084167
avg_loss: 0.8800079452991486
avg_loss: 0.8952251195907592
avg_loss: 0.8667005383968354
avg_loss: 0.9099757361412049
avg_loss: 0.917379516363144
avg_loss: 0.8767937678098678
avg_loss: 0.9165993809700013
avg_loss: 0.9105795872211456
avg_loss: 0.8836725342273712
avg_loss: 0.8906971395015717
avg_loss: 0.924901579618454
avg_loss: 0.9013589036464691
avg_loss: 0.8793369543552398
avg_loss: 0.8620794677734375
avg_loss: 0.9144954442977905
avg_loss: 0.8645780253410339
{"dev acc"：0.4693963957255737}
{"bleu_0": 0.13393295629446955, "bleu_1": 0.12945300527122003, "bleu_avg": 0.1316929807828448}
{"acc_0": 0.51, "acc_1": 0.45999999999999996, "acc_avg": 0.485}
Epoch:  40%|██████████████████████████████████████████████████████████████▍                                                                                             | 4/10 [1:00:11<1:30:16, 902.80s/it]avg_loss: 0.7358231943845749
avg_loss: 0.7287547636032105
avg_loss: 0.7322980785369873
avg_loss: 0.7304180270433426
avg_loss: 0.7352280348539353
avg_loss: 0.6812422370910645
avg_loss: 0.7723556852340698
avg_loss: 0.7214154350757599
avg_loss: 0.7282660472393035
avg_loss: 0.7514702618122101
avg_loss: 0.7183676224946975
avg_loss: 0.7017265421152115
avg_loss: 0.7397328770160675
avg_loss: 0.7228981858491897
avg_loss: 0.7469948822259903
avg_loss: 0.7247194194793701
avg_loss: 0.7767915773391724
avg_loss: 0.7494132924079895
avg_loss: 0.7153304946422577
avg_loss: 0.7337801682949067
avg_loss: 0.7368180453777313
avg_loss: 0.7493932950496673
avg_loss: 0.7531298410892486
avg_loss: 0.7597152948379516
avg_loss: 0.740442059636116
avg_loss: 0.7489538389444351
avg_loss: 0.7165719991922379
avg_loss: 0.7430580174922943
avg_loss: 0.7251685237884522
avg_loss: 0.7363061571121216
avg_loss: 0.7502016353607178
avg_loss: 0.7463239192962646
avg_loss: 0.8187918454408646
avg_loss: 0.7274880278110504
avg_loss: 0.7145117527246475
avg_loss: 0.7680045372247696
avg_loss: 0.7651451009511948
avg_loss: 0.7247276592254639
avg_loss: 0.7380526548624039
avg_loss: 0.7440793842077256
avg_loss: 0.7296634119749069
avg_loss: 0.7260152405500412
avg_loss: 0.7522662860155106
avg_loss: 0.7754669845104217
avg_loss: 0.7423560392856597
avg_loss: 0.7545380276441574
avg_loss: 0.7627949517965317
avg_loss: 0.7707853299379349
avg_loss: 0.7346098387241363
avg_loss: 0.7529048925638199
avg_loss: 0.7781139945983887
avg_loss: 0.7316971999406815
avg_loss: 0.7567740207910538
avg_loss: 0.7948779726028442
avg_loss: 0.7540893638134003
avg_loss: 0.7734320729970932
avg_loss: 0.7898388224840164
avg_loss: 0.7310694879293442
avg_loss: 0.772473002076149
avg_loss: 0.7304303139448166
avg_loss: 0.7914503026008606
avg_loss: 0.8027990913391113
avg_loss: 0.7472918623685837
avg_loss: 0.7480668985843658
avg_loss: 0.7438103127479553
avg_loss: 0.7951603657007218
avg_loss: 0.7628648543357849
avg_loss: 0.7570562714338303
avg_loss: 0.7431128042936325
avg_loss: 0.7614299428462982
avg_loss: 0.725724202990532
avg_loss: 0.7784459066390991
avg_loss: 0.7336351561546326
avg_loss: 0.8079511076211929
avg_loss: 0.7812971925735473
avg_loss: 0.780011757016182
avg_loss: 0.7517421960830688
avg_loss: 0.7354923784732819
avg_loss: 0.7878744918107986
avg_loss: 0.7665158063173294
avg_loss: 0.8108742541074753
avg_loss: 0.7356790268421173
avg_loss: 0.7411140936613083
avg_loss: 0.7642168629169465
avg_loss: 0.7823491811752319
avg_loss: 0.7434953796863556
avg_loss: 0.7405806285142899
avg_loss: 0.7315470284223556
avg_loss: 0.784528631567955
avg_loss: 0.747823024392128
avg_loss: 0.7611354708671569
avg_loss: 0.7658217459917068
avg_loss: 0.817196034193039
avg_loss: 0.7697824740409851
avg_loss: 0.7658301842212677
avg_loss: 0.7624053174257278
avg_loss: 0.7822533398866653
avg_loss: 0.7748816418647766
avg_loss: 0.7856830489635468
avg_loss: 0.8007758021354675
avg_loss: 0.7836902314424514
avg_loss: 0.7995066088438034
avg_loss: 0.8031649553775787
avg_loss: 0.7481047922372818
avg_loss: 0.8223600339889526
avg_loss: 0.7727808845043183
avg_loss: 0.7708451002836227
{"dev acc"：0.47869280547758275}
{"bleu_0": 0.1334625990413985, "bleu_1": 0.12745879786436567, "bleu_avg": 0.1304606984528821}
{"acc_0": 0.526, "acc_1": 0.554, "acc_avg": 0.54}
Epoch:  50%|██████████████████████████████████████████████████████████████████████████████                                                                              | 5/10 [1:15:12<1:15:11, 902.22s/it]avg_loss: 0.6123203539848328
avg_loss: 0.6348423337936402
avg_loss: 0.6445610868930817
avg_loss: 0.6445067530870437
avg_loss: 0.6301071298122406
avg_loss: 0.6371382749080658
avg_loss: 0.6780779331922531
avg_loss: 0.6443499988317489
avg_loss: 0.6131009340286255
avg_loss: 0.6243833571672439
avg_loss: 0.6268841326236725
avg_loss: 0.6499951905012131
avg_loss: 0.6321888637542724
avg_loss: 0.6313448882102967
avg_loss: 0.6847846812009811
avg_loss: 0.6072307306528092
avg_loss: 0.6571174919605255
avg_loss: 0.6533152049779892
avg_loss: 0.6473002529144287
avg_loss: 0.6335447531938553
avg_loss: 0.6306109952926636
avg_loss: 0.6311834573745727
avg_loss: 0.6325075495243072
avg_loss: 0.6514892929792404
avg_loss: 0.6702069914340973
avg_loss: 0.6380462926626206
avg_loss: 0.6813527578115464
avg_loss: 0.6621283739805222
avg_loss: 0.6201505160331726
avg_loss: 0.6525314772129058
avg_loss: 0.6411542165279388
avg_loss: 0.6723444199562073
avg_loss: 0.6678645014762878
avg_loss: 0.6464905452728271
avg_loss: 0.6511173343658447
avg_loss: 0.6548368960618973
avg_loss: 0.6073325139284134
avg_loss: 0.6709468537569045
avg_loss: 0.6791260313987731
avg_loss: 0.606829052567482
avg_loss: 0.6606733500957489
avg_loss: 0.676526392698288
avg_loss: 0.6567698162794113
avg_loss: 0.6867644834518433
avg_loss: 0.6886197447776794
avg_loss: 0.6438314545154572
avg_loss: 0.6432611477375031
avg_loss: 0.6960996836423874
avg_loss: 0.6720548808574677
avg_loss: 0.6416982209682465
avg_loss: 0.6459879887104034
avg_loss: 0.6732823622226715
avg_loss: 0.627066301703453
avg_loss: 0.6741776269674301
avg_loss: 0.6407014620304108
avg_loss: 0.628218492269516
avg_loss: 0.6466073858737945
avg_loss: 0.6379535150527954
avg_loss: 0.673593293428421
avg_loss: 0.6848637396097184
avg_loss: 0.6655352681875228
avg_loss: 0.6362196415662765
avg_loss: 0.6579350757598877
avg_loss: 0.6698488563299179
avg_loss: 0.6639629977941514
avg_loss: 0.6536467915773392
avg_loss: 0.6622874730825424
avg_loss: 0.6710756081342697
avg_loss: 0.6734804207086563
avg_loss: 0.6851052814722061
avg_loss: 0.6733498865365982
avg_loss: 0.6732175993919373
avg_loss: 0.6959745818376541
avg_loss: 0.6396691858768463
avg_loss: 0.6404280132055282
avg_loss: 0.6721462684869767
avg_loss: 0.6309856933355331
avg_loss: 0.6628126931190491
avg_loss: 0.63497190117836
avg_loss: 0.683392989039421
avg_loss: 0.6863858276605606
avg_loss: 0.6559235984086991
avg_loss: 0.6589297878742219
avg_loss: 0.689162939786911
avg_loss: 0.6714803332090378
avg_loss: 0.6848131448030472
avg_loss: 0.701207264661789
avg_loss: 0.6736887687444687
avg_loss: 0.6685859870910644
avg_loss: 0.6589182478189468
avg_loss: 0.672884448170662
avg_loss: 0.6815194070339203
avg_loss: 0.7018631625175477
avg_loss: 0.6757958465814591
avg_loss: 0.6770452189445496
avg_loss: 0.6523764872550964
avg_loss: 0.6949582487344742
avg_loss: 0.6815472823381424
avg_loss: 0.6818529558181763
avg_loss: 0.7247094827890396
avg_loss: 0.6991762512922287
avg_loss: 0.6631383776664734
avg_loss: 0.6487055772542953
avg_loss: 0.6414458703994751
avg_loss: 0.703499094247818
avg_loss: 0.6656926792860031
avg_loss: 0.6829764252901077
{"dev acc"：0.4761368772305929}
{"bleu_0": 0.1348922359899083, "bleu_1": 0.13171002314690547, "bleu_avg": 0.1333011295684069}
{"acc_0": 0.508, "acc_1": 0.5760000000000001, "acc_avg": 0.542}
Epoch:  60%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 6/10 [1:30:14<1:00:09, 902.36s/it]avg_loss: 0.5431978392601013
avg_loss: 0.5857966196537018
avg_loss: 0.5605617201328278
avg_loss: 0.5771376872062683
avg_loss: 0.552365112900734
avg_loss: 0.5610178577899932
avg_loss: 0.5498264980316162
avg_loss: 0.5496408158540725
avg_loss: 0.5631249791383743
avg_loss: 0.5697580397129058
avg_loss: 0.5851313549280167
avg_loss: 0.5767106908559799
avg_loss: 0.5888169747591019
avg_loss: 0.5389640903472901
avg_loss: 0.5755475336313247
avg_loss: 0.5474457138776779
avg_loss: 0.593077432513237
avg_loss: 0.5662465679645539
avg_loss: 0.5507258898019791
avg_loss: 0.5623406410217285
avg_loss: 0.5813624209165573
avg_loss: 0.6084458142518997
avg_loss: 0.587042818069458
avg_loss: 0.5812533521652221
avg_loss: 0.5862969887256623
avg_loss: 0.5866244542598724
avg_loss: 0.5820779454708099
avg_loss: 0.591536453962326
avg_loss: 0.5688716846704484
avg_loss: 0.5724571198225021
avg_loss: 0.5653362727165222
avg_loss: 0.5922400969266891
avg_loss: 0.5702542960643768
avg_loss: 0.5647549438476562
avg_loss: 0.6122812438011169
avg_loss: 0.6073473650217056
avg_loss: 0.5572414720058441
avg_loss: 0.5837441742420196
avg_loss: 0.6089466631412506
avg_loss: 0.5705099016427994
avg_loss: 0.5791286438703537
avg_loss: 0.5802486389875412
avg_loss: 0.6011128968000412
avg_loss: 0.5433855423331261
avg_loss: 0.6037846171855926
avg_loss: 0.5994502687454224
avg_loss: 0.5699447345733643
avg_loss: 0.558219153881073
avg_loss: 0.6069000291824341
avg_loss: 0.5905832797288895
avg_loss: 0.5860837543010712
avg_loss: 0.5719571685791016
avg_loss: 0.5965565913915634
avg_loss: 0.585153461098671
avg_loss: 0.554841932952404
avg_loss: 0.6016672229766846
avg_loss: 0.5528820163011551
avg_loss: 0.6095055204629898
avg_loss: 0.566757419705391
avg_loss: 0.5318918266892433
avg_loss: 0.5411049216985703
avg_loss: 0.5981325471401214
avg_loss: 0.5503580212593079
avg_loss: 0.5685257083177566
avg_loss: 0.5895849496126175
avg_loss: 0.5803925198316574
avg_loss: 0.5713634032011032
avg_loss: 0.5720477420091629
avg_loss: 0.5965440505743027
avg_loss: 0.6275729405879974
avg_loss: 0.5695653069019317
avg_loss: 0.5789020553231239
avg_loss: 0.6099249053001404
avg_loss: 0.5750621640682221
avg_loss: 0.5775771933794022
avg_loss: 0.5412759310007096
avg_loss: 0.5547740721702575
avg_loss: 0.5577057647705078
avg_loss: 0.5976710826158523
avg_loss: 0.5763006299734116
avg_loss: 0.5924686402082443
avg_loss: 0.5930212289094925
avg_loss: 0.577118581533432
avg_loss: 0.5812233114242553
avg_loss: 0.606894133090973
avg_loss: 0.565442544221878
avg_loss: 0.5951050817966461
avg_loss: 0.581769604086876
avg_loss: 0.5840906924009324
avg_loss: 0.6001770049333572
avg_loss: 0.5889148437976837
avg_loss: 0.617875742316246
avg_loss: 0.5505252504348754
avg_loss: 0.5606010174751281
avg_loss: 0.589416863322258
avg_loss: 0.6092931896448135
avg_loss: 0.579310667514801
avg_loss: 0.594178900718689
avg_loss: 0.5874771755933762
avg_loss: 0.5782998043298722
avg_loss: 0.6048953914642334
avg_loss: 0.5940574330091476
avg_loss: 0.5727125746011734
avg_loss: 0.5983955773711205
avg_loss: 0.5693529587984085
avg_loss: 0.5723434686660767
avg_loss: 0.5893816190958023
{"dev acc"：0.4836046553912596}
{"bleu_0": 0.13354784539344028, "bleu_1": 0.12533514653470276, "bleu_avg": 0.1294414959640715}
{"acc_0": 0.502, "acc_1": 0.55, "acc_avg": 0.526}
Epoch:  70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                               | 7/10 [1:45:17<45:07, 902.34s/it]avg_loss: 0.47776094019412996
avg_loss: 0.5063052076101303
avg_loss: 0.48689122676849367
avg_loss: 0.4907024216651916
avg_loss: 0.5134927439689636
avg_loss: 0.5223126029968261
avg_loss: 0.5240719181299209
avg_loss: 0.49998353540897367
avg_loss: 0.4976135814189911
avg_loss: 0.5151300579309464
avg_loss: 0.5137262815237045
avg_loss: 0.5034913712739945
avg_loss: 0.5059233430027962
avg_loss: 0.5249349555373192
avg_loss: 0.5137434136867524
avg_loss: 0.501316397190094
avg_loss: 0.514715239405632
avg_loss: 0.501194531917572
avg_loss: 0.5025150352716445
avg_loss: 0.5145429331064224
avg_loss: 0.5347310787439347
avg_loss: 0.4879351708292961
avg_loss: 0.531884133219719
avg_loss: 0.5048573166131973
avg_loss: 0.502568062543869
avg_loss: 0.5314454585313797
avg_loss: 0.47109330087900164
avg_loss: 0.510718150138855
avg_loss: 0.493205406665802
avg_loss: 0.46424379348754885
avg_loss: 0.4999637788534164
avg_loss: 0.5382182335853577
avg_loss: 0.5442308819293976
avg_loss: 0.5249399507045746
avg_loss: 0.5464720147848129
avg_loss: 0.5084889006614685
avg_loss: 0.5035480278730392
avg_loss: 0.5148960646986961
avg_loss: 0.507304340004921
avg_loss: 0.49139163017272947
avg_loss: 0.5203647410869598
avg_loss: 0.49411980450153353
avg_loss: 0.5047899097204208
avg_loss: 0.5329467496275901
avg_loss: 0.5205363413691521
avg_loss: 0.5258078607916832
avg_loss: 0.5083907175064087
avg_loss: 0.5324265491962433
avg_loss: 0.4952125692367554
avg_loss: 0.5534431916475296
avg_loss: 0.49069430291652677
avg_loss: 0.5054139053821564
avg_loss: 0.5345833253860474
avg_loss: 0.5148264050483704
avg_loss: 0.5146880894899368
avg_loss: 0.5005584436655045
avg_loss: 0.49847835779190064
avg_loss: 0.49283214926719665
avg_loss: 0.5392934399843216
avg_loss: 0.5388923615217209
avg_loss: 0.5621674710512161
avg_loss: 0.516363542675972
avg_loss: 0.5336315965652466
avg_loss: 0.529471474289894
avg_loss: 0.5098488998413085
avg_loss: 0.4858057504892349
avg_loss: 0.5189499759674072
avg_loss: 0.5324866396188735
avg_loss: 0.5313001370429993
avg_loss: 0.4986356472969055
avg_loss: 0.5230184245109558
avg_loss: 0.5067184865474701
avg_loss: 0.5151354217529297
avg_loss: 0.5168436294794083
avg_loss: 0.5451973992586135
avg_loss: 0.50050202190876
avg_loss: 0.5192707586288452
avg_loss: 0.5132300615310669
avg_loss: 0.5034365546703339
avg_loss: 0.5204718375205993
avg_loss: 0.5182084369659424
avg_loss: 0.5271552580595017
avg_loss: 0.5181256270408631
avg_loss: 0.5474790126085282
avg_loss: 0.5566900300979615
avg_loss: 0.4895850175619125
avg_loss: 0.515830654501915
avg_loss: 0.546294549703598
avg_loss: 0.5375233954191208
avg_loss: 0.5203617855906486
avg_loss: 0.5172132831811905
avg_loss: 0.5166244333982468
avg_loss: 0.574750205874443
avg_loss: 0.5393692290782929
avg_loss: 0.524792935848236
avg_loss: 0.5522088372707367
avg_loss: 0.5257145607471466
avg_loss: 0.5338913667201995
avg_loss: 0.5382303810119629
avg_loss: 0.518453117609024
avg_loss: 0.510235655605793
avg_loss: 0.48332467675209045
avg_loss: 0.5342377331852913
avg_loss: 0.5338159465789795
avg_loss: 0.5097942444682121
avg_loss: 0.5399279195070267
avg_loss: 0.5462493300437927
{"dev acc"：0.48380379614221075}
{"bleu_0": 0.1328752297971854, "bleu_1": 0.12495053338956169, "bleu_avg": 0.12891288159337355}
{"acc_0": 0.5, "acc_1": 0.5880000000000001, "acc_avg": 0.544}
Epoch:  80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 8/10 [2:00:19<30:04, 902.33s/it]avg_loss: 0.4544373771548271
avg_loss: 0.45741345345973966
avg_loss: 0.47007460981607435
avg_loss: 0.5147297996282577
avg_loss: 0.4463810038566589
avg_loss: 0.43857856065034867
avg_loss: 0.4419723403453827
avg_loss: 0.4582282078266144
avg_loss: 0.4480933409929275
avg_loss: 0.4771457940340042
avg_loss: 0.4781793636083603
avg_loss: 0.4415083974599838
avg_loss: 0.4823496225476265
avg_loss: 0.47893424332141876
avg_loss: 0.4758338820934296
avg_loss: 0.4548019105195999
avg_loss: 0.4631809175014496
avg_loss: 0.476343737244606
avg_loss: 0.42747738838195803
avg_loss: 0.45352127254009245
avg_loss: 0.4826521161198616
avg_loss: 0.4494949966669083
avg_loss: 0.46917963564395904
avg_loss: 0.4561812594532967
avg_loss: 0.46278792738914487
avg_loss: 0.47550336450338365
avg_loss: 0.4815970268845558
avg_loss: 0.4659030121564865
avg_loss: 0.45662205457687377
avg_loss: 0.4671827816963196
avg_loss: 0.4675707572698593
avg_loss: 0.47687233477830887
avg_loss: 0.466273697912693
avg_loss: 0.4674069756269455
avg_loss: 0.4467974156141281
avg_loss: 0.49098549902439115
avg_loss: 0.4711145657300949
avg_loss: 0.47746690005064013
avg_loss: 0.4597275608778
avg_loss: 0.46811297833919524
avg_loss: 0.46212028235197067
avg_loss: 0.47027282416820526
avg_loss: 0.4829539430141449
avg_loss: 0.45143949151039126
avg_loss: 0.4673181676864624
avg_loss: 0.4554268330335617
avg_loss: 0.4783384981751442
avg_loss: 0.4937593039870262
avg_loss: 0.4876680105924606
avg_loss: 0.45828804254531863
avg_loss: 0.48028879433870314
avg_loss: 0.44892008244991305
avg_loss: 0.4645989269018173
avg_loss: 0.4819458884000778
avg_loss: 0.449167315363884
avg_loss: 0.4777014893293381
avg_loss: 0.4704659000039101
avg_loss: 0.4912610352039337
avg_loss: 0.46650380253791807
avg_loss: 0.4602673703432083
avg_loss: 0.45644129931926725
avg_loss: 0.4519137144088745
avg_loss: 0.48498785197734834
avg_loss: 0.4556736269593239
avg_loss: 0.4651957830786705
avg_loss: 0.44756270706653595
avg_loss: 0.4989949542284012
avg_loss: 0.5018442815542221
avg_loss: 0.47137451171875
avg_loss: 0.47909303307533263
avg_loss: 0.4797928518056869
avg_loss: 0.4637377542257309
avg_loss: 0.4856716933846474
avg_loss: 0.4549890846014023
avg_loss: 0.48186365962028505
avg_loss: 0.47427109241485593
avg_loss: 0.47102293074131013
avg_loss: 0.4651821994781494
avg_loss: 0.4795448446273804
avg_loss: 0.47533701479434964
avg_loss: 0.44379645884037017
avg_loss: 0.5199280613660813
avg_loss: 0.47068063139915467
avg_loss: 0.45928534865379333
avg_loss: 0.47446798622608183
avg_loss: 0.48528989613056184
avg_loss: 0.4791662585735321
avg_loss: 0.4760414409637451
avg_loss: 0.481732257604599
avg_loss: 0.4742561501264572
avg_loss: 0.4653007358312607
avg_loss: 0.4565433293581009
avg_loss: 0.48346003085374833
avg_loss: 0.4442600482702255
avg_loss: 0.47695701241493227
avg_loss: 0.46627390176057815
avg_loss: 0.4734564435482025
avg_loss: 0.4903760680556297
avg_loss: 0.4622444260120392
avg_loss: 0.470284588932991
avg_loss: 0.4451561778783798
avg_loss: 0.47397698819637296
avg_loss: 0.5006868994235992
avg_loss: 0.46037143051624296
avg_loss: 0.46843565762043
avg_loss: 0.46962895691394807
avg_loss: 0.4684660071134567
{"dev acc"：0.48314749749342406}
{"bleu_0": 0.13527614733136928, "bleu_1": 0.1261176762754033, "bleu_avg": 0.13069691180338627}
{"acc_0": 0.502, "acc_1": 0.5780000000000001, "acc_avg": 0.54}
Epoch:  90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏               | 9/10 [2:15:21<15:02, 902.35s/it]avg_loss: 0.4056413051486015
avg_loss: 0.4124720484018326
avg_loss: 0.4299227386713028
avg_loss: 0.4400346022844315
avg_loss: 0.4299291491508484
avg_loss: 0.45337434351444245
avg_loss: 0.42721399426460266
avg_loss: 0.42680753231048585
avg_loss: 0.43589007675647734
avg_loss: 0.41645915150642393
avg_loss: 0.43120141357183456
avg_loss: 0.42704774796962736
avg_loss: 0.43820810943841937
avg_loss: 0.4350235903263092
avg_loss: 0.4593343883752823
avg_loss: 0.4318818673491478
avg_loss: 0.4164006179571152
avg_loss: 0.423086975812912
avg_loss: 0.4300762617588043
avg_loss: 0.42031229138374326
avg_loss: 0.4159312516450882
avg_loss: 0.4444785237312317
avg_loss: 0.4072150802612305
avg_loss: 0.45481249928474426
avg_loss: 0.4060527789592743
avg_loss: 0.4572433543205261
avg_loss: 0.4415174871683121
avg_loss: 0.4247787344455719
avg_loss: 0.44170527458190917
avg_loss: 0.4410777181386948
avg_loss: 0.45670013427734374
avg_loss: 0.4311114329099655
avg_loss: 0.3989229682087898
avg_loss: 0.4045299628376961
avg_loss: 0.452268570959568
avg_loss: 0.4202049013972282
avg_loss: 0.46276066958904266
avg_loss: 0.41834444463253023
avg_loss: 0.43366636216640475
avg_loss: 0.43319524347782135
avg_loss: 0.4431230226159096
avg_loss: 0.4337586230039597
avg_loss: 0.40537386149168014
avg_loss: 0.40541216373443606
avg_loss: 0.42135551482439043
avg_loss: 0.43485730528831484
avg_loss: 0.45576180070638656
avg_loss: 0.4617287865281105
avg_loss: 0.4335267326235771
avg_loss: 0.4272754245996475
avg_loss: 0.4416324061155319
avg_loss: 0.42854151874780655
avg_loss: 0.42699903666973116
avg_loss: 0.44230784475803375
avg_loss: 0.40005329340696333
avg_loss: 0.4375089302659035
avg_loss: 0.42705925792455673
avg_loss: 0.42233891516923905
avg_loss: 0.4139231702685356
avg_loss: 0.4132540088891983
avg_loss: 0.44311607629060745
avg_loss: 0.4780347263813019
avg_loss: 0.4163768875598908
avg_loss: 0.42524767577648165
avg_loss: 0.4186247274279594
avg_loss: 0.42974198698997496
avg_loss: 0.42091647773981095
avg_loss: 0.4565767630934715
avg_loss: 0.4144362273812294
avg_loss: 0.4288345119357109
avg_loss: 0.43865040481090545
avg_loss: 0.4464524793624878
avg_loss: 0.46410642445087436
avg_loss: 0.4483870947360992
avg_loss: 0.45969596803188323
avg_loss: 0.4582341974973679
avg_loss: 0.4432115614414215
avg_loss: 0.44029984712600706
avg_loss: 0.45468514889478684
avg_loss: 0.399396653175354
avg_loss: 0.43038719445466994
avg_loss: 0.4754431277513504
avg_loss: 0.4390564614534378
avg_loss: 0.4325360935926437
avg_loss: 0.44467779457569123
avg_loss: 0.46217729777097705
avg_loss: 0.43755344808101654
avg_loss: 0.43697142869234085
avg_loss: 0.4457161748409271
avg_loss: 0.4432088068127632
avg_loss: 0.4620100516080856
avg_loss: 0.42561126083135603
avg_loss: 0.42038836777210237
avg_loss: 0.4356400480866432
avg_loss: 0.4518381875753403
avg_loss: 0.43853952318429945
avg_loss: 0.4405478051304817
avg_loss: 0.4234573569893837
avg_loss: 0.4351571801304817
avg_loss: 0.43763290673494337
avg_loss: 0.4274101340770721
avg_loss: 0.4379263561964035
avg_loss: 0.44286949396133424
avg_loss: 0.45182573854923247
avg_loss: 0.4482687127590179
avg_loss: 0.433419363796711
avg_loss: 0.44165125757455825
{"dev acc"：0.4759611138721447}
{"bleu_0": 0.135745535511035, "bleu_1": 0.1291229935276472, "bleu_avg": 0.1324342645193411}
{"acc_0": 0.518, "acc_1": 0.594, "acc_avg": 0.556}
Epoch: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [2:30:26<00:00, 903.09s/it]
Best result: acc 0.556 bleu 0.1324342645193411
+ PYTHONPATH=/home/xgg/pros/MLM_transfer
+ /home/xgg/.conda/envs/py36/bin//python fine_tune_cbert_w_cls.py
03/12/2019 19:42:10 - WARNING - theano.configdefaults -   install mkl with `conda install mkl-service`: No module named 'mkl'
03/12/2019 19:42:11 - WARNING - theano.tensor.blas -   Using NumPy C-API based implementation for BLAS functions.
03/12/2019 19:42:13 - INFO - dataloader -   device cuda n_gpu 1 distributed training False
03/12/2019 19:42:14 - INFO - dataloader -   *** Example ***
03/12/2019 19:42:14 - INFO - dataloader -   guid: train-1
03/12/2019 19:42:14 - INFO - dataloader -   tokens: [CLS] always a great place to stop by in the mall . [SEP]
03/12/2019 19:42:14 - INFO - dataloader -   init_ids: 101 2467 1037 2307 2173 2000 2644 2011 1999 1996 6670 1012 102
03/12/2019 19:42:14 - INFO - dataloader -   input_ids: 101 103 103 103 103 103 103 2011 1999 1996 6670 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 19:42:14 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 19:42:14 - INFO - dataloader -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 19:42:14 - INFO - dataloader -   masked_lm_labels: -1 2467 1037 2307 2173 2000 2644 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 19:42:14 - INFO - dataloader -   *** Example ***
03/12/2019 19:42:14 - INFO - dataloader -   guid: train-2
03/12/2019 19:42:14 - INFO - dataloader -   tokens: [CLS] the food is good for inexpensive chinese food . [SEP]
03/12/2019 19:42:14 - INFO - dataloader -   init_ids: 101 1996 2833 2003 2204 2005 23766 2822 2833 1012 102
03/12/2019 19:42:14 - INFO - dataloader -   input_ids: 101 103 103 103 103 2005 23766 2822 2833 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 19:42:14 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 19:42:14 - INFO - dataloader -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 19:42:14 - INFO - dataloader -   masked_lm_labels: -1 1996 2833 2003 2204 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 19:42:14 - INFO - dataloader -   *** Example ***
03/12/2019 19:42:14 - INFO - dataloader -   guid: train-3
03/12/2019 19:42:14 - INFO - dataloader -   tokens: [CLS] i would highly recommend taking your car here . [SEP]
03/12/2019 19:42:14 - INFO - dataloader -   init_ids: 101 1045 2052 3811 16755 2635 2115 2482 2182 1012 102
03/12/2019 19:42:14 - INFO - dataloader -   input_ids: 101 103 103 103 103 2635 2115 2482 2182 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 19:42:14 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 19:42:14 - INFO - dataloader -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 19:42:14 - INFO - dataloader -   masked_lm_labels: -1 1045 2052 3811 16755 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 19:42:14 - INFO - dataloader -   *** Example ***
03/12/2019 19:42:14 - INFO - dataloader -   guid: train-4
03/12/2019 19:42:14 - INFO - dataloader -   tokens: [CLS] my husband had the chile re ##llen ##o and thought it was amazing . [SEP]
03/12/2019 19:42:14 - INFO - dataloader -   init_ids: 101 2026 3129 2018 1996 7029 2128 12179 2080 1998 2245 2009 2001 6429 1012 102
03/12/2019 19:42:14 - INFO - dataloader -   input_ids: 101 2026 3129 2018 1996 7029 2128 12179 2080 103 103 103 103 6429 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 19:42:14 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 19:42:14 - INFO - dataloader -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 19:42:14 - INFO - dataloader -   masked_lm_labels: -1 -1 -1 -1 -1 -1 -1 -1 -1 1998 2245 2009 2001 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 19:42:14 - INFO - dataloader -   *** Example ***
03/12/2019 19:42:14 - INFO - dataloader -   guid: train-5
03/12/2019 19:42:14 - INFO - dataloader -   tokens: [CLS] my second bad experience at a t ##gi fridays . [SEP]
03/12/2019 19:42:14 - INFO - dataloader -   init_ids: 101 2026 2117 2919 3325 2012 1037 1056 5856 26587 1012 102
03/12/2019 19:42:14 - INFO - dataloader -   input_ids: 101 2026 2117 103 103 103 1037 1056 5856 26587 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 19:42:14 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 19:42:14 - INFO - dataloader -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 19:42:14 - INFO - dataloader -   masked_lm_labels: -1 -1 -1 2919 3325 2012 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 19:42:41 - INFO - dataloader -   ***** Running training *****
03/12/2019 19:42:41 - INFO - dataloader -     Num examples = 172670
03/12/2019 19:42:41 - INFO - dataloader -     Batch size = 32
03/12/2019 19:42:41 - INFO - dataloader -     Num steps = 53959
**********************************************************
Namespace(bert_model='/home/xgg/.pytorch_pretrained_bert/bert-base-uncased.tar.gz', data_dir='./processed_data_frequency_ratio/yelp/', do_lower_case=True, do_train=True, eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, loss_scale=128, max_seq_length=32, no_cuda=False, num_train_epochs=10.0, optimize_on_cpu=False, output_dir='/tmp/yelp_output/', seed=42, task_name=None, train_batch_size=32, warmup_proportion=0.1)
Model pytorch_pretrained_cls/yelp.cbert.pkl loaded successfully!
Epoch:   0%|                                                                                                                                                                         | 0/10 [00:00<?, ?it/s]THCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=405 error=11 : invalid argument
-------avg_loss: 0.3948936646282673, lm_loss: 0.44187629222869873--------
{"dev acc"：70.3}
{"bleu_0": 13.198425220800313, "bleu_1": 12.842164184993186, "bleu_avg": 13.0}
{"acc_0": 65.4, "acc_1": 78.0, "acc_avg": 71.7}
ERROR: could not find reference file evaluation/outputs/yelp/sentiment.test.0.human.split at test_tools/yang_test_tool/multi-bleu.perl line 32.
Traceback (most recent call last):
  File "fine_tune_cbert_w_cls.py", line 242, in <module>
    main()
  File "fine_tune_cbert_w_cls.py", line 195, in main
    _bleu = eval_multi_bleu(model_name, task_name)
  File "/home/xgg/pros/MLM_transfer/test_tools/yang_test_tool/multi_bleu.py", line 8, in eval_multi_bleu
    bleu_0 = float(info[0].split(',')[0].split('=')[1])
IndexError: list index out of range
Exception ignored in: <bound method tqdm.__del__ of Epoch:   0%|                                                                                                                                                                         | 0/10 [01:53<?, ?it/s]>
Traceback (most recent call last):
  File "/home/xgg/.conda/envs/py36/lib/python3.6/site-packages/tqdm/_tqdm.py", line 931, in __del__
    self.close()
  File "/home/xgg/.conda/envs/py36/lib/python3.6/site-packages/tqdm/_tqdm.py", line 1133, in close
    self._decr_instances(self)
  File "/home/xgg/.conda/envs/py36/lib/python3.6/site-packages/tqdm/_tqdm.py", line 496, in _decr_instances
    cls.monitor.exit()
  File "/home/xgg/.conda/envs/py36/lib/python3.6/site-packages/tqdm/_monitor.py", line 52, in exit
    self.join()
  File "/home/xgg/.conda/envs/py36/lib/python3.6/threading.py", line 1053, in join
    raise RuntimeError("cannot join current thread")
RuntimeError: cannot join current thread
[01;32mxgg@decs[00m:[01;34m~/pros/MLM_transfer[00m$ bash scripts/frequency_ratio/fine_tune_yelp_frequency_ratio.sh [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Kbash scripts/frequency_ratio/fine_tune_yelp_frequency_ratio.sh [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython train_ae.py [K[44@bash scripts/frequency_ratio/fine_tune_yelp_frequency_ratio.sh[C
+ PROJECTPATH=/home/xgg/pros/MLM_transfer
+ PYTHONPATH=/home/xgg/pros/MLM_transfer
+ /home/xgg/.conda/envs/py36/bin//python fine_tune_cbert_w_cls.py
03/12/2019 20:37:25 - WARNING - theano.configdefaults -   install mkl with `conda install mkl-service`: No module named 'mkl'
03/12/2019 20:37:25 - WARNING - theano.tensor.blas -   Using NumPy C-API based implementation for BLAS functions.
03/12/2019 20:37:28 - INFO - dataloader -   device cuda n_gpu 1 distributed training False
03/12/2019 20:37:29 - INFO - dataloader -   *** Example ***
03/12/2019 20:37:29 - INFO - dataloader -   guid: train-1
03/12/2019 20:37:29 - INFO - dataloader -   tokens: [CLS] always a great place to stop by in the mall . [SEP]
03/12/2019 20:37:29 - INFO - dataloader -   init_ids: 101 2467 1037 2307 2173 2000 2644 2011 1999 1996 6670 1012 102
03/12/2019 20:37:29 - INFO - dataloader -   input_ids: 101 103 103 103 103 103 103 2011 1999 1996 6670 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 20:37:29 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 20:37:29 - INFO - dataloader -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 20:37:29 - INFO - dataloader -   masked_lm_labels: -1 2467 1037 2307 2173 2000 2644 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 20:37:29 - INFO - dataloader -   *** Example ***
03/12/2019 20:37:29 - INFO - dataloader -   guid: train-2
03/12/2019 20:37:29 - INFO - dataloader -   tokens: [CLS] the food is good for inexpensive chinese food . [SEP]
03/12/2019 20:37:29 - INFO - dataloader -   init_ids: 101 1996 2833 2003 2204 2005 23766 2822 2833 1012 102
03/12/2019 20:37:29 - INFO - dataloader -   input_ids: 101 103 103 103 103 2005 23766 2822 2833 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 20:37:29 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 20:37:29 - INFO - dataloader -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 20:37:29 - INFO - dataloader -   masked_lm_labels: -1 1996 2833 2003 2204 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 20:37:29 - INFO - dataloader -   *** Example ***
03/12/2019 20:37:29 - INFO - dataloader -   guid: train-3
03/12/2019 20:37:29 - INFO - dataloader -   tokens: [CLS] i would highly recommend taking your car here . [SEP]
03/12/2019 20:37:29 - INFO - dataloader -   init_ids: 101 1045 2052 3811 16755 2635 2115 2482 2182 1012 102
03/12/2019 20:37:29 - INFO - dataloader -   input_ids: 101 103 103 103 103 2635 2115 2482 2182 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 20:37:29 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 20:37:29 - INFO - dataloader -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 20:37:29 - INFO - dataloader -   masked_lm_labels: -1 1045 2052 3811 16755 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 20:37:29 - INFO - dataloader -   *** Example ***
03/12/2019 20:37:29 - INFO - dataloader -   guid: train-4
03/12/2019 20:37:29 - INFO - dataloader -   tokens: [CLS] my husband had the chile re ##llen ##o and thought it was amazing . [SEP]
03/12/2019 20:37:29 - INFO - dataloader -   init_ids: 101 2026 3129 2018 1996 7029 2128 12179 2080 1998 2245 2009 2001 6429 1012 102
03/12/2019 20:37:29 - INFO - dataloader -   input_ids: 101 2026 3129 2018 1996 7029 2128 12179 2080 103 103 103 103 6429 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 20:37:29 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 20:37:29 - INFO - dataloader -   segment_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 20:37:29 - INFO - dataloader -   masked_lm_labels: -1 -1 -1 -1 -1 -1 -1 -1 -1 1998 2245 2009 2001 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 20:37:29 - INFO - dataloader -   *** Example ***
03/12/2019 20:37:29 - INFO - dataloader -   guid: train-5
03/12/2019 20:37:29 - INFO - dataloader -   tokens: [CLS] my second bad experience at a t ##gi fridays . [SEP]
03/12/2019 20:37:29 - INFO - dataloader -   init_ids: 101 2026 2117 2919 3325 2012 1037 1056 5856 26587 1012 102
03/12/2019 20:37:29 - INFO - dataloader -   input_ids: 101 2026 2117 103 103 103 1037 1056 5856 26587 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 20:37:29 - INFO - dataloader -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 20:37:29 - INFO - dataloader -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/12/2019 20:37:29 - INFO - dataloader -   masked_lm_labels: -1 -1 -1 2919 3325 2012 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
03/12/2019 20:37:55 - INFO - dataloader -   ***** Running training *****
03/12/2019 20:37:55 - INFO - dataloader -     Num examples = 172670
03/12/2019 20:37:55 - INFO - dataloader -     Batch size = 32
03/12/2019 20:37:55 - INFO - dataloader -     Num steps = 53959
**********************************************************
Namespace(bert_model='/home/xgg/.pytorch_pretrained_bert/bert-base-uncased.tar.gz', data_dir='./processed_data_frequency_ratio/yelp/', do_lower_case=True, do_train=True, eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, loss_scale=128, max_seq_length=32, no_cuda=False, num_train_epochs=10.0, optimize_on_cpu=False, output_dir='/tmp/yelp_output/', seed=42, task_name=None, train_batch_size=32, warmup_proportion=0.1)
Model pytorch_pretrained_cls/yelp.cbert.pkl loaded successfully!
Epoch:   0%|                                                                                                                                                                         | 0/10 [00:00<?, ?it/s]THCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=405 error=11 : invalid argument

-------avg_loss: 0.39489364175871017, lm_loss: 0.44187623262405396--------
{"dev acc"：70.3}
{"bleu_0": 13.198425220800313, "bleu_1": 12.842164184993186, "bleu_avg": 13.0}
{"acc_0": 65.4, "acc_1": 78.0, "acc_avg": 71.7}
{"_ACCU": 74.9, "_BLEU": 18.9}
: -------avg_loss: 0.008574708618223667, lm_loss: 0.45523378252983093--------
{"dev acc"：76.5}
{"bleu_0": 13.025317093576652, "bleu_1": 13.037119218563204, "bleu_avg": 13.0}
{"acc_0": 68.39999999999999, "acc_1": 82.0, "acc_avg": 75.2}
{"_ACCU": 78.5, "_BLEU": 18.8}
-------avg_loss: 0.0024214450642466544, lm_loss: 0.7403427362442017--------
{"dev acc"：78.9}
{"bleu_0": 12.879471716180719, "bleu_1": 12.593786280017019, "bleu_avg": 12.7}
{"acc_0": 68.0, "acc_1": 83.2, "acc_avg": 75.6}
{"_ACCU": 79.9, "_BLEU": 18.6}
-------avg_loss: 0.0008878844305872918, lm_loss: 0.473792165517807--------
{"dev acc"：81.0}
{"bleu_0": 12.961855961264618, "bleu_1": 12.812516006697697, "bleu_avg": 12.9}
{"acc_0": 73.0, "acc_1": 84.6, "acc_avg": 78.8}
{"_ACCU": 83.1, "_BLEU": 18.7}
-------avg_loss: 0.00022043289244174958, lm_loss: 0.58590167760849--------
{"dev acc"：82.4}
{"bleu_0": 12.645345872392799, "bleu_1": 12.66476654586354, "bleu_avg": 12.7}
{"acc_0": 73.0, "acc_1": 85.0, "acc_avg": 79.0}
{"_ACCU": 83.2, "_BLEU": 18.5}
-------avg_loss: 0.00017869913578033448, lm_loss: 0.6699253916740417--------
{"dev acc"：83.7}
{"bleu_0": 12.520703193853787, "bleu_1": 12.404043698144196, "bleu_avg": 12.5}
{"acc_0": 74.8, "acc_1": 83.39999999999999, "acc_avg": 79.1}
{"_ACCU": 82.2, "_BLEU": 18.6}
-------avg_loss: 0.00012363536655902863, lm_loss: 0.7658416032791138--------
{"dev acc"：83.1}
{"bleu_0": 12.821990099435443, "bleu_1": 12.735370396629994, "bleu_avg": 12.8}
{"acc_0": 74.8, "acc_1": 82.0, "acc_avg": 78.4}
{"_ACCU": 83.9, "_BLEU": 18.6}
-------avg_loss: 0.00014844200015068053, lm_loss: 0.5881251692771912--------
{"dev acc"：85.0}
{"bleu_0": 12.346054788060146, "bleu_1": 12.601370513261918, "bleu_avg": 12.5}
{"acc_0": 78.8, "acc_1": 83.2, "acc_avg": 81.0}
{"_ACCU": 85.1, "_BLEU": 18.4}
-------avg_loss: 0.00010365264117717744, lm_loss: 0.8041431307792664--------
{"dev acc"：87.9}
{"bleu_0": 12.661158301964429, "bleu_1": 12.529731953529314, "bleu_avg": 12.6}
{"acc_0": 78.2, "acc_1": 85.39999999999999, "acc_avg": 81.8}
{"_ACCU": 84.7, "_BLEU": 18.4}
-------avg_loss: 7.027319073677063e-05, lm_loss: 0.6297338008880615--------
{"dev acc"：87.1}
{"bleu_0": 12.478677317331064, "bleu_1": 12.430069016758857, "bleu_avg": 12.5}
{"acc_0": 79.80000000000001, "acc_1": 85.8, "acc_avg": 82.8}
{"_ACCU": 86.6, "_BLEU": 18.3}
-------avg_loss: 4.958599805831909e-05, lm_loss: 0.798720121383667--------
{"dev acc"：89.2}
{"bleu_0": 12.323756325507848, "bleu_1": 12.310985817660745, "bleu_avg": 12.3}
{"acc_0": 80.4, "acc_1": 86.0, "acc_avg": 83.2}
{"_ACCU": 86.2, "_BLEU": 18.2}
-------avg_loss: 3.658051788806915e-05, lm_loss: 0.8159858584403992--------
{"dev acc"：88.4}
{"bleu_0": 12.461186327369465, "bleu_1": 12.339738977704164, "bleu_avg": 12.4}
{"acc_0": 80.60000000000001, "acc_1": 86.2, "acc_avg": 83.4}
{"_ACCU": 86.1, "_BLEU": 18.3}
-------avg_loss: 2.9620230197906494e-05, lm_loss: 0.7413000464439392--------
{"dev acc"：89.4}
{"bleu_0": 12.016114110188534, "bleu_1": 12.374574315877751, "bleu_avg": 12.2}
{"acc_0": 80.2, "acc_1": 86.4, "acc_avg": 83.3}
{"_ACCU": 86.6, "_BLEU": 18.1}
-------avg_loss: 2.5267094373703002e-05, lm_loss: 0.7848599553108215--------
{"dev acc"：90.6}
{"bleu_0": 11.90277102109455, "bleu_1": 12.74365184210129, "bleu_avg": 12.3}
{"acc_0": 82.0, "acc_1": 87.8, "acc_avg": 84.9}
{"_ACCU": 87.9, "_BLEU": 18.2}
-------avg_loss: 1.8845856189727782e-05, lm_loss: 0.86998051404953--------
{"dev acc"：91.3}
{"bleu_0": 12.316192598322429, "bleu_1": 12.322199623353779, "bleu_avg": 12.3}
{"acc_0": 82.2, "acc_1": 87.2, "acc_avg": 84.7}
{"_ACCU": 87.6, "_BLEU": 18.1}
-------avg_loss: 1.13336443901062e-05, lm_loss: 0.8664367198944092--------
{"dev acc"：90.7}
{"bleu_0": 11.943571230760677, "bleu_1": 12.60004611678639, "bleu_avg": 12.3}
{"acc_0": 83.2, "acc_1": 87.0, "acc_avg": 85.1}
{"_ACCU": 88.7, "_BLEU": 18.1}
-------avg_loss: 1.0125190019607544e-05, lm_loss: 0.9334778785705566--------
{"dev acc"：92.6}
{"bleu_0": 12.217090441575296, "bleu_1": 12.60579185040237, "bleu_avg": 12.4}
{"acc_0": 84.6, "acc_1": 88.2, "acc_avg": 86.4}
{"_ACCU": 89.2, "_BLEU": 18.2}
-------avg_loss: 1.0442227125167846e-05, lm_loss: 0.6816555261611938--------
{"dev acc"：92.8}
{"bleu_0": 11.692173606461912, "bleu_1": 12.25773849484235, "bleu_avg": 12.0}
{"acc_0": 85.0, "acc_1": 87.8, "acc_avg": 86.4}
{"_ACCU": 89.8, "_BLEU": 17.8}
-------avg_loss: 6.145298480987549e-06, lm_loss: 0.8477723598480225--------
{"dev acc"：93.5}
{"bleu_0": 11.941588451264346, "bleu_1": 12.686039470288588, "bleu_avg": 12.3}
{"acc_0": 86.4, "acc_1": 88.0, "acc_avg": 87.2}
{"_ACCU": 89.9, "_BLEU": 18.0}
-------avg_loss: 5.753070116043091e-06, lm_loss: 0.8049492835998535--------
{"dev acc"：94.0}
{"bleu_0": 11.68686254695119, "bleu_1": 11.86540542170507, "bleu_avg": 11.8}
{"acc_0": 86.6, "acc_1": 88.8, "acc_avg": 87.7}
{"_ACCU": 90.5, "_BLEU": 17.6}
-------avg_loss: 5.274206399917603e-06, lm_loss: 1.4008276462554932--------
{"dev acc"：93.7}
{"bleu_0": 11.766036881775927, "bleu_1": 12.120281906785939, "bleu_avg": 11.9}
{"acc_0": 85.8, "acc_1": 88.2, "acc_avg": 87.0}
{"_ACCU": 90.7, "_BLEU": 17.8}
Best result: dev_acc 94.0 acc 87.7 bleu 11.8 _acc 90.5 _bleu 17.6
Epoch:  10%|███████████████▋                                                                                                                                             | 1/10 [38:51<5:49:43, 2331.52s/it]-------avg_loss: 3.3527612686157227e-06, lm_loss: 1.2302724123001099--------
{"dev acc"：94.6}
{"bleu_0": 11.872689398756775, "bleu_1": 12.332283424887414, "bleu_avg": 12.1}
{"acc_0": 86.0, "acc_1": 89.2, "acc_avg": 87.6}
{"_ACCU": 91.6, "_BLEU": 17.8}
-------avg_loss: 3.2308101654052735e-06, lm_loss: 1.4412652254104614--------
{"dev acc"：94.6}
{"bleu_0": 11.7491872961568, "bleu_1": 12.015261831639263, "bleu_avg": 11.9}
{"acc_0": 86.6, "acc_1": 90.4, "acc_avg": 88.5}
{"_ACCU": 92.0, "_BLEU": 17.7}
-------avg_loss: 2.9246509075164796e-06, lm_loss: 1.3982988595962524--------
{"dev acc"：95.4}
{"bleu_0": 11.758028141647637, "bleu_1": 12.346639091021617, "bleu_avg": 12.1}
{"acc_0": 87.2, "acc_1": 89.2, "acc_avg": 88.2}
{"_ACCU": 90.6, "_BLEU": 17.8}
-------avg_loss: 2.3926496505737306e-06, lm_loss: 1.273573398590088--------
{"dev acc"：95.1}
{"bleu_0": 11.750793550863737, "bleu_1": 12.290341398294798, "bleu_avg": 12.0}
{"acc_0": 88.8, "acc_1": 89.4, "acc_avg": 89.1}
{"_ACCU": 92.1, "_BLEU": 17.8}
-------avg_loss: 2.38075852394104e-06, lm_loss: 1.4029737710952759--------
{"dev acc"：95.0}
{"bleu_0": 11.79974033424317, "bleu_1": 12.491917838817255, "bleu_avg": 12.1}
{"acc_0": 88.4, "acc_1": 89.60000000000001, "acc_avg": 89.0}
{"_ACCU": 92.3, "_BLEU": 17.8}
-------avg_loss: 2.284348011016846e-06, lm_loss: 1.4390020370483398--------
{"dev acc"：96.0}
{"bleu_0": 11.651100833335597, "bleu_1": 12.027309683135439, "bleu_avg": 11.8}
{"acc_0": 88.4, "acc_1": 89.8, "acc_avg": 89.1}
{"_ACCU": 92.3, "_BLEU": 17.6}
-------avg_loss: 2.0204484462738038e-06, lm_loss: 1.8062511682510376--------
{"dev acc"：95.6}
{"bleu_0": 11.679178703996417, "bleu_1": 12.130916070269542, "bleu_avg": 11.9}
{"acc_0": 87.4, "acc_1": 90.2, "acc_avg": 88.8}
{"_ACCU": 92.4, "_BLEU": 17.7}
-------avg_loss: 1.7380714416503906e-06, lm_loss: 1.28856360912323--------
{"dev acc"：95.1}
{"bleu_0": 11.667239557997306, "bleu_1": 12.596348697085812, "bleu_avg": 12.1}
{"acc_0": 87.4, "acc_1": 90.2, "acc_avg": 88.8}
{"_ACCU": 92.1, "_BLEU": 17.9}
-------avg_loss: 1.7594397068023681e-06, lm_loss: 1.5895336866378784--------
{"dev acc"：95.4}
{"bleu_0": 11.557839005120268, "bleu_1": 12.254959451232764, "bleu_avg": 11.9}
{"acc_0": 88.6, "acc_1": 90.2, "acc_avg": 89.4}
{"_ACCU": 91.9, "_BLEU": 17.7}
-------avg_loss: 1.727968454360962e-06, lm_loss: 1.3044636249542236--------
{"dev acc"：95.8}
{"bleu_0": 11.598831765343984, "bleu_1": 11.825425420374684, "bleu_avg": 11.7}
{"acc_0": 88.4, "acc_1": 90.4, "acc_avg": 89.4}
{"_ACCU": 92.4, "_BLEU": 17.5}
-------avg_loss: 1.4474391937255859e-06, lm_loss: 1.423148512840271--------
{"dev acc"：96.1}
{"bleu_0": 11.561052387070013, "bleu_1": 12.180894830739446, "bleu_avg": 11.9}
{"acc_0": 88.2, "acc_1": 90.2, "acc_avg": 89.2}
{"_ACCU": 92.0, "_BLEU": 17.6}
-------avg_loss: 1.582324504852295e-06, lm_loss: 1.2353136539459229--------
{"dev acc"：95.9}
{"bleu_0": 11.649598765738443, "bleu_1": 11.91966288362415, "bleu_avg": 11.8}
{"acc_0": 88.8, "acc_1": 89.2, "acc_avg": 89.0}
{"_ACCU": 92.0, "_BLEU": 17.6}
-------avg_loss: 1.2894868850708008e-06, lm_loss: 1.161989688873291--------
{"dev acc"：95.7}
{"bleu_0": 11.55022044202867, "bleu_1": 12.20855573295088, "bleu_avg": 11.9}
{"acc_0": 88.6, "acc_1": 91.0, "acc_avg": 89.8}
{"_ACCU": 92.3, "_BLEU": 17.7}
-------avg_loss: 1.21384859085083e-06, lm_loss: 1.4548484086990356--------
{"dev acc"：96.5}
{"bleu_0": 11.581186224453289, "bleu_1": 11.936018955451434, "bleu_avg": 11.8}
{"acc_0": 88.2, "acc_1": 89.8, "acc_avg": 89.0}
{"_ACCU": 91.9, "_BLEU": 17.7}
-------avg_loss: 1.2640655040740967e-06, lm_loss: 1.062703013420105--------
{"dev acc"：95.8}
{"bleu_0": 11.70195589225664, "bleu_1": 12.18436500710535, "bleu_avg": 11.9}
{"acc_0": 87.8, "acc_1": 90.8, "acc_avg": 89.3}
{"_ACCU": 92.3, "_BLEU": 17.7}
-------avg_loss: 1.1147260665893556e-06, lm_loss: 1.1071394681930542--------
{"dev acc"：95.9}
{"bleu_0": 11.610777676844256, "bleu_1": 11.5724230001946, "bleu_avg": 11.6}
{"acc_0": 89.2, "acc_1": 91.2, "acc_avg": 90.2}
{"_ACCU": 93.1, "_BLEU": 17.5}
-------avg_loss: 1.1566281318664551e-06, lm_loss: 1.152068018913269--------
{"dev acc"：96.3}
{"bleu_0": 11.597484938601786, "bleu_1": 11.99883957449281, "bleu_avg": 11.8}
{"acc_0": 90.2, "acc_1": 90.8, "acc_avg": 90.5}
{"_ACCU": 92.8, "_BLEU": 17.6}
-------avg_loss: 1.4417469501495362e-06, lm_loss: 1.1698037385940552--------
{"dev acc"：96.1}
{"bleu_0": 11.632299077778036, "bleu_1": 12.273762888282574, "bleu_avg": 12.0}
{"acc_0": 89.2, "acc_1": 90.4, "acc_avg": 89.8}
{"_ACCU": 93.0, "_BLEU": 17.6}
-------avg_loss: 9.65893268585205e-07, lm_loss: 1.2388286590576172--------
{"dev acc"：96.5}
{"bleu_0": 11.397716941400752, "bleu_1": 11.98667648110895, "bleu_avg": 11.7}
{"acc_0": 88.6, "acc_1": 90.60000000000001, "acc_avg": 89.6}
{"_ACCU": 92.4, "_BLEU": 17.6}
-------avg_loss: 9.75102186203003e-07, lm_loss: 1.2694121599197388--------
{"dev acc"：96.2}
{"bleu_0": 11.549936229864272, "bleu_1": 12.100933775067798, "bleu_avg": 11.8}
{"acc_0": 88.6, "acc_1": 90.4, "acc_avg": 89.5}
{"_ACCU": 92.5, "_BLEU": 17.6}
-------avg_loss: 9.353160858154297e-07, lm_loss: 1.4288458824157715--------
{"dev acc"：96.4}
{"bleu_0": 11.692006990072565, "bleu_1": 12.225830176451986, "bleu_avg": 12.0}
{"acc_0": 89.4, "acc_1": 89.60000000000001, "acc_avg": 89.5}
{"_ACCU": 92.5, "_BLEU": 17.7}
Best result: dev_acc 96.5 acc 89.3 bleu 11.7 _acc 92.2 _bleu 17.6
Epoch:  20%|███████████████████████████████                                                                                                                            | 2/10 [1:18:25<5:12:34, 2344.29s/it]-------avg_loss: 8.212327957153321e-07, lm_loss: 1.4284969568252563--------
{"dev acc"：96.1}
{"bleu_0": 11.80143125791833, "bleu_1": 12.05147197895878, "bleu_avg": 11.9}
{"acc_0": 87.8, "acc_1": 91.2, "acc_avg": 89.5}
{"_ACCU": 93.3, "_BLEU": 17.7}
-------avg_loss: 8.257627487182617e-07, lm_loss: 1.1631168127059937--------
{"dev acc"：96.4}
{"bleu_0": 11.659366462235168, "bleu_1": 12.068762726365845, "bleu_avg": 11.9}
{"acc_0": 89.8, "acc_1": 90.4, "acc_avg": 90.1}
{"_ACCU": 93.1, "_BLEU": 17.6}
-------avg_loss: 7.099509239196777e-07, lm_loss: 1.06267249584198--------
{"dev acc"：96.1}
{"bleu_0": 11.478028350043052, "bleu_1": 11.94202196564902, "bleu_avg": 11.7}
{"acc_0": 89.60000000000001, "acc_1": 90.8, "acc_avg": 90.2}
{"_ACCU": 92.7, "_BLEU": 17.5}
-------avg_loss: 7.332563400268554e-07, lm_loss: 1.2576736211776733--------
{"dev acc"：96.4}
{"bleu_0": 11.39906663630853, "bleu_1": 11.845576126461255, "bleu_avg": 11.6}
{"acc_0": 89.2, "acc_1": 91.2, "acc_avg": 90.2}
{"_ACCU": 93.4, "_BLEU": 17.5}
-------avg_loss: 6.342530250549316e-07, lm_loss: 1.3177043199539185--------
{"dev acc"：96.5}
{"bleu_0": 11.635204691061615, "bleu_1": 12.021899154735975, "bleu_avg": 11.8}
{"acc_0": 88.6, "acc_1": 91.4, "acc_avg": 90.0}
{"_ACCU": 93.1, "_BLEU": 17.6}
-------avg_loss: 6.077885627746582e-07, lm_loss: 1.047916293144226--------
{"dev acc"：96.8}
{"bleu_0": 11.517486362644917, "bleu_1": 11.945484852287269, "bleu_avg": 11.7}
{"acc_0": 88.8, "acc_1": 90.0, "acc_avg": 89.4}
{"_ACCU": 92.8, "_BLEU": 17.6}
-------avg_loss: 6.000995635986328e-07, lm_loss: 1.030505657196045--------
{"dev acc"：96.7}
{"bleu_0": 11.921938750428621, "bleu_1": 12.078041184246507, "bleu_avg": 12.0}
{"acc_0": 89.2, "acc_1": 90.0, "acc_avg": 89.6}
{"_ACCU": 92.6, "_BLEU": 17.7}
-------avg_loss: 6.038546562194824e-07, lm_loss: 1.0269619226455688--------
{"dev acc"：95.9}
{"bleu_0": 11.4197074901464, "bleu_1": 12.013764359389768, "bleu_avg": 11.7}
{"acc_0": 89.8, "acc_1": 90.2, "acc_avg": 90.0}
{"_ACCU": 92.5, "_BLEU": 17.5}
-------avg_loss: 5.398392677307129e-07, lm_loss: 1.1359244585037231--------
{"dev acc"：96.5}
{"bleu_0": 11.641068820420951, "bleu_1": 12.313262728754053, "bleu_avg": 12.0}
{"acc_0": 90.2, "acc_1": 91.0, "acc_avg": 90.6}
{"_ACCU": 93.7, "_BLEU": 17.7}
-------avg_loss: 5.768537521362305e-07, lm_loss: 1.1124472618103027--------
{"dev acc"：96.2}
{"bleu_0": 11.453847222696984, "bleu_1": 11.726437776488465, "bleu_avg": 11.6}
{"acc_0": 89.60000000000001, "acc_1": 90.8, "acc_avg": 90.2}
{"_ACCU": 93.7, "_BLEU": 17.5}
-------avg_loss: 4.75764274597168e-07, lm_loss: 0.6216458082199097--------
{"dev acc"：96.1}
{"bleu_0": 11.491236957143167, "bleu_1": 11.81509472151568, "bleu_avg": 11.7}
{"acc_0": 90.8, "acc_1": 90.60000000000001, "acc_avg": 90.7}
{"_ACCU": 93.2, "_BLEU": 17.5}
-------avg_loss: 4.5615434646606443e-07, lm_loss: 1.0746654272079468--------
{"dev acc"：96.4}
{"bleu_0": 11.453207039802313, "bleu_1": 12.352900849457631, "bleu_avg": 11.9}
{"acc_0": 90.2, "acc_1": 90.4, "acc_avg": 90.3}
{"_ACCU": 92.9, "_BLEU": 17.6}
-------avg_loss: 4.565119743347168e-07, lm_loss: 0.8833951950073242--------
{"dev acc"：96.3}
{"bleu_0": 11.485223898647888, "bleu_1": 11.808102029963905, "bleu_avg": 11.6}
{"acc_0": 90.0, "acc_1": 91.4, "acc_avg": 90.7}
{"_ACCU": 93.2, "_BLEU": 17.5}
-------avg_loss: 4.4399499893188476e-07, lm_loss: 1.1616569757461548--------
{"dev acc"：97.0}
{"bleu_0": 11.68646894752988, "bleu_1": 12.176406148322405, "bleu_avg": 11.9}
{"acc_0": 89.4, "acc_1": 90.8, "acc_avg": 90.1}
{"_ACCU": 93.7, "_BLEU": 17.6}
-------avg_loss: 4.320740699768066e-07, lm_loss: 1.0531529188156128--------
{"dev acc"：96.8}
{"bleu_0": 11.382247182899514, "bleu_1": 11.770847265935595, "bleu_avg": 11.6}
{"acc_0": 88.6, "acc_1": 90.60000000000001, "acc_avg": 89.6}
{"_ACCU": 92.9, "_BLEU": 17.4}
-------avg_loss: 3.976225852966309e-07, lm_loss: 1.3763930797576904--------
{"dev acc"：96.1}
{"bleu_0": 11.638372721117765, "bleu_1": 11.974907714787266, "bleu_avg": 11.8}
{"acc_0": 88.6, "acc_1": 90.8, "acc_avg": 89.7}
{"_ACCU": 92.8, "_BLEU": 17.7}
-------avg_loss: 3.8927793502807615e-07, lm_loss: 1.241607427597046--------
{"dev acc"：96.5}
{"bleu_0": 11.611301259616159, "bleu_1": 11.969655042884046, "bleu_avg": 11.8}
{"acc_0": 90.2, "acc_1": 89.4, "acc_avg": 89.8}
{"_ACCU": 92.5, "_BLEU": 17.6}
-------avg_loss: 3.786683082580566e-07, lm_loss: 1.280076026916504--------
{"dev acc"：96.7}
{"bleu_0": 11.423052526104591, "bleu_1": 11.839167756249266, "bleu_avg": 11.6}
{"acc_0": 89.4, "acc_1": 90.8, "acc_avg": 90.1}
{"_ACCU": 92.8, "_BLEU": 17.5}
-------avg_loss: 3.7914514541625975e-07, lm_loss: 1.1314195394515991--------
{"dev acc"：96.6}
{"bleu_0": 11.588225657004516, "bleu_1": 12.071548997078125, "bleu_avg": 11.8}
{"acc_0": 90.60000000000001, "acc_1": 91.0, "acc_avg": 90.8}
{"_ACCU": 93.8, "_BLEU": 17.6}
-------avg_loss: 3.598928451538086e-07, lm_loss: 0.9322118163108826--------
{"dev acc"：96.6}
{"bleu_0": 11.57949300652188, "bleu_1": 11.937052569760057, "bleu_avg": 11.8}
{"acc_0": 90.2, "acc_1": 90.4, "acc_avg": 90.3}
{"_ACCU": 93.1, "_BLEU": 17.5}
-------avg_loss: 3.458857536315918e-07, lm_loss: 0.983901858329773--------
{"dev acc"：96.7}
{"bleu_0": 11.454316654136354, "bleu_1": 11.815878629797755, "bleu_avg": 11.6}
{"acc_0": 90.4, "acc_1": 90.60000000000001, "acc_avg": 90.5}
{"_ACCU": 93.1, "_BLEU": 17.5}
Best result: dev_acc 97.0 acc 90.1 bleu 11.9 _acc 93.7 _bleu 17.6
Epoch:  30%|██████████████████████████████████████████████▌                                                                                                            | 3/10 [1:57:28<4:33:28, 2344.01s/it]-------avg_loss: 3.5440921783447264e-07, lm_loss: 0.7884209156036377--------
{"dev acc"：97.3}
{"bleu_0": 11.495270645971793, "bleu_1": 11.912084457712512, "bleu_avg": 11.7}
{"acc_0": 90.0, "acc_1": 90.8, "acc_avg": 90.4}
{"_ACCU": 92.9, "_BLEU": 17.6}
-------avg_loss: 3.426074981689453e-07, lm_loss: 1.3249186277389526--------
{"dev acc"：96.7}
{"bleu_0": 11.537159071736985, "bleu_1": 11.842785958309483, "bleu_avg": 11.7}
{"acc_0": 89.2, "acc_1": 90.0, "acc_avg": 89.6}
{"_ACCU": 92.6, "_BLEU": 17.6}
-------avg_loss: 3.2514333724975586e-07, lm_loss: 1.2067580223083496--------
{"dev acc"：96.8}
{"bleu_0": 11.531044659677482, "bleu_1": 12.187202100022905, "bleu_avg": 11.9}
{"acc_0": 89.60000000000001, "acc_1": 90.0, "acc_avg": 89.8}
{"_ACCU": 93.3, "_BLEU": 17.7}
-------avg_loss: 3.1566619873046877e-07, lm_loss: 1.2918683290481567--------
{"dev acc"：96.6}
{"bleu_0": 11.290028197433893, "bleu_1": 12.021329255362238, "bleu_avg": 11.7}
{"acc_0": 90.4, "acc_1": 90.4, "acc_avg": 90.4}
{"_ACCU": 93.6, "_BLEU": 17.5}
-------avg_loss: 3.258585929870605e-07, lm_loss: 1.296559453010559--------
{"dev acc"：96.4}
{"bleu_0": 11.367836812225688, "bleu_1": 12.076950067692351, "bleu_avg": 11.7}
{"acc_0": 90.60000000000001, "acc_1": 89.8, "acc_avg": 90.2}
{"_ACCU": 93.7, "_BLEU": 17.5}
-------avg_loss: 3.1369924545288085e-07, lm_loss: 1.2585885524749756--------
{"dev acc"：96.6}
{"bleu_0": 11.504695703862179, "bleu_1": 12.054296769031573, "bleu_avg": 11.8}
{"acc_0": 89.8, "acc_1": 90.8, "acc_avg": 90.3}
{"_ACCU": 92.6, "_BLEU": 17.6}
-------avg_loss: 2.880096435546875e-07, lm_loss: 1.3281712532043457--------
{"dev acc"：96.8}
{"bleu_0": 11.769608753334657, "bleu_1": 12.25531116476031, "bleu_avg": 12.0}
{"acc_0": 90.8, "acc_1": 90.8, "acc_avg": 90.8}
{"_ACCU": 93.8, "_BLEU": 17.8}
-------avg_loss: 2.873539924621582e-07, lm_loss: 0.7792980670928955--------
{"dev acc"：96.7}
{"bleu_0": 11.433994110124537, "bleu_1": 12.292044084798457, "bleu_avg": 11.9}
{"acc_0": 90.2, "acc_1": 90.60000000000001, "acc_avg": 90.4}
{"_ACCU": 93.3, "_BLEU": 17.7}
-------avg_loss: 3.185868263244629e-07, lm_loss: 1.3678028583526611--------
{"dev acc"：96.5}
{"bleu_0": 11.483741513763944, "bleu_1": 12.000429175534606, "bleu_avg": 11.7}
{"acc_0": 90.2, "acc_1": 90.2, "acc_avg": 90.2}
{"_ACCU": 93.5, "_BLEU": 17.6}
-------avg_loss: 3.0779838562011717e-07, lm_loss: 1.020650029182434--------
{"dev acc"：96.7}
{"bleu_0": 11.44601330859395, "bleu_1": 12.195441901596379, "bleu_avg": 11.8}
{"acc_0": 88.4, "acc_1": 90.60000000000001, "acc_avg": 89.5}
{"_ACCU": 92.8, "_BLEU": 17.6}
-------avg_loss: 2.9683113098144534e-07, lm_loss: 1.3717222213745117--------
{"dev acc"：97.0}
{"bleu_0": 11.443436531465505, "bleu_1": 12.072394583140426, "bleu_avg": 11.8}
{"acc_0": 90.0, "acc_1": 91.0, "acc_avg": 90.5}
{"_ACCU": 93.8, "_BLEU": 17.5}
-------avg_loss: 2.9575824737548827e-07, lm_loss: 1.005867600440979--------
{"dev acc"：96.4}
{"bleu_0": 11.379426795483386, "bleu_1": 12.084555343869072, "bleu_avg": 11.7}
{"acc_0": 90.4, "acc_1": 90.0, "acc_avg": 90.2}
{"_ACCU": 93.0, "_BLEU": 17.5}
-------avg_loss: 2.802014350891113e-07, lm_loss: 1.431135892868042--------
{"dev acc"：96.7}
{"bleu_0": 11.465958301258139, "bleu_1": 12.222317694572238, "bleu_avg": 11.8}
{"acc_0": 91.2, "acc_1": 91.60000000000001, "acc_avg": 91.4}
{"_ACCU": 93.6, "_BLEU": 17.7}
-------avg_loss: 2.689361572265625e-07, lm_loss: 1.0941957235336304--------
{"dev acc"：96.6}
{"bleu_0": 11.522132812360896, "bleu_1": 11.955361794944872, "bleu_avg": 11.7}
{"acc_0": 90.4, "acc_1": 90.60000000000001, "acc_avg": 90.5}
{"_ACCU": 93.7, "_BLEU": 17.6}
-------avg_loss: 2.763867378234863e-07, lm_loss: 1.157312273979187--------
{"dev acc"：96.2}
{"bleu_0": 11.474748043348653, "bleu_1": 11.707284768552856, "bleu_avg": 11.6}
{"acc_0": 90.60000000000001, "acc_1": 90.4, "acc_avg": 90.5}
{"_ACCU": 93.7, "_BLEU": 17.4}
-------avg_loss: 2.802610397338867e-07, lm_loss: 1.0880951881408691--------
{"dev acc"：96.4}
{"bleu_0": 11.365721712948108, "bleu_1": 12.042944366883262, "bleu_avg": 11.7}
{"acc_0": 90.60000000000001, "acc_1": 91.8, "acc_avg": 91.2}
{"_ACCU": 93.7, "_BLEU": 17.5}
-------avg_loss: 2.7227401733398435e-07, lm_loss: 1.5127805471420288--------
{"dev acc"：96.3}
{"bleu_0": 11.557527912564899, "bleu_1": 11.799838289832726, "bleu_avg": 11.7}
{"acc_0": 90.60000000000001, "acc_1": 89.60000000000001, "acc_avg": 90.1}
{"_ACCU": 92.9, "_BLEU": 17.5}
-------avg_loss: 2.7692317962646484e-07, lm_loss: 1.4058514833450317--------
{"dev acc"：95.9}
{"bleu_0": 11.305446678616809, "bleu_1": 12.15240185231725, "bleu_avg": 11.7}
{"acc_0": 90.4, "acc_1": 91.60000000000001, "acc_avg": 91.0}
{"_ACCU": 94.1, "_BLEU": 17.5}
-------avg_loss: 2.721548080444336e-07, lm_loss: 1.134092092514038--------
{"dev acc"：96.3}
{"bleu_0": 11.514183362398976, "bleu_1": 12.148886855562818, "bleu_avg": 11.8}
{"acc_0": 89.4, "acc_1": 90.60000000000001, "acc_avg": 90.0}
{"_ACCU": 93.3, "_BLEU": 17.6}
-------avg_loss: 2.713799476623535e-07, lm_loss: 1.370025634765625--------
{"dev acc"：96.4}
{"bleu_0": 11.479076075395769, "bleu_1": 12.05935836660641, "bleu_avg": 11.8}
{"acc_0": 88.2, "acc_1": 90.8, "acc_avg": 89.5}
{"_ACCU": 92.4, "_BLEU": 17.5}
-------avg_loss: 2.5790929794311523e-07, lm_loss: 1.4230310916900635--------
{"dev acc"：96.0}
{"bleu_0": 11.450704464236171, "bleu_1": 12.206626871024206, "bleu_avg": 11.8}
{"acc_0": 89.8, "acc_1": 90.8, "acc_avg": 90.3}
{"_ACCU": 93.2, "_BLEU": 17.6}
Best result: dev_acc 97.3 acc 90.4 bleu 11.7 _acc 92.9 _bleu 17.6
Epoch:  40%|██████████████████████████████████████████████████████████████                                                                                             | 4/10 [2:36:29<3:54:17, 2342.99s/it]-------avg_loss: 2.630949020385742e-07, lm_loss: 0.7721713781356812--------
{"dev acc"：96.7}
{"bleu_0": 11.469345605320855, "bleu_1": 12.053039849277313, "bleu_avg": 11.8}
{"acc_0": 89.60000000000001, "acc_1": 90.8, "acc_avg": 90.2}
{"_ACCU": 93.7, "_BLEU": 17.6}
-------avg_loss: 2.6744604110717774e-07, lm_loss: 1.0160473585128784--------
{"dev acc"：96.7}
{"bleu_0": 11.540655376438975, "bleu_1": 12.121639917031702, "bleu_avg": 11.8}
{"acc_0": 91.4, "acc_1": 90.8, "acc_avg": 91.1}
{"_ACCU": 93.9, "_BLEU": 17.6}
-------avg_loss: 2.6845932006835935e-07, lm_loss: 1.0218781232833862--------
{"dev acc"：96.6}
{"bleu_0": 11.453056532137463, "bleu_1": 12.117997918620436, "bleu_avg": 11.8}
{"acc_0": 90.0, "acc_1": 90.60000000000001, "acc_avg": 90.3}
{"_ACCU": 93.4, "_BLEU": 17.7}
-------avg_loss: 2.6786327362060546e-07, lm_loss: 0.9033740162849426--------
{"dev acc"：96.5}
{"bleu_0": 11.755229241537501, "bleu_1": 11.814644442621274, "bleu_avg": 11.8}
{"acc_0": 90.2, "acc_1": 89.8, "acc_avg": 90.0}
{"_ACCU": 93.2, "_BLEU": 17.5}
-------avg_loss: 2.5326013565063475e-07, lm_loss: 0.9309107065200806--------
{"dev acc"：96.8}
{"bleu_0": 11.380690615988778, "bleu_1": 11.72666219215332, "bleu_avg": 11.6}
{"acc_0": 89.4, "acc_1": 90.2, "acc_avg": 89.8}
{"_ACCU": 93.6, "_BLEU": 17.5}
-------avg_loss: 2.561807632446289e-07, lm_loss: 0.967637300491333--------
{"dev acc"：96.2}
{"bleu_0": 11.462086298012922, "bleu_1": 11.845642806626733, "bleu_avg": 11.7}
{"acc_0": 90.60000000000001, "acc_1": 89.2, "acc_avg": 89.9}
{"_ACCU": 92.6, "_BLEU": 17.4}
-------avg_loss: 2.512335777282715e-07, lm_loss: 1.046528697013855--------
{"dev acc"：96.2}
{"bleu_0": 11.439560432835727, "bleu_1": 11.947754959350137, "bleu_avg": 11.7}
{"acc_0": 90.60000000000001, "acc_1": 90.4, "acc_avg": 90.5}
{"_ACCU": 93.5, "_BLEU": 17.6}
-------avg_loss: 2.543330192565918e-07, lm_loss: 0.9233241677284241--------
{"dev acc"：96.9}
{"bleu_0": 11.42492754598892, "bleu_1": 12.02087471998729, "bleu_avg": 11.7}
{"acc_0": 90.4, "acc_1": 90.2, "acc_avg": 90.3}
{"_ACCU": 93.2, "_BLEU": 17.5}
-------avg_loss: 2.599358558654785e-07, lm_loss: 1.183972716331482--------
{"dev acc"：96.2}
{"bleu_0": 11.411460113529998, "bleu_1": 12.072203557110042, "bleu_avg": 11.7}
{"acc_0": 90.0, "acc_1": 89.8, "acc_avg": 89.9}
{"_ACCU": 93.0, "_BLEU": 17.5}
-------avg_loss: 2.557635307312012e-07, lm_loss: 1.2396668195724487--------
{"dev acc"：96.7}
{"bleu_0": 11.495094984318879, "bleu_1": 11.885075195805204, "bleu_avg": 11.7}
{"acc_0": 90.4, "acc_1": 90.4, "acc_avg": 90.4}
{"_ACCU": 93.5, "_BLEU": 17.6}
-------avg_loss: 2.506375312805176e-07, lm_loss: 0.9872701168060303--------
{"dev acc"：96.9}
{"bleu_0": 11.49962215130911, "bleu_1": 12.10641576179405, "bleu_avg": 11.8}
{"acc_0": 90.2, "acc_1": 89.8, "acc_avg": 90.0}
{"_ACCU": 93.1, "_BLEU": 17.5}
-------avg_loss: 2.477169036865234e-07, lm_loss: 1.2182120084762573--------
{"dev acc"：96.5}
{"bleu_0": 11.541398833550673, "bleu_1": 12.14878095868153, "bleu_avg": 11.8}
{"acc_0": 89.4, "acc_1": 90.0, "acc_avg": 89.7}
{"_ACCU": 93.0, "_BLEU": 17.7}
-------avg_loss: 2.5272369384765626e-07, lm_loss: 1.1747468709945679--------
{"dev acc"：96.1}
{"bleu_0": 11.400595787639599, "bleu_1": 11.926275805548459, "bleu_avg": 11.7}
{"acc_0": 90.8, "acc_1": 88.8, "acc_avg": 89.8}
{"_ACCU": 93.3, "_BLEU": 17.5}
-------avg_loss: 2.55584716796875e-07, lm_loss: 1.00594961643219--------
{"dev acc"：96.6}
{"bleu_0": 11.251357647684246, "bleu_1": 11.910115013064724, "bleu_avg": 11.6}
{"acc_0": 91.60000000000001, "acc_1": 90.2, "acc_avg": 90.9}
{"_ACCU": 93.2, "_BLEU": 17.5}
-------avg_loss: 2.4253129959106445e-07, lm_loss: 1.18718421459198--------
{"dev acc"：95.9}
{"bleu_0": 11.501309429721404, "bleu_1": 11.693031516101149, "bleu_avg": 11.6}
{"acc_0": 89.0, "acc_1": 89.8, "acc_avg": 89.4}
{"_ACCU": 92.8, "_BLEU": 17.5}
-------avg_loss: 2.5182962417602537e-07, lm_loss: 1.008733868598938--------
{"dev acc"：96.5}
{"bleu_0": 11.565304201069235, "bleu_1": 11.819919303339057, "bleu_avg": 11.7}
{"acc_0": 90.4, "acc_1": 89.60000000000001, "acc_avg": 90.0}
{"_ACCU": 93.2, "_BLEU": 17.5}
-------avg_loss: 2.4324655532836916e-07, lm_loss: 1.0811669826507568--------
{"dev acc"：96.6}
{"bleu_0": 11.630757841627677, "bleu_1": 11.893132122906804, "bleu_avg": 11.8}
{"acc_0": 91.2, "acc_1": 90.4, "acc_avg": 90.8}
{"_ACCU": 93.9, "_BLEU": 17.5}
-------avg_loss: 2.4425983428955077e-07, lm_loss: 0.8890448808670044--------
{"dev acc"：96.1}
{"bleu_0": 11.470509569405328, "bleu_1": 11.94327466411831, "bleu_avg": 11.7}
{"acc_0": 90.4, "acc_1": 91.2, "acc_avg": 90.8}
{"_ACCU": 93.4, "_BLEU": 17.5}
-------avg_loss: 2.437233924865723e-07, lm_loss: 0.9676631689071655--------
{"dev acc"：96.2}
{"bleu_0": 11.471531442807322, "bleu_1": 11.603025407597531, "bleu_avg": 11.5}
{"acc_0": 89.4, "acc_1": 89.4, "acc_avg": 89.4}
{"_ACCU": 93.2, "_BLEU": 17.4}
-------avg_loss: 2.409815788269043e-07, lm_loss: 1.1264235973358154--------
{"dev acc"：96.7}
{"bleu_0": 11.367946713826585, "bleu_1": 11.984696076176714, "bleu_avg": 11.7}
{"acc_0": 90.0, "acc_1": 90.60000000000001, "acc_avg": 90.3}
{"_ACCU": 93.4, "_BLEU": 17.5}
-------avg_loss: 2.4247169494628904e-07, lm_loss: 1.4547611474990845--------
{"dev acc"：96.8}
{"bleu_0": 11.558445591828292, "bleu_1": 11.721734273372546, "bleu_avg": 11.6}
{"acc_0": 90.0, "acc_1": 90.60000000000001, "acc_avg": 90.3}
{"_ACCU": 93.2, "_BLEU": 17.5}
Best result: dev_acc 97.3 acc 90.4 bleu 11.7 _acc 92.9 _bleu 17.6
Epoch:  50%|█████████████████████████████████████████████████████████████████████████████▌                                                                             | 5/10 [3:15:26<3:15:06, 2341.28s/it]-------avg_loss: 2.396106719970703e-07, lm_loss: 1.0060889720916748--------
{"dev acc"：96.8}
{"bleu_0": 11.526119664248965, "bleu_1": 11.94623373186321, "bleu_avg": 11.7}
{"acc_0": 90.2, "acc_1": 90.0, "acc_avg": 90.1}
{"_ACCU": 93.4, "_BLEU": 17.6}
-------avg_loss: 2.4437904357910154e-07, lm_loss: 0.7060949802398682--------
{"dev acc"：96.4}
{"bleu_0": 11.271827218951843, "bleu_1": 11.864805340434351, "bleu_avg": 11.6}
{"acc_0": 90.4, "acc_1": 90.2, "acc_avg": 90.3}
{"_ACCU": 93.3, "_BLEU": 17.4}
-------avg_loss: 2.439022064208984e-07, lm_loss: 1.195129156112671--------
{"dev acc"：96.0}
{"bleu_0": 11.566883924655448, "bleu_1": 11.902247059290563, "bleu_avg": 11.7}
{"acc_0": 90.2, "acc_1": 89.60000000000001, "acc_avg": 89.9}
{"_ACCU": 93.3, "_BLEU": 17.6}
-------avg_loss: 2.3609399795532226e-07, lm_loss: 1.0706504583358765--------
{"dev acc"：96.1}
{"bleu_0": 11.460214238291076, "bleu_1": 12.370303938473656, "bleu_avg": 11.9}
{"acc_0": 90.2, "acc_1": 89.4, "acc_avg": 89.8}
{"_ACCU": 93.0, "_BLEU": 17.6}
-------avg_loss: 2.409219741821289e-07, lm_loss: 1.1749440431594849--------
{"dev acc"：96.3}
{"bleu_0": 11.422477837218786, "bleu_1": 12.04807017164499, "bleu_avg": 11.7}
{"acc_0": 90.60000000000001, "acc_1": 91.0, "acc_avg": 90.8}
{"_ACCU": 93.3, "_BLEU": 17.6}
-------avg_loss: 2.459883689880371e-07, lm_loss: 1.2098246812820435--------
{"dev acc"：96.7}
{"bleu_0": 11.482420407005979, "bleu_1": 11.676921358852026, "bleu_avg": 11.6}
{"acc_0": 90.0, "acc_1": 90.60000000000001, "acc_avg": 90.3}
{"_ACCU": 93.7, "_BLEU": 17.4}
-------avg_loss: 2.3698806762695312e-07, lm_loss: 1.0152984857559204--------
{"dev acc"：96.2}
{"bleu_0": 11.366261786841338, "bleu_1": 11.80537941470869, "bleu_avg": 11.6}
{"acc_0": 90.4, "acc_1": 90.2, "acc_avg": 90.3}
{"_ACCU": 94.0, "_BLEU": 17.5}
-------avg_loss: 2.45213508605957e-07, lm_loss: 0.8888455629348755--------
{"dev acc"：96.0}
{"bleu_0": 11.418622400611559, "bleu_1": 11.704025566737927, "bleu_avg": 11.6}
{"acc_0": 91.4, "acc_1": 90.0, "acc_avg": 90.7}
{"_ACCU": 93.2, "_BLEU": 17.5}
-------avg_loss: 2.4080276489257813e-07, lm_loss: 1.1330748796463013--------
{"dev acc"：96.2}
{"bleu_0": 11.298896833733059, "bleu_1": 11.578442706949334, "bleu_avg": 11.4}
{"acc_0": 89.8, "acc_1": 90.0, "acc_avg": 89.9}
{"_ACCU": 94.1, "_BLEU": 17.3}
-------avg_loss: 2.433061599731445e-07, lm_loss: 1.3358525037765503--------
{"dev acc"：96.3}
{"bleu_0": 11.511745028646702, "bleu_1": 11.696954898662486, "bleu_avg": 11.6}
{"acc_0": 91.0, "acc_1": 90.0, "acc_avg": 90.5}
{"_ACCU": 93.6, "_BLEU": 17.4}
-------avg_loss: 2.3251771926879882e-07, lm_loss: 1.029818058013916--------
{"dev acc"：96.3}
{"bleu_0": 11.346225914330889, "bleu_1": 11.993066076490337, "bleu_avg": 11.7}
{"acc_0": 89.8, "acc_1": 89.60000000000001, "acc_avg": 89.7}
{"_ACCU": 93.2, "_BLEU": 17.6}
-------avg_loss: 2.345442771911621e-07, lm_loss: 0.9925521612167358--------
{"dev acc"：96.6}
{"bleu_0": 11.368059346149805, "bleu_1": 11.78490547875569, "bleu_avg": 11.6}
{"acc_0": 89.8, "acc_1": 89.2, "acc_avg": 89.5}
{"_ACCU": 93.3, "_BLEU": 17.5}
-------avg_loss: 2.399086952209473e-07, lm_loss: 0.9861140251159668--------
{"dev acc"：96.7}
{"bleu_0": 11.440909171411283, "bleu_1": 11.918643545354522, "bleu_avg": 11.7}
{"acc_0": 90.60000000000001, "acc_1": 89.60000000000001, "acc_avg": 90.1}
{"_ACCU": 93.3, "_BLEU": 17.5}
-------avg_loss: 2.2989511489868165e-07, lm_loss: 0.9247728586196899--------
{"dev acc"：96.2}
{"bleu_0": 11.513511794395077, "bleu_1": 11.91012299689672, "bleu_avg": 11.7}
{"acc_0": 90.4, "acc_1": 88.6, "acc_avg": 89.5}
{"_ACCU": 93.1, "_BLEU": 17.6}
-------avg_loss: 2.4020671844482423e-07, lm_loss: 0.9807153940200806--------
{"dev acc"：96.5}
{"bleu_0": 11.434346486281346, "bleu_1": 11.734102775276103, "bleu_avg": 11.6}
{"acc_0": 90.4, "acc_1": 90.0, "acc_avg": 90.2}
{"_ACCU": 93.4, "_BLEU": 17.5}
-------avg_loss: 2.332329750061035e-07, lm_loss: 0.921347975730896--------
{"dev acc"：96.5}
{"bleu_0": 11.517360417549021, "bleu_1": 11.956291892951034, "bleu_avg": 11.7}
{"acc_0": 91.2, "acc_1": 91.60000000000001, "acc_avg": 91.4}
{"_ACCU": 94.1, "_BLEU": 17.6}
-------avg_loss: 2.319812774658203e-07, lm_loss: 1.0032925605773926--------
{"dev acc"：96.8}
{"bleu_0": 11.404396839730659, "bleu_1": 11.958791169949388, "bleu_avg": 11.7}
{"acc_0": 89.8, "acc_1": 90.0, "acc_avg": 89.9}
{"_ACCU": 93.3, "_BLEU": 17.6}
-------avg_loss: 2.3430585861206055e-07, lm_loss: 0.9127339720726013--------
{"dev acc"：96.1}
{"bleu_0": 11.34630977089406, "bleu_1": 11.925165108761679, "bleu_avg": 11.6}
{"acc_0": 91.4, "acc_1": 89.0, "acc_avg": 90.2}
{"_ACCU": 93.7, "_BLEU": 17.5}
-------avg_loss: 2.340078353881836e-07, lm_loss: 0.9682549834251404--------
{"dev acc"：96.7}
{"bleu_0": 11.411127534885166, "bleu_1": 11.741372270049624, "bleu_avg": 11.6}
{"acc_0": 89.8, "acc_1": 90.8, "acc_avg": 90.3}
{"_ACCU": 92.8, "_BLEU": 17.5}
-------avg_loss: 2.3943185806274416e-07, lm_loss: 1.3549169301986694--------
{"dev acc"：96.4}
{"bleu_0": 11.704725492919554, "bleu_1": 11.972233180062227, "bleu_avg": 11.8}
{"acc_0": 90.0, "acc_1": 89.0, "acc_avg": 89.5}
{"_ACCU": 93.0, "_BLEU": 17.6}
-------avg_loss: 2.340078353881836e-07, lm_loss: 1.1562471389770508--------
{"dev acc"：96.4}
{"bleu_0": 11.340039952060966, "bleu_1": 11.899572931534564, "bleu_avg": 11.6}
{"acc_0": 91.0, "acc_1": 88.8, "acc_avg": 89.9}
{"_ACCU": 93.6, "_BLEU": 17.4}
Best result: dev_acc 97.3 acc 90.4 bleu 11.7 _acc 92.9 _bleu 17.6
Epoch:  60%|█████████████████████████████████████████████████████████████████████████████████████████████                                                              | 6/10 [3:54:18<2:35:53, 2338.36s/it]-------avg_loss: 2.3257732391357423e-07, lm_loss: 1.0144524574279785--------
{"dev acc"：96.8}
{"bleu_0": 11.681329932342596, "bleu_1": 12.096263992278384, "bleu_avg": 11.9}
{"acc_0": 89.8, "acc_1": 88.6, "acc_avg": 89.2}
{"_ACCU": 92.7, "_BLEU": 17.5}
-------avg_loss: 2.333521842956543e-07, lm_loss: 1.0472068786621094--------
{"dev acc"：96.1}
{"bleu_0": 11.462239569737086, "bleu_1": 12.340301377236177, "bleu_avg": 11.9}
{"acc_0": 90.2, "acc_1": 90.60000000000001, "acc_avg": 90.4}
{"_ACCU": 92.9, "_BLEU": 17.6}
-------avg_loss: 2.4378299713134765e-07, lm_loss: 0.96561598777771--------
{"dev acc"：96.6}
{"bleu_0": 11.774751101248938, "bleu_1": 11.848398956586346, "bleu_avg": 11.8}
{"acc_0": 90.8, "acc_1": 89.8, "acc_avg": 90.3}
{"_ACCU": 92.9, "_BLEU": 17.5}
-------avg_loss: 2.3382902145385742e-07, lm_loss: 1.010603904724121--------
{"dev acc"：96.7}
{"bleu_0": 11.522038771785159, "bleu_1": 11.927582206842047, "bleu_avg": 11.7}
{"acc_0": 89.8, "acc_1": 90.8, "acc_avg": 90.3}
{"_ACCU": 93.5, "_BLEU": 17.5}
-------avg_loss: 2.3615360260009767e-07, lm_loss: 0.9328661561012268--------
{"dev acc"：96.2}
{"bleu_0": 11.564230702154273, "bleu_1": 11.88390897920672, "bleu_avg": 11.7}
{"acc_0": 90.60000000000001, "acc_1": 90.60000000000001, "acc_avg": 90.6}
{"_ACCU": 93.7, "_BLEU": 17.6}
-------avg_loss: 2.3341178894042968e-07, lm_loss: 1.1650739908218384--------
{"dev acc"：96.1}
{"bleu_0": 11.628226722524053, "bleu_1": 11.797926909051926, "bleu_avg": 11.7}
{"acc_0": 90.2, "acc_1": 90.4, "acc_avg": 90.3}
{"_ACCU": 92.6, "_BLEU": 17.6}
-------avg_loss: 2.3102760314941406e-07, lm_loss: 0.7275364995002747--------
{"dev acc"：96.9}
{"bleu_0": 11.575193387473293, "bleu_1": 12.344084108171625, "bleu_avg": 12.0}
{"acc_0": 90.4, "acc_1": 88.6, "acc_avg": 89.5}
{"_ACCU": 92.8, "_BLEU": 17.7}
-------avg_loss: 2.418160438537598e-07, lm_loss: 1.0163483619689941--------
{"dev acc"：95.9}
{"bleu_0": 11.354027810352935, "bleu_1": 11.755223094026592, "bleu_avg": 11.6}
{"acc_0": 90.60000000000001, "acc_1": 90.2, "acc_avg": 90.4}
{"_ACCU": 93.8, "_BLEU": 17.5}
-------avg_loss: 2.340078353881836e-07, lm_loss: 1.0630810260772705--------
{"dev acc"：96.4}
{"bleu_0": 11.532408619264169, "bleu_1": 11.840158290728855, "bleu_avg": 11.7}
{"acc_0": 90.2, "acc_1": 89.8, "acc_avg": 90.0}
{"_ACCU": 93.0, "_BLEU": 17.6}
-------avg_loss: 2.3120641708374023e-07, lm_loss: 0.8366336822509766--------
{"dev acc"：95.9}
{"bleu_0": 11.30067077843546, "bleu_1": 11.938011599399948, "bleu_avg": 11.6}
{"acc_0": 90.0, "acc_1": 89.0, "acc_avg": 89.5}
{"_ACCU": 92.8, "_BLEU": 17.5}
-------avg_loss: 2.3365020751953125e-07, lm_loss: 1.0755161046981812--------
{"dev acc"：96.5}
{"bleu_0": 11.617857154396171, "bleu_1": 11.956278864416705, "bleu_avg": 11.8}
{"acc_0": 90.2, "acc_1": 89.4, "acc_avg": 89.8}
{"_ACCU": 93.0, "_BLEU": 17.6}
-------avg_loss: 2.281665802001953e-07, lm_loss: 0.849531352519989--------
{"dev acc"：96.2}
{"bleu_0": 11.555758112422474, "bleu_1": 12.1370688796846, "bleu_avg": 11.8}
{"acc_0": 90.4, "acc_1": 89.60000000000001, "acc_avg": 90.0}
{"_ACCU": 92.8, "_BLEU": 17.6}
-------avg_loss: 2.3561716079711913e-07, lm_loss: 1.4036245346069336--------
{"dev acc"：95.9}
{"bleu_0": 11.478488740096978, "bleu_1": 11.898893922338623, "bleu_avg": 11.7}
{"acc_0": 90.0, "acc_1": 90.0, "acc_avg": 90.0}
{"_ACCU": 93.2, "_BLEU": 17.5}
-------avg_loss: 2.3001432418823242e-07, lm_loss: 0.943138062953949--------
{"dev acc"：96.1}
{"bleu_0": 11.41102375462209, "bleu_1": 11.75622955790362, "bleu_avg": 11.6}
{"acc_0": 90.8, "acc_1": 90.0, "acc_avg": 90.4}
{"_ACCU": 93.2, "_BLEU": 17.5}
-------avg_loss: 2.3549795150756836e-07, lm_loss: 1.0553375482559204--------
{"dev acc"：95.8}
{"bleu_0": 11.50097217207297, "bleu_1": 11.99000943318856, "bleu_avg": 11.7}
{"acc_0": 91.0, "acc_1": 91.0, "acc_avg": 91.0}
{"_ACCU": 93.6, "_BLEU": 17.6}
-------avg_loss: 2.308487892150879e-07, lm_loss: 0.9356219172477722--------
{"dev acc"：96.5}
{"bleu_0": 11.36661645618862, "bleu_1": 11.912428104579172, "bleu_avg": 11.6}
{"acc_0": 89.60000000000001, "acc_1": 89.2, "acc_avg": 89.4}
{"_ACCU": 93.0, "_BLEU": 17.5}
-------avg_loss: 2.3531913757324218e-07, lm_loss: 1.0945419073104858--------
{"dev acc"：96.2}
{"bleu_0": 11.329697109706242, "bleu_1": 11.949870699258202, "bleu_avg": 11.6}
{"acc_0": 90.60000000000001, "acc_1": 89.0, "acc_avg": 89.8}
{"_ACCU": 92.4, "_BLEU": 17.6}
-------avg_loss: 2.3764371871948243e-07, lm_loss: 0.8758684992790222--------
{"dev acc"：96.5}
{"bleu_0": 11.49919777025688, "bleu_1": 12.087326047570434, "bleu_avg": 11.8}
{"acc_0": 89.8, "acc_1": 89.2, "acc_avg": 89.5}
{"_ACCU": 92.7, "_BLEU": 17.6}
-------avg_loss: 2.326369285583496e-07, lm_loss: 0.8860774040222168--------
{"dev acc"：95.8}
{"bleu_0": 11.294731432377288, "bleu_1": 12.205008325748995, "bleu_avg": 11.7}
{"acc_0": 90.4, "acc_1": 89.4, "acc_avg": 89.9}
{"_ACCU": 92.9, "_BLEU": 17.6}
-------avg_loss: 2.396702766418457e-07, lm_loss: 0.9734716415405273--------
{"dev acc"：96.0}
{"bleu_0": 11.475903531663088, "bleu_1": 12.112693110444594, "bleu_avg": 11.8}
{"acc_0": 90.4, "acc_1": 89.4, "acc_avg": 89.9}
{"_ACCU": 93.0, "_BLEU": 17.6}
-------avg_loss: 2.3043155670166016e-07, lm_loss: 1.2305723428726196--------
{"dev acc"：96.3}
{"bleu_0": 11.517476457433826, "bleu_1": 11.933330724161062, "bleu_avg": 11.7}
{"acc_0": 90.0, "acc_1": 90.0, "acc_avg": 90.0}
{"_ACCU": 92.6, "_BLEU": 17.5}
Best result: dev_acc 97.3 acc 90.4 bleu 11.7 _acc 92.9 _bleu 17.6
Epoch:  70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                              | 7/10 [4:33:24<1:57:02, 2340.71s/it]-------avg_loss: 2.366304397583008e-07, lm_loss: 0.7781181931495667--------
{"dev acc"：95.8}
{"bleu_0": 11.38986983403674, "bleu_1": 11.76675027233857, "bleu_avg": 11.6}
{"acc_0": 89.8, "acc_1": 89.60000000000001, "acc_avg": 89.7}
{"_ACCU": 93.3, "_BLEU": 17.4}
-------avg_loss: 2.3299455642700194e-07, lm_loss: 1.1192004680633545--------
{"dev acc"：96.5}
{"bleu_0": 11.613214208479757, "bleu_1": 11.98676098024314, "bleu_avg": 11.8}
{"acc_0": 90.4, "acc_1": 89.0, "acc_avg": 89.7}
{"_ACCU": 92.4, "_BLEU": 17.7}
-------avg_loss: 2.3347139358520507e-07, lm_loss: 1.0394896268844604--------
{"dev acc"：95.9}
{"bleu_0": 11.40031521588723, "bleu_1": 11.898973036878267, "bleu_avg": 11.6}
{"acc_0": 90.60000000000001, "acc_1": 88.8, "acc_avg": 89.7}
{"_ACCU": 92.6, "_BLEU": 17.5}
-------avg_loss: 2.328157424926758e-07, lm_loss: 0.9390392303466797--------
{"dev acc"：96.4}
{"bleu_0": 11.468709094493105, "bleu_1": 11.728347054475616, "bleu_avg": 11.6}
{"acc_0": 90.60000000000001, "acc_1": 89.60000000000001, "acc_avg": 90.1}
{"_ACCU": 93.5, "_BLEU": 17.5}
-------avg_loss: 2.281665802001953e-07, lm_loss: 1.2490875720977783--------
{"dev acc"：95.6}
{"bleu_0": 11.374775248223633, "bleu_1": 12.075462236756056, "bleu_avg": 11.7}
{"acc_0": 91.8, "acc_1": 90.2, "acc_avg": 91.0}
{"_ACCU": 93.5, "_BLEU": 17.6}
-------avg_loss: 2.2876262664794922e-07, lm_loss: 1.0278711318969727--------
{"dev acc"：96.4}
{"bleu_0": 11.836900154349044, "bleu_1": 11.855870636443194, "bleu_avg": 11.8}
{"acc_0": 90.2, "acc_1": 90.8, "acc_avg": 90.5}
{"_ACCU": 93.6, "_BLEU": 17.6}
-------avg_loss: 2.289414405822754e-07, lm_loss: 0.9023106098175049--------
{"dev acc"：96.0}
{"bleu_0": 11.426906574735392, "bleu_1": 11.84053258024872, "bleu_avg": 11.6}
{"acc_0": 90.2, "acc_1": 90.4, "acc_avg": 90.3}
{"_ACCU": 92.8, "_BLEU": 17.4}
-------avg_loss: 2.3448467254638673e-07, lm_loss: 1.1486399173736572--------
{"dev acc"：96.2}
{"bleu_0": 11.425626105699896, "bleu_1": 12.05421086913453, "bleu_avg": 11.7}
{"acc_0": 90.2, "acc_1": 89.8, "acc_avg": 90.0}
{"_ACCU": 93.1, "_BLEU": 17.6}
-------avg_loss: 2.3359060287475586e-07, lm_loss: 1.2227199077606201--------
{"dev acc"：95.7}
{"bleu_0": 11.519940028862639, "bleu_1": 11.844719326622922, "bleu_avg": 11.7}
{"acc_0": 90.4, "acc_1": 90.4, "acc_avg": 90.4}
{"_ACCU": 92.9, "_BLEU": 17.6}
-------avg_loss: 2.2870302200317384e-07, lm_loss: 1.0528607368469238--------
{"dev acc"：96.3}
{"bleu_0": 11.423154939018772, "bleu_1": 11.871612697779534, "bleu_avg": 11.6}
{"acc_0": 90.60000000000001, "acc_1": 90.60000000000001, "acc_avg": 90.6}
{"_ACCU": 93.8, "_BLEU": 17.5}
-------avg_loss: 2.3221969604492187e-07, lm_loss: 1.0900931358337402--------
{"dev acc"：96.7}
{"bleu_0": 11.415818490168341, "bleu_1": 12.50746726090278, "bleu_avg": 12.0}
{"acc_0": 91.60000000000001, "acc_1": 88.6, "acc_avg": 90.1}
{"_ACCU": 93.1, "_BLEU": 17.7}
-------avg_loss: 2.326369285583496e-07, lm_loss: 0.9520940184593201--------
{"dev acc"：96.1}
{"bleu_0": 11.634644571638505, "bleu_1": 11.812285271562077, "bleu_avg": 11.7}
{"acc_0": 90.8, "acc_1": 90.2, "acc_avg": 90.5}
{"_ACCU": 93.2, "_BLEU": 17.5}
-------avg_loss: 2.2554397583007811e-07, lm_loss: 0.9430485367774963--------
{"dev acc"：96.8}
{"bleu_0": 11.493909492356934, "bleu_1": 11.904717519868317, "bleu_avg": 11.7}
{"acc_0": 91.2, "acc_1": 90.60000000000001, "acc_avg": 90.9}
{"_ACCU": 93.5, "_BLEU": 17.5}
-------avg_loss: 2.3245811462402343e-07, lm_loss: 0.9098849296569824--------
{"dev acc"：95.8}
{"bleu_0": 11.541229377698134, "bleu_1": 12.068333002550542, "bleu_avg": 11.8}
{"acc_0": 90.4, "acc_1": 89.4, "acc_avg": 89.9}
{"_ACCU": 93.7, "_BLEU": 17.7}
-------avg_loss: 2.2804737091064454e-07, lm_loss: 0.9229481220245361--------
{"dev acc"：96.0}
{"bleu_0": 11.451155297509708, "bleu_1": 12.272536484578108, "bleu_avg": 11.9}
{"acc_0": 90.60000000000001, "acc_1": 89.0, "acc_avg": 89.8}
{"_ACCU": 92.9, "_BLEU": 17.6}
-------avg_loss: 2.3162364959716798e-07, lm_loss: 0.8879536390304565--------
{"dev acc"：96.7}
{"bleu_0": 11.338008364687422, "bleu_1": 12.169579875105187, "bleu_avg": 11.8}
{"acc_0": 90.60000000000001, "acc_1": 90.0, "acc_avg": 90.3}
{"_ACCU": 93.0, "_BLEU": 17.6}
-------avg_loss: 2.332329750061035e-07, lm_loss: 1.1718432903289795--------
{"dev acc"：96.7}
{"bleu_0": 11.723427813928858, "bleu_1": 12.073181443858063, "bleu_avg": 11.9}
{"acc_0": 90.8, "acc_1": 89.8, "acc_avg": 90.3}
{"_ACCU": 92.8, "_BLEU": 17.7}
-------avg_loss: 2.2524595260620117e-07, lm_loss: 0.841359555721283--------
{"dev acc"：95.5}
{"bleu_0": 11.31401401079751, "bleu_1": 12.150770547646731, "bleu_avg": 11.7}
{"acc_0": 90.2, "acc_1": 87.8, "acc_avg": 89.0}
{"_ACCU": 93.0, "_BLEU": 17.5}
-------avg_loss: 2.2858381271362304e-07, lm_loss: 1.1039921045303345--------
{"dev acc"：95.9}
{"bleu_0": 11.540078043977836, "bleu_1": 11.876276997414106, "bleu_avg": 11.7}
{"acc_0": 90.2, "acc_1": 88.4, "acc_avg": 89.3}
{"_ACCU": 92.7, "_BLEU": 17.6}
-------avg_loss: 2.3049116134643555e-07, lm_loss: 1.0980576276779175--------
{"dev acc"：95.8}
{"bleu_0": 11.606189311742586, "bleu_1": 11.866336259652622, "bleu_avg": 11.7}
{"acc_0": 90.8, "acc_1": 88.8, "acc_avg": 89.8}
{"_ACCU": 93.3, "_BLEU": 17.5}
-------avg_loss: 2.573728561401367e-07, lm_loss: 0.8245589733123779--------
{"dev acc"：96.5}
{"bleu_0": 11.55164519313578, "bleu_1": 12.016197678128165, "bleu_avg": 11.8}
{"acc_0": 90.8, "acc_1": 89.60000000000001, "acc_avg": 90.2}
{"_ACCU": 92.7, "_BLEU": 17.6}
Best result: dev_acc 97.3 acc 90.4 bleu 11.7 _acc 92.9 _bleu 17.6
Epoch:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 8/10 [5:12:28<1:18:03, 2341.59s/it]-------avg_loss: 2.309083938598633e-07, lm_loss: 1.2761787176132202--------
{"dev acc"：96.2}
{"bleu_0": 11.360275108593251, "bleu_1": 11.711797598880349, "bleu_avg": 11.5}
{"acc_0": 90.4, "acc_1": 89.60000000000001, "acc_avg": 90.0}
{"_ACCU": 93.3, "_BLEU": 17.4}
-------avg_loss: 2.3412704467773437e-07, lm_loss: 1.1143707036972046--------
{"dev acc"：96.1}
{"bleu_0": 11.311405649036498, "bleu_1": 12.074936829509985, "bleu_avg": 11.7}
{"acc_0": 90.0, "acc_1": 88.8, "acc_avg": 89.4}
{"_ACCU": 92.7, "_BLEU": 17.5}
-------avg_loss: 2.3305416107177735e-07, lm_loss: 1.0886082649230957--------
{"dev acc"：96.2}
{"bleu_0": 11.486100878364253, "bleu_1": 12.014974795712467, "bleu_avg": 11.8}
{"acc_0": 91.0, "acc_1": 90.0, "acc_avg": 90.5}
{"_ACCU": 93.9, "_BLEU": 17.6}
-------avg_loss: 2.2941827774047853e-07, lm_loss: 1.1475136280059814--------
{"dev acc"：96.1}
{"bleu_0": 11.469083113008667, "bleu_1": 11.999819764141293, "bleu_avg": 11.7}
{"acc_0": 90.60000000000001, "acc_1": 89.8, "acc_avg": 90.2}
{"_ACCU": 93.0, "_BLEU": 17.5}
-------avg_loss: 2.2709369659423828e-07, lm_loss: 1.0177918672561646--------
{"dev acc"：96.5}
{"bleu_0": 11.564959086454534, "bleu_1": 12.00035916739125, "bleu_avg": 11.8}
{"acc_0": 91.0, "acc_1": 90.0, "acc_avg": 90.5}
{"_ACCU": 93.4, "_BLEU": 17.6}
-------avg_loss: 2.320408821105957e-07, lm_loss: 1.1353158950805664--------
{"dev acc"：95.7}
{"bleu_0": 11.61993680093739, "bleu_1": 12.153989499668082, "bleu_avg": 11.9}
{"acc_0": 91.2, "acc_1": 90.2, "acc_avg": 90.7}
{"_ACCU": 93.4, "_BLEU": 17.5}
-------avg_loss: 2.301931381225586e-07, lm_loss: 0.7601540088653564--------
{"dev acc"：96.1}
{"bleu_0": 11.535610713126065, "bleu_1": 11.955327130305784, "bleu_avg": 11.7}
{"acc_0": 90.60000000000001, "acc_1": 88.8, "acc_avg": 89.7}
{"_ACCU": 93.4, "_BLEU": 17.6}
-------avg_loss: 2.307295799255371e-07, lm_loss: 0.8333181142807007--------
{"dev acc"：95.9}
{"bleu_0": 11.42994038621313, "bleu_1": 11.783904395747482, "bleu_avg": 11.6}
{"acc_0": 91.2, "acc_1": 90.4, "acc_avg": 90.8}
{"_ACCU": 93.3, "_BLEU": 17.5}
-------avg_loss: 2.3114681243896485e-07, lm_loss: 1.3462002277374268--------
{"dev acc"：96.0}
{"bleu_0": 11.378365986958814, "bleu_1": 11.74766065672874, "bleu_avg": 11.6}
{"acc_0": 90.8, "acc_1": 89.8, "acc_avg": 90.3}
{"_ACCU": 93.6, "_BLEU": 17.4}
-------avg_loss: 2.321004867553711e-07, lm_loss: 0.8927515149116516--------
{"dev acc"：95.9}
{"bleu_0": 11.289254452555863, "bleu_1": 11.86950828553158, "bleu_avg": 11.6}
{"acc_0": 91.0, "acc_1": 91.60000000000001, "acc_avg": 91.3}
{"_ACCU": 94.2, "_BLEU": 17.5}
-------avg_loss: 2.326369285583496e-07, lm_loss: 1.0706610679626465--------
{"dev acc"：96.2}
{"bleu_0": 11.328012950915047, "bleu_1": 11.865950342491185, "bleu_avg": 11.6}
{"acc_0": 91.0, "acc_1": 89.8, "acc_avg": 90.4}
{"_ACCU": 93.6, "_BLEU": 17.4}
-------avg_loss: 2.2721290588378905e-07, lm_loss: 1.061323881149292--------
{"dev acc"：96.4}
{"bleu_0": 11.36139351887864, "bleu_1": 11.743711224703558, "bleu_avg": 11.6}
{"acc_0": 90.4, "acc_1": 89.8, "acc_avg": 90.1}
{"_ACCU": 93.5, "_BLEU": 17.4}
-------avg_loss: 2.308487892150879e-07, lm_loss: 0.8944479823112488--------
{"dev acc"：95.9}
{"bleu_0": 11.339370611651619, "bleu_1": 11.865416444307614, "bleu_avg": 11.6}
{"acc_0": 90.8, "acc_1": 90.2, "acc_avg": 90.5}
{"_ACCU": 93.9, "_BLEU": 17.5}
-------avg_loss: 2.3484230041503906e-07, lm_loss: 1.1053466796875--------
{"dev acc"：96.2}
{"bleu_0": 11.702719537813186, "bleu_1": 11.976398599465197, "bleu_avg": 11.8}
{"acc_0": 90.60000000000001, "acc_1": 91.4, "acc_avg": 91.0}
{"_ACCU": 93.6, "_BLEU": 17.5}
-------avg_loss: 2.32696533203125e-07, lm_loss: 1.1938118934631348--------
{"dev acc"：95.9}
{"bleu_0": 11.36670003564562, "bleu_1": 12.146326574280572, "bleu_avg": 11.8}
{"acc_0": 91.4, "acc_1": 89.2, "acc_avg": 90.3}
{"_ACCU": 93.1, "_BLEU": 17.5}
-------avg_loss: 2.282857894897461e-07, lm_loss: 1.1624575853347778--------
{"dev acc"：96.1}
{"bleu_0": 11.282263718781307, "bleu_1": 11.841017581768153, "bleu_avg": 11.6}
{"acc_0": 91.0, "acc_1": 89.60000000000001, "acc_avg": 90.3}
{"_ACCU": 93.5, "_BLEU": 17.5}
-------avg_loss: 2.3299455642700194e-07, lm_loss: 1.0038282871246338--------
{"dev acc"：95.8}
{"bleu_0": 11.355310099808971, "bleu_1": 12.059746873685631, "bleu_avg": 11.7}
{"acc_0": 90.8, "acc_1": 89.8, "acc_avg": 90.3}
{"_ACCU": 93.3, "_BLEU": 17.6}
-------avg_loss: 2.295374870300293e-07, lm_loss: 1.2046278715133667--------
{"dev acc"：96.4}
{"bleu_0": 11.27892779025496, "bleu_1": 11.913729736594084, "bleu_avg": 11.6}
{"acc_0": 91.0, "acc_1": 90.2, "acc_avg": 90.6}
{"_ACCU": 93.2, "_BLEU": 17.4}
-------avg_loss: 2.2733211517333985e-07, lm_loss: 0.8823854327201843--------
{"dev acc"：95.9}
{"bleu_0": 11.383314142527066, "bleu_1": 12.130585960641476, "bleu_avg": 11.8}
{"acc_0": 91.4, "acc_1": 90.0, "acc_avg": 90.7}
{"_ACCU": 93.9, "_BLEU": 17.6}
-------avg_loss: 2.3418664932250976e-07, lm_loss: 1.0421751737594604--------
{"dev acc"：96.2}
{"bleu_0": 11.52340487466286, "bleu_1": 11.74646180787086, "bleu_avg": 11.6}
{"acc_0": 91.2, "acc_1": 89.8, "acc_avg": 90.5}
{"_ACCU": 93.3, "_BLEU": 17.5}
-------avg_loss: 2.3061037063598634e-07, lm_loss: 1.002765417098999--------
{"dev acc"：96.4}
{"bleu_0": 11.314362374647862, "bleu_1": 11.76899836334176, "bleu_avg": 11.5}
{"acc_0": 90.2, "acc_1": 88.6, "acc_avg": 89.4}
{"_ACCU": 92.8, "_BLEU": 17.4}
Best result: dev_acc 97.3 acc 90.4 bleu 11.7 _acc 92.9 _bleu 17.6
Epoch:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 9/10 [5:51:15<38:57, 2337.26s/it]-------avg_loss: 2.2941827774047853e-07, lm_loss: 1.189928650856018--------
{"dev acc"：96.0}
{"bleu_0": 11.4036693431646, "bleu_1": 11.948513875619977, "bleu_avg": 11.7}
{"acc_0": 90.8, "acc_1": 89.4, "acc_avg": 90.1}
{"_ACCU": 93.1, "_BLEU": 17.5}
-------avg_loss: 2.2977590560913086e-07, lm_loss: 0.9410340189933777--------
{"dev acc"：96.0}
{"bleu_0": 11.572749938714647, "bleu_1": 12.024603892940107, "bleu_avg": 11.8}
{"acc_0": 91.60000000000001, "acc_1": 89.2, "acc_avg": 90.4}
{"_ACCU": 93.2, "_BLEU": 17.5}
-------avg_loss: 2.3317337036132812e-07, lm_loss: 1.5075433254241943--------
{"dev acc"：96.2}
{"bleu_0": 11.305336385962422, "bleu_1": 11.950581608092946, "bleu_avg": 11.6}
{"acc_0": 90.60000000000001, "acc_1": 91.0, "acc_avg": 90.8}
{"_ACCU": 93.7, "_BLEU": 17.5}
-------avg_loss: 2.2864341735839843e-07, lm_loss: 1.1208254098892212--------
{"dev acc"：96.1}
{"bleu_0": 11.586679187852193, "bleu_1": 11.955455234287523, "bleu_avg": 11.8}
{"acc_0": 91.60000000000001, "acc_1": 90.2, "acc_avg": 90.9}
{"_ACCU": 93.2, "_BLEU": 17.6}
-------avg_loss: 2.262592315673828e-07, lm_loss: 1.0570091009140015--------
{"dev acc"：95.9}
{"bleu_0": 11.473898336796044, "bleu_1": 12.2735569604801, "bleu_avg": 11.9}
{"acc_0": 91.8, "acc_1": 90.2, "acc_avg": 91.0}
{"_ACCU": 94.1, "_BLEU": 17.6}
-------avg_loss: 2.3347139358520507e-07, lm_loss: 1.2297776937484741--------
{"dev acc"：95.4}
{"bleu_0": 11.43213128459586, "bleu_1": 11.679475334864001, "bleu_avg": 11.6}
{"acc_0": 91.2, "acc_1": 90.4, "acc_avg": 90.8}
{"_ACCU": 93.5, "_BLEU": 17.4}
-------avg_loss: 2.2995471954345704e-07, lm_loss: 1.1655086278915405--------
{"dev acc"：96.8}
{"bleu_0": 11.448368812331383, "bleu_1": 11.80978795140994, "bleu_avg": 11.6}
{"acc_0": 90.8, "acc_1": 89.60000000000001, "acc_avg": 90.2}
{"_ACCU": 92.9, "_BLEU": 17.5}
-------avg_loss: 2.2768974304199218e-07, lm_loss: 1.2866952419281006--------
{"dev acc"：96.3}
{"bleu_0": 11.42420373527456, "bleu_1": 12.07496103442552, "bleu_avg": 11.7}
{"acc_0": 89.60000000000001, "acc_1": 89.4, "acc_avg": 89.5}
{"_ACCU": 93.0, "_BLEU": 17.6}
-------avg_loss: 2.2852420806884766e-07, lm_loss: 1.109047293663025--------
{"dev acc"：96.8}
{"bleu_0": 11.371176371050398, "bleu_1": 11.830904142051509, "bleu_avg": 11.6}
{"acc_0": 90.8, "acc_1": 89.0, "acc_avg": 89.9}
{"_ACCU": 93.3, "_BLEU": 17.5}
-------avg_loss: 2.309083938598633e-07, lm_loss: 0.8234723806381226--------
{"dev acc"：95.8}
{"bleu_0": 11.439758365053592, "bleu_1": 12.088304673281678, "bleu_avg": 11.8}
{"acc_0": 90.60000000000001, "acc_1": 89.4, "acc_avg": 90.0}
{"_ACCU": 93.6, "_BLEU": 17.6}
-------avg_loss: 2.3216009140014649e-07, lm_loss: 0.9847015738487244--------
{"dev acc"：96.4}
{"bleu_0": 11.314407633947596, "bleu_1": 12.099848997517435, "bleu_avg": 11.7}
{"acc_0": 90.60000000000001, "acc_1": 89.60000000000001, "acc_avg": 90.1}
{"_ACCU": 93.2, "_BLEU": 17.5}
-------avg_loss: 2.309083938598633e-07, lm_loss: 1.039299488067627--------
{"dev acc"：96.6}
{"bleu_0": 11.320859939897575, "bleu_1": 11.977585096031094, "bleu_avg": 11.6}
{"acc_0": 90.0, "acc_1": 89.2, "acc_avg": 89.6}
{"_ACCU": 93.5, "_BLEU": 17.5}
-------avg_loss: 2.3138523101806641e-07, lm_loss: 1.0644217729568481--------
{"dev acc"：96.5}
{"bleu_0": 11.550114391436042, "bleu_1": 11.771562430257793, "bleu_avg": 11.7}
{"acc_0": 90.2, "acc_1": 90.60000000000001, "acc_avg": 90.4}
{"_ACCU": 93.2, "_BLEU": 17.5}
-------avg_loss: 2.2840499877929687e-07, lm_loss: 0.9910628795623779--------
{"dev acc"：96.4}
{"bleu_0": 11.613815693280062, "bleu_1": 12.079060733037808, "bleu_avg": 11.8}
{"acc_0": 90.2, "acc_1": 89.8, "acc_avg": 90.0}
{"_ACCU": 92.8, "_BLEU": 17.6}
-------avg_loss: 2.3186206817626954e-07, lm_loss: 1.4435241222381592--------
{"dev acc"：95.8}
{"bleu_0": 11.436111326309433, "bleu_1": 12.158176748973311, "bleu_avg": 11.8}
{"acc_0": 90.0, "acc_1": 90.0, "acc_avg": 90.0}
{"_ACCU": 93.3, "_BLEU": 17.6}
-------avg_loss: 2.3245811462402343e-07, lm_loss: 1.0763258934020996--------
{"dev acc"：96.0}
{"bleu_0": 11.46303540213128, "bleu_1": 11.612884749832986, "bleu_avg": 11.5}
{"acc_0": 90.2, "acc_1": 90.2, "acc_avg": 90.2}
{"_ACCU": 93.6, "_BLEU": 17.5}
-------avg_loss: 2.3162364959716798e-07, lm_loss: 1.3000590801239014--------
{"dev acc"：96.2}
{"bleu_0": 11.441892084341717, "bleu_1": 11.920754695078035, "bleu_avg": 11.7}
{"acc_0": 90.0, "acc_1": 89.2, "acc_avg": 89.6}
{"_ACCU": 93.1, "_BLEU": 17.5}
-------avg_loss: 2.2768974304199218e-07, lm_loss: 1.0336482524871826--------
{"dev acc"：96.3}
{"bleu_0": 11.52443643613089, "bleu_1": 12.30662782599204, "bleu_avg": 11.9}
{"acc_0": 90.8, "acc_1": 89.60000000000001, "acc_avg": 90.2}
{"_ACCU": 93.3, "_BLEU": 17.6}
-------avg_loss: 2.281665802001953e-07, lm_loss: 0.9305171370506287--------
{"dev acc"：96.2}
{"bleu_0": 11.404927751328394, "bleu_1": 12.036592077454065, "bleu_avg": 11.7}
{"acc_0": 90.8, "acc_1": 88.8, "acc_avg": 89.8}
{"_ACCU": 93.2, "_BLEU": 17.5}
-------avg_loss: 2.31325626373291e-07, lm_loss: 0.6418656706809998--------
{"dev acc"：96.3}
{"bleu_0": 11.426455972951887, "bleu_1": 11.539391431378741, "bleu_avg": 11.5}
{"acc_0": 91.0, "acc_1": 90.0, "acc_avg": 90.5}
{"_ACCU": 93.2, "_BLEU": 17.4}
-------avg_loss: 2.2578239440917968e-07, lm_loss: 0.9636198282241821--------
{"dev acc"：95.8}
{"bleu_0": 11.42042820612175, "bleu_1": 11.860268094324768, "bleu_avg": 11.6}
{"acc_0": 90.8, "acc_1": 88.8, "acc_avg": 89.8}
{"_ACCU": 92.7, "_BLEU": 17.4}
Best result: dev_acc 97.3 acc 90.4 bleu 11.7 _acc 92.9 _bleu 17.6
Epoch: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [6:30:06<00:00, 2335.37s/it]
[01;32mxgg@decs[00m:[01;34m~/pros/MLM_transfer[00m$ 
[01;32mxgg@decs[00m:[01;34m~/pros/MLM_transfer[00m$ exit
